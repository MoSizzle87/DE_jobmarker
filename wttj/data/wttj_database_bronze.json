{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-04-20", "sector": "Mobilit√©, Application mobile, Logiciels, Intelligence artificielle / Machine Learning, Big Data, E-commerce", "company_size": "1178", "creation_date": "2000", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": [":sqlawssparkscalaairflowpythonconnaissances", "java/kotlin", ":sqlawssparkscalaairflowpythonconnaissances", "java/kotlin"], "databases": null, "data_analyze": null, "big_data_tools": [":sqlawssparkscalaairflowpythonconnaissances"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", ":sqlawssparkscalaairflowpythonconnaissances"], "dev_tools": ["digitales", "digitalisation.son", "#digitalmobilitychanger.c‚Äôest"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": [":sqlawssparkscalaairflowpythonconnaissances"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud"], "raw_description": "Descriptif du posteSNCF Connect & Tech, filiale priv√©e de SNCF Voyageurs, est¬†le leader du e-commerce fran√ßais¬†et impl√©mente les solutions digitales clients dans le secteur des mobilit√©s. En s‚Äôappuyant sur l‚Äôexpertise de plus de 1200 collaborateurs bas√©s √† Lille, Nantes et Paris, SNCF Connect & Tech accompagne le groupe SNCF dans les projets de digitalisation.Son ambition : innover pour rendre les mobilit√©s durables accessibles √† tous.Au sein de l‚Äô√©quipe Business&Client, les Data Engineers r√©pondent aux besoins de reporting de l‚Äôactivit√© commerciale de notre plateforme e-commerce¬†: SNCF Connect, application de r√©servation de billets de train en ligne.En lien direct avec les √©quipes Marketing et la Direction G√©n√©rale, vous collectez et transformez la donn√©e. Dans un contexte de migration sur le Cloud AWS en 2021, vous participez √©galement √† l‚Äôimpl√©mentation de l‚Äôarchitecture dans le but de migrer d‚Äôun dataware house vers un datalake house.Vous serez entour√©.e d‚Äôune √©quipe compos√©e actuellement de 6 Data Engineers, un Product Owner, un Project Manager, un Scrum master d√©di√© et de 2 Quality Assurance Engineers.Activit√©s :Collecter, nettoyer et transformer la donn√©e de mani√®re hebdomadaire,Participation aux d√©veloppements sur le socle Data,Assurer la mise en production et son support,Accompagner les √©quipes Client Interne √† analyser la donn√©e afin qu‚Äôils puissent prendre des d√©cisions strat√©giques pour le groupe,Participer au cadrage de l‚Äôimpl√©mentation de l‚Äôarchitecture,Documenter l‚Äôarchitecture,Garantir les bonnes pratiques de d√©veloppement et de mise en production.Environnement technique :SQLAWSSparkScalaAirflowPythonConnaissances BIProfil recherch√©¬†:Vous avez au minimum 6 ans d'exp√©rience dans la DATA et une premi√®re exp√©rience BI,Vous √™tes proactif.ve, vous ne laissez jamais une probl√©matique sans solution,Savoir √©changer sur l‚Äôavanc√©e de ses projets et partager √† l‚Äô√©quipe sont indispensables,Vous √™tes capable de prendre du recul pour analyser vos pratiques et proposer des solutions dans un esprit d‚Äôam√©lioration continue,Vous souhaitez vous impliquer dans une √©quipe aux projets strat√©giques,Des connaissances en JAVA/KOTLIN serait un plus.Rejoindre SNCF Connect & Tech¬†:C‚Äôest int√©grer la plus grande¬†communaut√© d‚Äôexperts¬†des transformations num√©riques, en France, dans le secteur des mobilit√©s¬†et devenir un¬†#DigitalMobilityChanger.C‚Äôest innover pour rendre les mobilit√©s durables accessibles √† tous\", en incarnant¬†les valeurs de l'entreprise¬†: Citoyennet√©, Audace, Performance, Ouverture, Confiance.C'est¬†continuer √† apprendre et grandir¬†gr√¢ce √† un programme de formation adapt√©e aux envies de chacunC'est b√©n√©ficier d'un package financier comp√©titif et √©quitable fond√© sur un¬†principe de m√©ritocratie¬†collective et individuelleC'est √©voluer au sein d‚Äôune entreprise humaine, inclusive qui favorise un¬†bon √©quilibre de vie pro/perso¬†(jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), certifi√©e Great Place to Work pour la 4√® ann√©e cons√©cutiveC'est¬†s‚Äôengager¬†au service d‚Äôune soci√©t√© durable et solidaire, en favorisant des comportements, des mobilit√©s et des usages responsables"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-03-08", "sector": "SaaS / Cloud Services, Big Data, Cybers√©curit√©", "company_size": "200", "creation_date": "2015", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": ["java,", "scala,", "scalable"], "databases": null, "data_analyze": null, "big_data_tools": ["flink", "flink", "flink"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "gcp,"], "dev_tools": ["github,", "docker.we", "docker,"], "OS": ["unix/linux"], "big_data_and_processing": ["cassandra,"], "automation_and_orchestration": ["ansible", "kubernetes.you"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["docker.we", "docker,", "kubernetes.you"], "collaboration": ["slack,", "subteams", "teams.", "#teamspirit", "teams,"], "skills": ["cloud", "cloud"], "raw_description": "Descriptif du poste ‚≠ê About the team:Made up of six subteams (Dashboard, Engine, Infrastructure, Integrations, Threat Research & Security), the DataDome tech team is spread across Europe and the US. We handle over 2 000 billion events per day giving responses within 3ms (99p). We are present in more than 25 data centers around the world, deployed using Docker.We deploy on AWS, Scaleway, Vultr, and GCP, using Docker, Ansible and Terraform, and monitor with Grafana and Prometheus. We handle an average of  10 billion requests per day and manage more than 350 TB of data per month.When it comes to our stack, we run real-time detection layer in Java, low latency Stream Engine running on Flink in Scala, ElasticSearch for storage, Kafka for communication between layers, HAProxy for load balancing, Symfony & Angular for our dashboards. We use Slack, GitHub, Hangouts, & StackOverflow for Teams. While previous experience in cyber is not a must, we'll pair you with mentors who will help you bridge the gaps. As #growth is part of our DNA, we‚Äôll give you the resources and support you need to develop mastery.The DevOps / SRE TeamOur DevOps / Site Reliability Engineering team is currently composed of 12 SRE Engineers in charge of improving our delivery processes and providing a reliable and scalable platform for our customers.One of the team goal, called Core team, is to handle data stream and data storage in the most performant and efficient way. We are looking for an experienced Site Reliability Engineer with experience in distributed data storage solution.As a member of our Core team, you will :Design, develop and optimise solutions based on ElasticSearch, Kafka and Flink cluster.Develop efficient indexing and search strategies for large volumes of data.Monitor ElasticSearch and kafka performance and storage capacity.Work with the team to integrate ElasticSearch, Kafka and Flink cluster with different cloud provider and bare metal server provider.RequirementsYou have worked at very high scale with systems like ElasticSearch, cassandra, mongodbYou have a great experience working in Unix/Linux environments and a good knowledge of networking systemsYou care about code quality, simplicity and performanceYou have a real passion for automationYou are familiar with, or ready to take, on-call dutiesYou are fluent in EnglishBonus pointsYou have been building big platform at scale and monitoring production environments for several years in the cloud and/or on premises.You have worked with Kubernetes.You monitor your own house and/or homelab :-)You contributed to an open-source project What‚Äôs in it for you?Flex Life: While we offer remote, hybrid, & in-office options each position specifies the level of flexibility. Our Parisian office is located next to the Opera Garnier. You will also receive a 500‚Ç¨ stipend to help you set up your ideal workspace if you work hybrid or remotely.Generous Health Benefits: We have partnered with Alan for your healthcare needs.Professional Development: #Growth is part of our DNA, therefore we have invested in an internal Learning and Development platform and offer the opportunity to request additional training and support via your manager.Events & Team building: Feel the #TeamSpirit both virtually & onsite, with several events & workshops planned throughout the year, including an annual offsite evens, quarterly online and offline events and parties, lunch & learns, & much more.Parent Care: Gift & care packages for parents.PTO: Based on the country you are based from (e.g. 25 days in France).ü¶Ñ DataDome‚Äôs bot and online fraud protection detects and mitigates attacks with unparalleled accuracy and zero compromise. Our machine learning solution analyzes 3 trillion signals per day to adapt to new threats in real time. Hundreds of enterprises worldwide‚Äîincluding Reddit, Rakuten, and AngelList‚Äîtrust DataDome‚Äôs solution and 24/7 SOC experts to protect their mobile apps, websites, and APIs against online fraud, ATO, carding, scraping, layer 7 DDoS, credential stuffing, and more.A force multiplier for IT and security teams, DataDome is fully transparent, easy to deploy, and frictionless for consumers. We offer the only secure, user-friendly, and privacy compliant CAPTCHA integrated with our complete 360¬∞ bot detection solution. With 25+ regional PoPs and autoscaling technology, DataDome responds to requests with zero latency and no impact on the speed of protected platforms.DataDome was ranked top G2 Leader in Bot Detection & Mitigation for three consecutive periods: Fall 2022-Spring 2023, was named a Strong Performer in the 2022 Forrester Wave: Bot Management, and placed 21st in cybersecurity on the Inc. 5000. Certified a Great Place to Work in the US and France, DataDome‚Äôs dedicated team of 160+ BotBusters spans the globe as far as its high-profile customer base.DataDome is an equal opportunity employer, and proud to be committed to diversity and inclusion. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. "}
{"job_title": null, "contract_type": "CDI", "salary": "45K √† 65K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "IT / Digital, SaaS / Cloud Services, Big Data", "company_size": "15", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "1.7", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["gcp.effectuer"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud"], "raw_description": "Descriptif du posteLe posteAu sein de l‚Äô√©quipe de d√©veloppement d‚ÄôInnovela, vous participerez √† la conception et au d√©veloppement de pipeline de donn√©es en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d‚Äôune √©quipe passionn√©e et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectu√©s soit chez nos clients, soit directement dans les locaux d‚ÄôInnovela situ√©s dans le 11√®me arrondissement de Paris.Enfin, vous participerez √©galement aux √©v√©nements organis√©s par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilit√©sIdentifier et conseiller les solutions appropri√©es pour r√©pondre aux besoins des clients.Participer aux diff√©rentes phases d‚Äôun projet (analyse, prototypage, conception, d√©veloppement, d√©ploiement, maintenance).Veiller √† la gouvernance des donn√©es et mise en place de process MDM : Rapprochement de donn√©es de diff√©rentes sources non homog√®nes, D√©doublonnage, Normalisation, Historisation, Calcul d‚Äôindicateurs et d‚Äôagr√©gats.Construire et monitorer des pipeline de donn√©es sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."}
{"job_title": null, "contract_type": "CDI", "salary": "55K √† 80K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "IT / Digital, SaaS / Cloud Services, Big Data", "company_size": "15", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "1.7", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["gcp.effectuer"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud"], "raw_description": "Descriptif du posteLe poste Au sein de l‚Äô√©quipe de d√©veloppement d‚ÄôInnovela, vous participerez √† la conception et au d√©veloppement de pipeline de donn√©es en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d‚Äôune √©quipe passionn√©e et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectu√©s soit chez nos clients, soit directement dans les locaux d‚ÄôInnovela situ√©s √† Paris.Enfin, vous participerez √©galement aux √©v√©nements organis√©s par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilit√©sIdentifier et conseiller les solutions appropri√©es pour r√©pondre aux besoins des clients.Participer aux diff√©rentes phases d‚Äôun projet (analyse, prototypage, conception, d√©veloppement, d√©ploiement, maintenance).Veiller √† la gouvernance des donn√©es et mise en place de process MDM : Rapprochement de donn√©es de diff√©rentes sources non homog√®nes, D√©doublonnage, Normalisation, Historisation, Calcul d‚Äôindicateurs et d‚Äôagr√©gats.Construire et monitorer des pipeline de donn√©es sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Maisons-Alfort", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "FinTech / InsurTech", "company_size": "300", "creation_date": "2012", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digital", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVos missions au service de l‚Äô√©conomie fran√ßaiseAu sein de la Digital Factory, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleurs solutions Data permettant de r√©pondre aux enjeux Business & Strat√©giques de Bpifrance.Afin de renforcer son collectif, la Digital Factory est √† la recherche d‚Äôun. e Lead Data Engineer.La/le lead data engineer :Contribue √† la r√©daction de la feuille de route de l‚Äô√©quipe Core Data de la Data FactoryPrend en charge la supervision, l‚Äôorganision et l‚Äôanimation des Data Engineers de la Data Factory¬†Con√ßoit, met en ≈ìuvre et monitore les traitements d‚Äôalimentation et de transformation des donn√©esGaranti la gouvernance des donn√©es (Data quality, lineage & Data cataloging) en mettant en place les outils et Kpi de suivi ad√©quats¬†Met en place les bonnes pratiques de code et devX¬†Participe √† la formation et au coaching des √©quipes"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Tunis", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Digital Marketing / Data Marketing, IT / Digital, Marketing / Communication", "company_size": "250", "creation_date": "2001", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "26", "proportion_female": "40", "proportion_male": null, "programming_languages": ["python,", "python"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": ["orange"], "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitales", "git."], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["jira,"], "skills": ["cloud", "cloud,"], "raw_description": "Descriptif du posteData Engineer¬†(F/H)Poste bas√© √† TunisSplio est une scale-up du march√© des technologies marketing et digitales dont le si√®ge est √† Paris (Op√©ra). L‚Äôentreprise compte plus de 250 collaborateurs et 4 bureaux en Europe et MEA.Splio √©dite une plateforme marketing SaaS qui int√®gre CDP et Marketing Automation ainsi que toutes les fonctionnalit√©s essentielles du CRM (fid√©lit√©, Mobile Wallets), en une seule et m√™me plateforme boost√©e √† l‚ÄôIA. La plateforme permet aux √©quipes CRM du retail, e-commerce, FMCG et des T√©l√©coms de communiquer et fid√©liser leurs clients de fa√ßon personnalis√©e sur tous les canaux (email, SMS, Push Wallet...)Plus de 500 entreprises du retail, e-commerce, FMCG et des T√©l√©coms, √† travers l‚ÄôEurope et le MEA utilisent Splio au quotidien, parmi lesquelles Nature et D√©couvertes, Longchamp, Bazarchic, APC, The Kooples, Fnac-Darty, Micromania, Faguo, Cyrillus, Orange ou encore Samsung.Missions principales :Toutes les missions sont r√©alis√©es sous la responsabilit√© d‚Äôun Project Manager.Tes missions seront les suivantes :‚ÄØ‚ÄØ Contribution      dans le cadrage technique et des analyses de faisabilit√© des diff√©rentes      √©tapes du projet. Manipulation,      nettoyage et audit de donn√©es D√©veloppement      et maintenance de scripts Python, SQL, Big Query‚Ä¶ D√©veloppement      des mod√®les Data. Mise en      prod des processus projets dans les environnements Cloud de Splio. Audit et      suivi des processus projet en phase Running Etudes      Analytiques approfondies :     o Diagnostic ‚Äì analyses comportementales     o Evaluation de performances des actions en fonction des besoins marketing      et business Gestion de      projets data en autonomie et contact direct avec le client.Profil recherch√© Une      exp√©rience de 0 - 3 ans dans le domaine de la Data. Un dipl√¥me      d‚Äôune √©cole d‚Äôing√©nieur ou master universitaire en data. Une forte      capacit√©e d‚Äôanalyse et de manipulation de la donn√©e. Des      connaissances avanc√©es en Python et SQL. Des      qualifications Google Cloud, dbt, php, Jira, shell et Git. Un go√ªt      prononc√© pour le travail en √©quipe Un sens de      la communication d√©velopp√© Une      organisation sans faille pour r√©pondre aux challenges, tenir les      engagements et traiter plusieurs missions en parall√®leAvantages :üå¥ 12 Splio days (jours off), en plus des 25 jours cong√©s l√©gauxInformations compl√©mentairesType de contrat : CDIDate de d√©but : D√®s que PossibleLieu : Tunis"}
{"job_title": null, "contract_type": "Stage(6 mois)", "salary": "1K √† 1,2K¬†‚Ç¨ par mois", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Musique", "company_size": "30", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["stackpython", "python", "scalable"], "databases": ["3postgresqldbtterraform"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["dmsairflowmissionsimprove", "airflow"], "IaC": ["3postgresqldbtterraform", "terraformcreate"], "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams"], "skills": null, "raw_description": "Descriptif du posteAs a Data Engineering intern, you will be part of the Data Team to deliver the best data infrastructure to support Groover‚Äôs growth. Reporting to our Staff Data Engineer, you will be helping to build our Data Warehouse and interacting with all other teams to scale our analytics infrastructure. You will be instrumental in creating the best analytics infrastructure to support Groover‚Äôs growth.Tech stackPython 3PostgreSQLdbtTerraform / DMSAirflowMissionsImprove our data warehouse infrastructure and data models. Our Data warehouse is the main source of decision-making at Groover, it needs to be robust, available at all times, and centralize all needed data while enforcing our in-house data model.Bring new data sources in our data ecosystem. We constantly seek to add new data sources in our infrastructure so we can improve our user experience or make better analysis. You will have to extract data from various APIs and tools, store it efficiently and make it usable for further purposes.Fuel informed decision-making. Our data warehouse is evolving to meet everyone‚Äôs need at Groover. You will contribute to building a scalable and efficient data analysis ecosystem.In your day-to-day work, you will:Enhance our analytics system by adding or updating models in our dbt environmentReplicate data sources into our data warehouse with AWS DMS and TerraformCreate ETL processes with Python and Airflow to enrich our data sourcesYou‚Äôll be the main owner for all the features you create. It means that you will be the main point of contact for any questions regarding your work and you will have to maintain and make evolve your features.Foster our data-driven culture: A music company building state of the art data infrastructure is putting us ahead of our competition. You will be an ambassador of that culture within the company."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Toulouse", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Application mobile, Logiciels, E-commerce", "company_size": "50", "creation_date": "2009", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "14M$", "proportion_female": "50", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteMission and challenges üéØSi tu es enthousiaste √† embarquer dans la nouvelle √©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c‚Äôest l‚Äôaventure qu‚Äôil te faut!¬†üèîÔ∏èAvec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les √©quipes de Pictarine ne sont jamais √† court d‚Äôid√©es pour explorer de nouveaux horizons. üöÄEn tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta cr√©ativit√© pour garantir la qualit√© de la data, accompagner et challenger les besoins data.Tu √©volueras au sein de l‚Äô√©quipe Engineering, compos√©e des p√¥les dev & data. Tu rejoindras une √©quipe data d√©j√† compos√©e d'une data analyste, Romane, et de la data manager, Marie¬†!Ton r√¥le comprendra les aspects suivants üëáüèªTu es garant de la qualit√© de la data !En simplifiant la structure de la data et r√©duisant le nombre de tablesEn transformant les donn√©es pour les rendre facilement utilisablesEn orchestrant le flux des donn√©es de mani√®re continue et automatiqueTu accompagnes et challenges les √©quipes de Pictarine !En co-construisant des solutions data appropri√©esEn √©levant le niveau de jeu des m√©thodes data existantesEn faisant rayonner la data autour de bonnes pratiques et d‚Äôoutillages ad√©quates"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "Big Data", "company_size": "48", "creation_date": "2017", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["(gcp,"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes", "airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["kubernetes"], "collaboration": null, "skills": null, "raw_description": "Descriptif du posteContexte:Chez namR, nous avons d√©velopp√© une base de donn√©es unique qui permet de caract√©riser tous les b√¢timents de France ‚Äì soit 35 millions de b√¢timents ‚Äì du point de vue de leur morphologie (mesures du b√¢timent, mat√©riaux de toiture etc.), et du point de vue de chacun des axes de potentiel √©cologique, de d√©veloppement et de transformation des b√¢timents (sur ces 3 axes : r√©duction de carbone, r√©silience face au changement climatique, et de d√©veloppement harmonieux avec la nature).Toutes ces donn√©es, appel√©es attributs, sont produites √† partir de notre datalake (la Data Library) puis consolid√©es et massifi√©es par du machine learning et/ou de la computer vision et/ou de r√®gles m√©tiers. Elles sont ensuite stock√©es dans notre base de donn√©es.L‚Äôimpl√©mentation des attributs dans la base de donn√©es et le contr√¥le de leur qualit√© est la mission de l‚Äô√©quipe Data, qui regroupe les Data Scientists et Data Analysts.L‚Äô√©quipe Data engineering participe principalement au d√©veloppement d‚Äôoutils (automatisation des processus de production et de qualit√©) aidant les √©quipes data √† produire des donn√©es. Nous avons √©galement pour mission d‚Äôautomatiser au maximum les pipeline de donn√©es pour √™tre capable de mettre √† jour nos attributs suite √† la publication de nouvelles donn√©es.Nous participons aussi au maintien et au d√©veloppement de l‚Äôinfrastructure et des bases de donn√©es des √©quipes data.Nous sommes actuellement une √©quipe de 5 data engineers, nous travaillons en m√©thode agile avec des sprints de 2 semaines. Nous cherchons donc un profile exp√©riment√© afin de pouvoir contribuer et challenger nos processus d‚Äôautomatisation de production de donn√©eMissions :Participation √† la mise √† jour de nos r√©f√©rentiels de donn√©es ;Veille technique pour proposer de nouvelles solution ;Participation aux r√©flexions sur la mise en place de nouvelles infrastructures/pipelines de donn√©es (GCP, airflow, kubernetes etc..) ;Mise en place de pipelines automatis√©es et robustes (TDD) ;Support technique aux √©quipes data ;Formation de l‚Äô√©quipe ;Garantir la disponibilit√© des outils et bases de donn√©es utilis√©s par l‚Äôensemble des √©quipes intervenant sur notre datawarehouse pour un requ√™tage optimal ;Assurer et surveiller l‚Äôautomatisation des mises √† jour des donn√©es depuis leur sourcing √† leur structuration."}
{"job_title": null, "contract_type": "Stage(5 √† 12 mois)", "salary": "1,4K √† 1,5K¬†‚Ç¨ par mois", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "Logiciels, Intelligence artificielle / Machine Learning, A√©ronautique / Spatiale", "company_size": "100", "creation_date": "2008", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "14", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteSysnav a d√©velopp√© un dispositif m√©dical permettant de mesurer les mouvements des patients, afin de diagnostiquer des maladies neuromusculaires. Ce dispositif est port√© au poignet ou √† la cheville, et des algorithmes utilisent les donn√©es de capteurs inertiels (acc√©l√©rom√®tres et gyrom√®tres) pour reconstruire la trajectoire et estimer des param√®tres cliniques int√©ressants pour les m√©decins et pour d√©terminer l‚Äôefficacit√© des traitements. Plusieurs centaines d‚Äôexemplaires de ce dispositif, nomm√© Syde, sont utilis√©s pour le suivi de patients dans le monde entier.Au sein de l‚Äô√©quipe m√©dicale de Sysnav, le stage consiste √† analyser les donn√©es issues des √©tudes cliniques. Chaque √©tude clinique peut avoir plusieurs centaines de patients portant le dispositif quotidiennement. Ces donn√©es doivent ensuite √™tre trait√©es pour extraire les variables int√©ressantes cliniquement, qui varient suivant la pathologie, l‚Äô√©tat de sant√© du patient, et les sympt√¥mes que l‚Äôon souhaite √©valuer. Ceci n√©cessite la mise en place de pipelines de calcul complexes, ainsi qu‚Äô√† une analyse statistique pouss√©e des donn√©es, en lien √©troit avec les √©quipes cliniques et les m√©decins.2 jours par semaine de d√©placement/pr√©sence dans notre si√®ge social √† Vernon est n√©cessaire."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "Organisation / Management, Strat√©gie, Supply Chain", "company_size": "750", "creation_date": "1995", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "38", "proportion_female": "55", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableaux"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNous recherchons pour un de nos clients sp√©cialis√©s dans la production et la commercialisation de spiritueux, un ing√©nieur supply chain H/F.Vos missions serons les suivantes :Participer aux projets d‚Äôam√©lioration et de d√©veloppement de la logistiqueMettre en ≈ìuvre des indicateurs de pilotage sur la performance logistique des fournisseurs.Cr√©er, d√©ployer des tableaux de bord pour alerter et mesurer les performances pour faciliter le pilotage des activit√©s.Mener des analyses transversales sur des sujets Supply Chain."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-05-07", "sector": "Logiciels, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "40", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": ["mysql,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws"], "dev_tools": ["github,", "dockerdatabase:"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["dockerdatabase:"], "collaboration": null, "skills": ["ml"], "raw_description": "Descriptif du posteTa missionTu int√©greras l‚Äô√©quipe technique de Tomorro, compos√©e de 10 d√©veloppeurs, 2 product designer et 3 product managers.Ton but sera alors de contribuer au d√©veloppement et √† l‚Äôam√©lioration continue de notre application SaaS de gestion de contrats gr√¢ce aux LLMs au sein d‚Äôune squad d√©di√©e.Tu auras pour objectif de d√©velopper de nouvelles fonctionnalit√©s, optimiser les performances et participer √† l‚Äôarchitecture de la solution pour pouvoir offrir une exp√©rience utilisateur fluide et fiable autour des technologies de GenAI.Tes responsabilit√©sContribuer au futur de Tomorro tant au niveau technique que produit en impl√©mentant de nouvelles fonctionnalit√©s autour de l‚ÄôIA g√©n√©rativeSuperviser l‚Äôint√©gration des mod√®les d‚ÄôIA dans nos syst√®mes existants, en s‚Äôassurant qu‚Äôils sont √©volutifs, fiables et performantsMaintenir un niveau maximal de s√©curit√© et de confidentialit√© dans un contexte juridiqueCollaborer avec les autres membres de l‚Äô√©quipe et cultiver le partage de connaissances.Prendre part aux revues de code et veiller √† un niveau d‚Äôexigence √©lev√© sur la qualit√© du codeAssurer une veille permanente sur les sujets IA / ML et proposer des innovationsParticiper activement aux discussions sur l‚Äôarchitecture et challenger les choix techniques de mani√®re pragmatiqueJouer un r√¥le essentiel dans la construction de notre √©quipe technique dans le recrutement et dans la mise en place d‚Äôune structure solideStack techniqueFront-end: React, Typescript, Apollo, StorybookBack-end: Nodejs, Typescript, Nestjs, GraphQLInfrastructure: AWS (ECS, S3, SQS, SNS, Lambdas ‚Ä¶), IAC with CDK, DockerDatabase: Mysql, OpenSearch, RedisMonitoring & Observability: Datadog, SentryCI / CD: Github, CircleCIGestion de projet:¬†Notion, Linear, Figma"}
{"job_title": null, "contract_type": "Alternance(24 √† 12 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": "< 6 mois", "education_level": "Bac +3", "publication_date": "2024-05-07", "sector": "IT / Digital, Transformation, Cybers√©curit√©", "company_size": "1350", "creation_date": "1989", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "136", "proportion_female": "52", "proportion_male": null, "programming_languages": ["python."], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws."], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVos missions :Au sein de la Direction du Num√©rique et de L'innovation, le/la Ing√©nieur Data est acteur (actrice) du d√©veloppement de structures et de pipelines √† grande √©chelle pour collecter, pr√©parer, transformer et diffuser des donn√©es. Il/elle est participant(e) du d√©ploiement et de la surveillance des pipelines de donn√©es, de l'am√©lioration du flux et de la collecte de donn√©es et la production du reporting d√©cisionnel.Vous serez amen√©(e) √† prendre en charge les activit√©s suivantes :- D√©finir l'architecture des donn√©es et s'assurer de la mani√®re dont les donn√©es seront stock√©es, consomm√©es, int√©gr√©es et g√©r√©es par diff√©rentes entit√©s et syst√®mes informatiques pour un cas d'utilisation donn√©es- Prendre part aux d√©veloppements informatiques pour construire et maintenir l'infrastructure requise pour l'extraction, la transformation et le chargement optimal des donn√©es √† partir d'une grande vari√©t√© de sources de donn√©es. Possibilit√© de faire fonctionner des ETL sur des ensembles des donn√©es- Participer √† la cr√©ation de data lakes pouvant √™tre utilis√©s pour le reporting ou l'analyse d√©cisionnelle- Faire de la veille et des PoC sur de nouveaux outils de Data Transformation, DAta Analyse et DataVizVous travaillerez principalement sur les applications Talend, Google Data Studio, JasperSoft. Vous serez amen√© aussi √† faire sur SQL, possiblement des bases de donn√©es objets type MongoDB, et des scripts en Python. Les environnements sont sur AWS."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "V√©lizy-Villacoublay", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale", "company_size": "80000", "creation_date": "2000", "address": null, "average_age_of_employees": null, "turnover_in_millions": "19Mds‚Ç¨", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": ["hadoop"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitalisation"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud,"], "raw_description": "Descriptif du posteQUI SOMMES-NOUS ?Au sein du site de V√©lizy, nos √©quipes hautement qualifi√©es con√ßoivent et produisent des amplificateurs de puissance (tubes √† ondes progressives, klystrons, gyrotrons, sous-syst√®mes pour les Grandes Infrastructures de Recherche, etc.) √† destination des march√©s D√©fense, S√©curit√©, Spatial et Scientifique. Chaque jour nos cadres, ing√©nieurs, techniciens et op√©rateurs mettent en commun leurs savoir-faire unique au service de l‚Äôinnovation.QUI SOMMES-NOUS ?Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces.QUI √äTES-VOUS¬†?Issu d‚Äôune formation Bac +5¬†(√©cole d‚Äôing√©nieur, Master ou √©quivalent),¬†Vous justifiez d‚Äôune¬†exp√©rience de minimum 5 ans¬†sur un poste similaire d‚Äô Architecte Data (H/F)¬†et vous vous reconnaissez dans le profil recherch√© :Vous avez une exp√©rience significative en mise en place d‚Äôun √©cosyst√®me data ¬´ moderne ¬ª couvrant les sujets technologiques, m√©thodologiques et organisationnels.Savoir √©vang√©liser autour des nouvelles approches Data et des notions de Data as a Product en comprenant, expliquant et conduisant le changement.Vous avez une grande connaissance de l‚Äô√©volution de l‚Äô√©cosyst√®me Hadoop et des offres data des principaux cloud providers ainsi qu‚Äôune bonne compr√©hension des enjeux m√©tiers bancaires.Savoir √©voluer dans un environnement complexe (diversit√© des activit√©s, nombre d‚Äôinterlocuteurs, contraintes r√®glementaires, ‚Ä¶)Adaptable, savoir synth√©tiser et simplifier des notions complexes pour partager et transmettre vos connaissancesDes connaissances de la r√©glementation relative √† la donn√©e seraient un plusEtre √† l‚Äôaise en anglais pour animer des r√©unions et des √©changes et r√©diger de la documentationVous maitrisez l‚Äôanglais¬†√† l‚Äôoral comme √† l‚Äô√©crit.Vous avez une connaissance du secteur financier¬†et de ses m√©tiers (banque, assurance ou mutuelle).Vous √™tes reconnu pour votre esprit d'√©quipe, curiosit√© et autonomie, et √©galement pour avoir d√©montr√© des capacit√©s d'analyse et de recherche sur incidents ainsi que sur la compr√©hension et prise en charge de probl√®me en autonomie.CE QUE NOUS POUVONS FAIRE ENSEMBLE¬†:Regroup√©es en centres de comp√©tences logiciel, nos √©quipes participent √† des projets innovants et strat√©giques pour nos clients Grand Comptes dans des secteurs d‚Äôactivit√©s vari√©s (la D√©fense, de l‚ÄôEnergie, des Services et de l‚ÄôA√©ronautique).¬†Notre √©quipe du secteur¬†Banque, Assurance, Mutuelle¬†est √† la recherche d‚Äôun¬†Architecte Data Confirm√©¬†pour poursuivre leur croissance.Acteurs majeurs bancaires en France, nos clients mettent en ≈ìuvre des programmes de transformation dans tous les m√©tiers bancaires afin d‚Äôoffrir une nouvelle exp√©rience √† leurs clients et leurs collaborateurs, d‚Äôacc√©l√©rer la digitalisation et √† am√©liorer l‚Äôefficacit√© op√©rationnelle,¬†et ceci de fa√ßon responsable.L‚Äôutilisation de l‚ÄôIA, de la DATA, le d√©veloppement du cloud, la convergence des plateformes technologiques et le d√©ploiement de l‚ÄôAPIsation du syst√®me d‚Äôinformation sont au c≈ìur de leur mod√®le et donc de nos missions.¬†Vous interviendrez sur des projets de modernisation du SI, de mutualisation et d‚Äôindustrialisation de solutions num√©riques innovantes.Vos missions seront les suivantes :Participer et suivre la mise en ≈ìuvre de la road map strat√©gique data d‚Äôun grand groupe bancaire.D√©finir et mettre en ≈ìuvre des architectures BIG DATA Assurer la structuration des bases de donn√©es dans l‚Äôenvironnement Big DataAssurer le suivi et l‚Äôint√©gration des projets majeurs des syst√®mes BIG DATAR√©aliser une veille technologique pour √©valuer et proposer des nouvelles solutionsAccompagner les √©quipes M√©tier dans leurs travaux d‚Äôidentification et de documentation des donn√©es ¬´¬†M√©tier¬†¬ª, de sp√©cifications et mod√©lisation des donn√©es et des ressources (API, flux, etc‚Ä¶)Piloter l‚Äôalimentation du dictionnaire des donn√©es ¬´¬†M√©tier¬†¬ª, des r√®gles de gestion relatives aux donn√©es et documenter le cycle de vie de chaque Donn√©eD√©finir les r√®gles et les solutions relatives √† la synchronisation des donn√©esTravailler de concert avec les √©quipes de d√©veloppement (agile) pour concevoir des solutions respectant les contraintes impos√©es par l'existant, les organisations ou la r√©glementation pour d√©finir une architecture p√©renne r√©pondant √† des besoins m√©tiersPiloter le choix, la mise en place et l‚Äôadministration fonctionnelle des outils de Data Management (Data Dictionary et Data Lineage)Contribuer √† la mise en ≈ìuvre des outils de contr√¥le de la qualit√© des donn√©es, ¬†√† la r√©alisation de ces contr√¥les et de la production des indicateurs associ√©sAccompagner les √©quipes projets sur le plan de la coh√©rence et de la mise en valeur des donn√©es dans la mise en ≈ìuvre des projets strat√©giques du plan d‚Äôentreprise‚ÄãLe Poste requiert une forte app√©tence technique. L‚Äôaccompagnement consiste √©galement √† mettre en ≈ìuvre les solutions pr√©conis√©es.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "V√©lizy-Villacoublay", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Logiciels, Cybers√©curit√©, A√©ronautique / Spatiale", "company_size": "80000", "creation_date": "2000", "address": null, "average_age_of_employees": null, "turnover_in_millions": "19Mds‚Ç¨", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "scala"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws"], "dev_tools": ["digital", "github,", "jenkins,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud.", "cloud,", "stream)cloud", "cloudwatch,", "fargateci/cd"], "raw_description": "Descriptif du posteQUI SOMMES-NOUS ?Au sein du site de V√©lizy, nos √©quipes hautement qualifi√©es con√ßoivent et produisent des amplificateurs de puissance (tubes √† ondes progressives, klystrons, gyrotrons, sous-syst√®mes pour les Grandes Infrastructures de Recherche, etc.) √† destination des march√©s D√©fense, S√©curit√©, Spatial et Scientifique. Chaque jour nos cadres, ing√©nieurs, techniciens et op√©rateurs mettent en commun leurs savoir-faire unique au service de l‚Äôinnovation.QUI SOMMES-NOUS ?Rejoignez Thales, leader mondial des technologies de s√ªret√© et de s√©curit√© pour les march√©s de l‚ÄôA√©rospatial, du Transport, de la D√©fense et de la S√©curit√©. Fort de 62 000 collaborateurs dans 56 pays, le Groupe b√©n√©ficie d‚Äôune implantation internationale qui lui permet d‚Äôagir au plus pr√®s de ses clients, partout dans le monde.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ?De formation Bac+5 en informatique (√©cole d‚Äôing√©nieur, Master ou √©quivalent) vous √™tes passionn√©(e) par les technologies du Big Data et du Cloud. Vous avez d√©j√† 3-4 ans d‚Äôexp√©rience dans ce domaine et vous recherchez un nouveau challenge professionnel¬†?Vous souhaitez √™tre encadr√© par des experts Big Data et Cloud, au sein d‚Äôune √©quipe jeune et dynamique.Vous r√™vez de concevoir et r√©aliser des infrastructures innovantes¬†dans un contexte Agile.Votre entourage vous reconnait pour votre capacit√© √† apporter des solutions personnalis√©es aux probl√©matiques de vos interlocuteurs. CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :Vous participerez √† la mise en place d‚Äôun pipe d‚Äôingestion de donn√©es au sein d‚Äôun √©cosyst√®me Digital d‚Äôun de nos clients grand compte qui apporte un dispositif de run, s√©curit√©, architecture et design.¬†En nous rejoignant, vous vous verrez confier diff√©rentes missions :Vous travaillerez parmi nos √©quipes de Data Engineers, de d√©veloppeurs Front-End, du SRE et du Responsable produit,Vous travaillerez en mode software craftsmanship : clean code, test, peer programming, reviewVous mettrez en place l‚Äôarchitecture propos√©e par nos Data Architect,Vous participer √† la construction des web APIs de la plateforme notamment autour de la probl√©matique du requ√™tage des s√©ries temporelles,Vous veillerez √† √™tre √† la pointe des technologies afin d‚Äô√™tre force de proposition, Contexte technique du projet¬†:Langage de programmation¬†: Python, Scala (framework Akka Stream)Cloud¬†AWS¬†: S3, Lambda, Kinesis, Dynamo, SageMaker, ECS FargateCI/CD¬†: Github, Jenkins, Cloudwatch, SonarQube, ‚Ä¶‚Ä¶Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-07", "sector": "IT / Digital, Transformation, Big Data", "company_size": "14500", "creation_date": "1976", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "12 Mds ‚Ç¨ en 2022", "proportion_female": "35", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "azure,", "gcp,"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "clouden"], "raw_description": "Descriptif du poste Vous serez amen√© √† r√©aliser les missions suivantes :- Conseil, Audit et Maitrise d‚Äô≈ìuvre- √âtudes d‚Äôopportunit√©, cadrage de projet d‚Äôint√©gration de donn√©es et aide au choix de solution- Accompagnement √† la mise en place de Data Lake / Big Data.- Accompagnement de profil junior.- Conception et d√©veloppement de flux d‚Äôint√©gration des donn√©es (ETL, ELT, streaming , API ‚Ä¶)- Conception et mise en ≈ìuvre de plateformes On Premise ou Cloud de stockage des donn√©es dans un Data Lake (Big Data)- Mise en place de platefome Cloud (OVH, AWS, Azure, GCP, OutScale etc.)- Migration des donn√©es- Move to CloudEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,‚Ä¶). "}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-07", "sector": "Banque, Assurance, FinTech / InsurTech", "company_size": "34244", "creation_date": "1985", "address": null, "average_age_of_employees": "41", "turnover_in_millions": null, "proportion_female": "55", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud¬∑"], "raw_description": "Descriptif du posteCr√©er des outils¬†¬∑ ¬† ¬† ¬† Etablir des cahiers des charges avec les utilisateurs, en comprenant leurs besoins pour d√©finir les solutions les plus adapt√©es¬∑ ¬† ¬† ¬† Lotir les d√©veloppements en ayant le souci de la valeur ajout√©e du 1er lot et de la coh√©rence des livraisons¬∑ ¬† ¬† ¬† D√©velopper les interfaces des applications¬∑ ¬† ¬† ¬† Mettre en place des pipelines de traitement de donn√©es (nettoyage, transformation) et des pipelines de d√©ploiement des applications sur le cloud¬∑ ¬† ¬† ¬† Assurer et garantir la production d'un code de qualit√© et de sa documentation technique¬∑ ¬† ¬† ¬† Etablir des plans de tests¬†Faire la maintenance des outils¬∑ ¬† ¬† ¬† Assurer la mise √† jour r√©guli√®re des outils et documents techniques¬∑ ¬† ¬† ¬† D√©velopper les usages des mod√®les de donn√©es¬†√ätre r√©f√©rent pour les actuaires produits vis-√†-vis de la DSI¬∑ ¬† ¬† ¬† Porter et suivre techniquement les demandes de d√©veloppements de l‚ÄôActuariat IARD Entreprises aupr√®s de la DSI¬∑ ¬† ¬† ¬† Prendre de la hauteur sur les probl√©matiques techniques afin d'orienter l'√©quipe et anticiper les blocages et risques dans les phases de d√©veloppement¬∑ ¬† ¬† ¬† G√©n√©raliser les bonnes pratiques d'industrialisation sur les diff√©rents traitements, en √©tant support p√©dagogue aupr√®s des actuaires Nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons √† nos salari√©s sont nombreux.Nous choisir, c‚Äôest b√©n√©ficier par exemple :D‚Äôun package de r√©mun√©ration complet comprenant un salaire fixe, un compl√©ment de r√©mun√©ration variable, des primes, de la participation et de l‚Äôint√©ressement, la possibilit√© d‚Äôacqu√©rir des actions AXA, ou encore des solutions d‚Äô√©pargne avantageuses ;D‚Äôun cadre de travail flexible jusqu‚Äô√† 3 jours de t√©l√©travail possible par semaine, des tickets restaurant pour les jours t√©l√©travaill√©s ou encore une participation √† l‚Äôachat d‚Äôun √©cran ou fauteuil ergonomique ;D‚Äôune politique visant √† concilier vie personnelle et vie professionnelle avec 28 jours de cong√©s pay√©s, entre 14 et 16 RTT selon les ann√©es, des formules de travail √† temps partiel ou encore des jours d‚Äôabsence r√©mun√©r√©es pour la rentr√©e scolaire ou un d√©m√©nagement par exemple ;De la possibilit√© de s‚Äôengager pour une cause qui vous tient √† c≈ìur gr√¢ce √† nos associations telles que AXA Atout C≈ìur, AXA Comp√©tences Solidaires ou encore AXA Pr√©vention ;Et bien plus encore ! Perspectives de d√©veloppement des comp√©tences et de carri√®res immenses, CE, conciergerie, offres privil√®ges, soutien en cas d‚Äô√©preuve personnelle‚Ä¶On s‚Äôarr√™te l√†, la liste est longue¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Croix", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-06", "sector": "Application mobile, Logiciels, Cybers√©curit√©, Sport, E-commerce, Grande distribution", "company_size": "4000", "creation_date": "2018", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "python,", "java", "scalabilit√©,", "scalables", "scala,", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["spark", "spark", "databricksbusiness"], "ML_and_data_mining": null, "data_viz": ["tableaucompute"], "statistics": null, "cloud_computing": ["aws", "d‚Äôaws"], "dev_tools": ["digital,", "digital", "digital,", "github,", "(github,", "digital", "digital", "digital"], "OS": ["windows)"], "big_data_and_processing": null, "automation_and_orchestration": ["airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["jira", "confluence"], "skills": ["cloud", "cloud", "cloud", "cloud", "ci/cd"], "raw_description": "Descriptif du poste L'√©quipe Data Platform de DECATHLON recherche ses futur-e-s Senior DE bas√©¬∑e¬∑s √† Lille/Paris. Decathlon Digital, qui sommes-nous ?Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille, Nantes, Lyon et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport.Le contexteAu c≈ìur de l‚Äôentit√© Decathlon Digital, nous recherchons nos futur.es Data Engineers pour rejoindre les √©quipes Data Platform.Cette plateforme technologique, globale √† tout le groupe de mani√®re internationale, soutient le d√©veloppement de l‚Äôusage de la Data chez Decathlon, du calcul du chiffre d‚Äôaffaires √† l‚Äôaide de conception de produits innovants.L‚Äô√©quipe Core Data Engineering Nous exposons des enrichissements et des agr√©gations de donn√©es avec un haut niveau de qualit√© permettant √† chaque entit√© de les comprendre et de les utiliser facilement (single point of truth).En rejoignant nos √©quipes vous serez int√©gr√©¬∑e dans une √©quipe core data engnineering pluridisciplinaire (chacune compos√©e de Product Manager, Tech lead, Data Engineer, Scrummaster) tel que  : Offer & Product : r√©f√©rentiel des informations produit , qualit√© des produits, tra√ßabilit√©Planet & Industry : indicateurs environnementaux, nouveaux business model, r√©f√©rentiel composants et mati√®reSales, Finance & HR : donn√©es de ventes, financi√®res et collaborateursTraffic : web & app tracking, SEO, SEA, affluence magasinStock & Market Dynamics : stock, pr√©visions, prix, connaissance du march√©Customer : informations sur les clients (GDPR) L'√©quipe Data FactoryNous sommes garants des outils, de la scalabilit√©, de la mise en place et du respect des bonnes pratiques de d√©veloppement. Nous accompagnons au quotidien l‚Äôensemble des acteurs m√©tiers tels que Data Analysts, Data Engineers, Analytics Engineers, Data Scientists.La Data Factory est con√ßue comme une Modern Data Stack, avec un lakehouse comme centre de gravit√©.Elle est ensuite divis√©e en plusieurs √©quipes, chacune √©tant pilot√©e par un leader technique, avec comme ambition de travailler avec un.e Product Manager attitr√©.e.Envie de contribuer √† cette ambition ? Vous serez int√©gr√©¬∑e dans une des √©quipes suivantes en fonction de vos envies et profil : Equipe Data Processing :Mission : cette √©quipe est en charge de proposer les meilleures solutions pour la r√©alisation de pipelines data. C‚Äôest un r√¥le critique dans la d√©mocratisation de la data et de l‚Äôintelligence artificielle √† Decathlon. Son p√©rim√®tre inclut les outils d‚Äôorchestration et de processing a minima.Personas: principalement des data engineers, d√©sireux d‚Äôobtenir des outils √† la fois performants et stables.Exemple de challenges actuels : ‚ÄúComment aider des utilisateurs peu techniques √† cr√©er des pipelines facilement ?‚Äù. ‚ÄúQuelle est la solution optimale, avec le meilleur ratio prix/performance pour des jobs de processing de moins de 5Go ?‚Äù Equipe Data Observability :Mission: cette √©quipe donne la capacit√© √† tous les utilisateurs du groupe de fiabiliser leurs produits et d'en mesurer la qualit√©. Nous parlons ici de data lineage, de data contracts, de tests d‚Äôint√©grit√© et de qualit√©.personas : profils vari√©s. Il peut s‚Äôagir de data producers souhaitant mieux contr√¥ler ce qui est d√©pos√© dans le lakehouse, de data engineers v√©rifiant le flux de cr√©ation de valeurExemple de challenges actuels : ‚Äúcomment permettre aux data producers de mieux contr√¥ler les donn√©es arrivant dans le lakehouse, et les usages associ√©s ?‚Äù, ‚Äúcomment int√©grer nativement l‚Äôobservabilit√© de la donn√©es aux outils actuels, de l'ingestion √† la data visualization ?‚ÄùTES RESPONSABILITESTu seras en charge de:Construire des pipelines scalables de donn√©es structur√©es et non structur√©es ;Contribuer √† l'√©laboration la strat√©gie de nos stacks techniques et garantir la CI/CD ;Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases ;Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ;Contribuer activement √† notre communaut√© de data engineers ;  STACK TECHNIQUE Environnement cloud AWS (S3, Glue, EMR, Athena...)Environnement Lakehouse DatabricksBusiness Intelligence : TableauCompute et Orchestration : Spark / Scala,  Python,  Airflow, dbtObservability : Open Lineage, Great Expectations, MarquezProduct Management : Jira Product Discovery, Github, Confluence CE DONT VOUS AUREZ BESOIN POUR R√âUSSIRVous avez au moins 5 ans d‚Äôexp√©rience comme Data Engineer, sur l'environnement Cloud d‚ÄôAWS ;Vous ma√Ætrisez au moins l‚Äôun des langages suivants : Python, Scala, Java ; Vous savez optimiser les traitements spark sur des pipelines en production ;Vous justifiez d'exp√©riences significatives sur des projets d‚Äôampleurs et dans la mise en ≈ìuvre de pipelines critiques ;Vous d√©montrez une expertise technique et fonctionnelle sur votre domaine et comprends les enjeux associ√©s ;Vos pairs vous reconnaissent pour votre capacit√© de mentorat et d‚Äôaccompagnement, vous appr√©ciez partager vos connaissance (meetup, etc.) ; Vous comprenez le cycle de vie de la donn√©e et vous √™tes √† l‚Äôaise avec les concepts de data lineage, data gouvernance et data privacy ;Vous ma√Ætrisez l‚ÄôAnglais, √† l‚Äôoral comme √† l‚Äô√©crit (Niveau B2 requis) ;Vous aimez travailler en agilit√© dans un environnement collaboratif (GitHub, Mob programming).Vous avez un sens du service d√©velopp√©.Vous √™tes particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle vous ont permis d‚Äôacqu√©rir dans votre style de leadership et la vie d'√©quipe !Vous avez envie de rejoindre une entreprise √† impact positif (#Tech4Good)   CE QUE NOUS T‚ÄôOFFRONS2 jours de t√©l√©travail par semaine ;Possibilit√© de travailler dans l'un des bureaux de Decathlon Digital √† Lille, Paris ;Mat√©riel fourni en accord avec tes missions et nos engagements soci√©taux (Mac, Windows) ;Une √©quipe de projet locale au sein d'un r√©seau mondial (possibilit√© de carri√®re internationale) ;D√©veloppement des comp√©tences et accompagnement (diversit√© des projets, certifications techniques d√®s la premi√®re ann√©e, formations internes et externes, etc.) ;Package de r√©mun√©ration (participation des employ√©s aux actions de l'entreprise, bonus mensuels/trimestriels).  DECATHLON DIGITAL Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-06", "sector": "Application mobile, Logiciels, Cybers√©curit√©, Sport, E-commerce, Grande distribution", "company_size": "4000", "creation_date": "2018", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "python,", "java", "scalabilit√©,", "scalables", "scala,", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["spark", "spark", "databricksbusiness"], "ML_and_data_mining": null, "data_viz": ["tableaucompute"], "statistics": null, "cloud_computing": ["aws", "d‚Äôaws"], "dev_tools": ["digital,", "digital", "digital,", "github,", "(github,", "digital", "digital", "digital"], "OS": ["windows)"], "big_data_and_processing": null, "automation_and_orchestration": ["airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["jira", "confluence"], "skills": ["cloud", "cloud", "cloud", "cloud", "ci/cd"], "raw_description": "Descriptif du poste L'√©quipe Data Platform de DECATHLON recherche ses futur-e-s Senior DE bas√©¬∑e¬∑s √† Lille/Paris. Decathlon Digital, qui sommes-nous ?Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille, Nantes, Lyon et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport.Le contexteAu c≈ìur de l‚Äôentit√© Decathlon Digital, nous recherchons nos futur.es Data Engineers pour rejoindre les √©quipes Data Platform.Cette plateforme technologique, globale √† tout le groupe de mani√®re internationale, soutient le d√©veloppement de l‚Äôusage de la Data chez Decathlon, du calcul du chiffre d‚Äôaffaires √† l‚Äôaide de conception de produits innovants.L‚Äô√©quipe Core Data Engineering Nous exposons des enrichissements et des agr√©gations de donn√©es avec un haut niveau de qualit√© permettant √† chaque entit√© de les comprendre et de les utiliser facilement (single point of truth).En rejoignant nos √©quipes vous serez int√©gr√©¬∑e dans une √©quipe core data engnineering pluridisciplinaire (chacune compos√©e de Product Manager, Tech lead, Data Engineer, Scrummaster) tel que  : Offer & Product : r√©f√©rentiel des informations produit , qualit√© des produits, tra√ßabilit√©Planet & Industry : indicateurs environnementaux, nouveaux business model, r√©f√©rentiel composants et mati√®reSales, Finance & HR : donn√©es de ventes, financi√®res et collaborateursTraffic : web & app tracking, SEO, SEA, affluence magasinStock & Market Dynamics : stock, pr√©visions, prix, connaissance du march√©Customer : informations sur les clients (GDPR) L'√©quipe Data FactoryNous sommes garants des outils, de la scalabilit√©, de la mise en place et du respect des bonnes pratiques de d√©veloppement. Nous accompagnons au quotidien l‚Äôensemble des acteurs m√©tiers tels que Data Analysts, Data Engineers, Analytics Engineers, Data Scientists.La Data Factory est con√ßue comme une Modern Data Stack, avec un lakehouse comme centre de gravit√©.Elle est ensuite divis√©e en plusieurs √©quipes, chacune √©tant pilot√©e par un leader technique, avec comme ambition de travailler avec un.e Product Manager attitr√©.e.Envie de contribuer √† cette ambition ? Vous serez int√©gr√©¬∑e dans une des √©quipes suivantes en fonction de vos envies et profil : Equipe Data Processing :Mission : cette √©quipe est en charge de proposer les meilleures solutions pour la r√©alisation de pipelines data. C‚Äôest un r√¥le critique dans la d√©mocratisation de la data et de l‚Äôintelligence artificielle √† Decathlon. Son p√©rim√®tre inclut les outils d‚Äôorchestration et de processing a minima.Personas: principalement des data engineers, d√©sireux d‚Äôobtenir des outils √† la fois performants et stables.Exemple de challenges actuels : ‚ÄúComment aider des utilisateurs peu techniques √† cr√©er des pipelines facilement ?‚Äù. ‚ÄúQuelle est la solution optimale, avec le meilleur ratio prix/performance pour des jobs de processing de moins de 5Go ?‚Äù Equipe Data Observability :Mission: cette √©quipe donne la capacit√© √† tous les utilisateurs du groupe de fiabiliser leurs produits et d'en mesurer la qualit√©. Nous parlons ici de data lineage, de data contracts, de tests d‚Äôint√©grit√© et de qualit√©.personas : profils vari√©s. Il peut s‚Äôagir de data producers souhaitant mieux contr√¥ler ce qui est d√©pos√© dans le lakehouse, de data engineers v√©rifiant le flux de cr√©ation de valeurExemple de challenges actuels : ‚Äúcomment permettre aux data producers de mieux contr√¥ler les donn√©es arrivant dans le lakehouse, et les usages associ√©s ?‚Äù, ‚Äúcomment int√©grer nativement l‚Äôobservabilit√© de la donn√©es aux outils actuels, de l'ingestion √† la data visualization ?‚ÄùTES RESPONSABILITESTu seras en charge de:Construire des pipelines scalables de donn√©es structur√©es et non structur√©es ;Contribuer √† l'√©laboration la strat√©gie de nos stacks techniques et garantir la CI/CD ;Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases ;Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ;Contribuer activement √† notre communaut√© de data engineers ;  STACK TECHNIQUE Environnement cloud AWS (S3, Glue, EMR, Athena...)Environnement Lakehouse DatabricksBusiness Intelligence : TableauCompute et Orchestration : Spark / Scala,  Python,  Airflow, dbtObservability : Open Lineage, Great Expectations, MarquezProduct Management : Jira Product Discovery, Github, Confluence CE DONT VOUS AUREZ BESOIN POUR R√âUSSIRVous avez au moins 5 ans d‚Äôexp√©rience comme Data Engineer, sur l'environnement Cloud d‚ÄôAWS ;Vous ma√Ætrisez au moins l‚Äôun des langages suivants : Python, Scala, Java ; Vous savez optimiser les traitements spark sur des pipelines en production ;Vous justifiez d'exp√©riences significatives sur des projets d‚Äôampleurs et dans la mise en ≈ìuvre de pipelines critiques ;Vous d√©montrez une expertise technique et fonctionnelle sur votre domaine et comprends les enjeux associ√©s ;Vos pairs vous reconnaissent pour votre capacit√© de mentorat et d‚Äôaccompagnement, vous appr√©ciez partager vos connaissance (meetup, etc.) ; Vous comprenez le cycle de vie de la donn√©e et vous √™tes √† l‚Äôaise avec les concepts de data lineage, data gouvernance et data privacy ;Vous ma√Ætrisez l‚ÄôAnglais, √† l‚Äôoral comme √† l‚Äô√©crit (Niveau B2 requis) ;Vous aimez travailler en agilit√© dans un environnement collaboratif (GitHub, Mob programming).Vous avez un sens du service d√©velopp√©.Vous √™tes particuli√®rement sensible √† l‚Äôimpact de la pratique du sport pour les valeurs qu'elle vous ont permis d‚Äôacqu√©rir dans votre style de leadership et la vie d'√©quipe !Vous avez envie de rejoindre une entreprise √† impact positif (#Tech4Good)   CE QUE NOUS T‚ÄôOFFRONS2 jours de t√©l√©travail par semaine ;Possibilit√© de travailler dans l'un des bureaux de Decathlon Digital √† Lille, Paris ;Mat√©riel fourni en accord avec tes missions et nos engagements soci√©taux (Mac, Windows) ;Une √©quipe de projet locale au sein d'un r√©seau mondial (possibilit√© de carri√®re internationale) ;D√©veloppement des comp√©tences et accompagnement (diversit√© des projets, certifications techniques d√®s la premi√®re ann√©e, formations internes et externes, etc.) ;Package de r√©mun√©ration (participation des employ√©s aux actions de l'entreprise, bonus mensuels/trimestriels).  DECATHLON DIGITAL Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Villeneuve-d'Ascq", "remote": "T√©l√©travail non autoris√©", "experience": "> 5", "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travail :Au sein d‚Äôune Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s.Vous avez l'occasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.C'est tentant non ? Alors embarquez pour une nouvelle aventure professionnelle !¬†Vos missions¬†:Rattach√©(e) √† la division¬† ¬´ Banque ¬ª, vous √©voluez dans un environnement challengeant et convivial, entour√©(e) de passionn√©s dot√©s d'expertises dans leurs domaines.En tant que Data Engineer, vous √©voluez sur des projets IT √† forte valeur ajout√©e et avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es¬†Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles¬†Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©es¬†Vous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins¬†Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©e¬†Vous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.¬†¬†¬†¬†¬†Informations suppl√©mentairesLes avantages √† nous rejoindre :Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor que vous choisissez.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble. Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´Vendredi ¬ªL'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore‚Ä¶).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements>¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travail :Au sein de notre Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l'occasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.Votre r√¥le et vos missions :Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es¬†;Vous vous assurez¬†que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles¬†;Vous d√©finissez¬†le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez¬†une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins¬†;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.¬†Informations suppl√©mentairesCe que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "FinTech / InsurTech, SaaS / Cloud Services", "company_size": "1400", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "44", "proportion_male": null, "programming_languages": ["python)ü§ù", "scalable,", "scalable"], "databases": ["snowflake,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams", "teams.", "teams.‚Ä¢", "teams"], "skills": null, "raw_description": "Descriptif du posteOur mission? Making day-to-day banking easier for SMEs and freelancers thanks to an online business account that's combined with invoicing, bookkeeping and spend management tools. Thanks to its innovative product, highly reactive 24/7 customer support and clear pricing, Qonto has become the leader in its market.Our journey: Founded by Alexandre¬†and¬†Steve in July 2017, Qonto has rapidly gained trust, serving over 450,000 customers. Thanks to our wonderful team of 1,400+ Qontoers, we also made it to the LinkedIn Top Companies French ranking!Our values:Customer focus | Prioritize customers in everything you doOwnership | Own your part, get things doneTeamwork | Make (team)work easyMastery | Continuously raise the barIntegrity | Always do what‚Äôs right, and respect peopleOur beliefs: At Qonto, we're committed to fostering a welcoming environment where everyone can thrive. We prioritize evaluating applicants based solely on skills and potential, ensuring diversity with 50% international team members, 44% women, and 20% parents. Join us in building a workplace that celebrates diversity and individuality.Discover the steps we took to create a discrimination-free hiring process.Join Qonto as an Analytics Engineering¬†Manager to build and improve our data warehouse, propelling our data platform goals from foundational structures to advanced analytics capabilities.Empower our Analytics Engineering team and engage with senior stakeholders to ensure our data infrastructure is robust and scalable, directly influencing Qonto‚Äôs Data platform's success.Our goal is to transform the data warehouse into a well-structured and easily navigable resource. By establishing a principled and thoroughly documented data model, we'll make our data more accessible and useful for all stakeholders.üë©‚Äçüíªüßë‚Äçüíª As a Analytics Engineering Manager at Qonto, you will:‚Ä¢ Lead the data warehouse roadmap, ensuring project deliverables align with business objectives and timelines.‚Ä¢ Mentor and develop a team of 6 analytics engineers, fostering a culture of technical excellence and growth.‚Ä¢ Engage with key stakeholders to understand business needs, translating them into actionable data solutions.‚Ä¢ Champion database design and best practices, ensuring data integrity and accessibility across the organization.‚Ä¢ Collaborate with cross-functional teams to decrease data ingestion incidents and increase data documentation and discoverability.ü§î What you can expect:‚Ä¢ A dynamic and challenging environment where you can put your stamp on the data warehouse and continuously improve our data stack.‚Ä¢ Close collaboration with technology leaders and the opportunity to shape the future of data analytics at Qonto.‚Ä¢ Exposure to cutting-edge data technologies and methodologies, with the autonomy to drive innovation.‚Ä¢ A hands-on role that values both technical prowess and business acumen.‚Ä¢ The chance to lead a team in a company that's as people-driven as it is data-driven.‚Ä¢ Working with a modern data stack (DBT, Snowflake, Kafka and Python)ü§ù About your future manager:Your future manager, David (Head of Data Platform), brings a wealth of experience in data analytics and a proven track record of leading high-performing teams. David is deeply committed to nurturing talent and fostering an environment where initiative and innovation thrive. He has a strong international career with multiple software and data engineering experiences. Before joining Qonto in January 2022, he was the CTO of several startups in the sports & video game industries.üèÖ About You:- People Management: You have strong leadership experience, managing data engineers, software engineers, or Analytics Engineers. ‚Ä¢ Stakeholder Management: You have a proven ability to manage complex stakeholder relationships and prioritize business impact.‚Ä¢ Mastery: Your domain modeling skills translate complex business processes into efficient and scalable data structures.‚Ä¢ Leadership: You are a natural leader with the ability to influence and drive initiatives across teams.‚Ä¢ Project management is second nature to you, with a knack for visual management and keeping teams on track.‚Ä¢ Hands-on technical expertise: you have a strong understanding of our data stack and the ability to contribute to database design.At Qonto we understand that true diversity isn't just about ticking boxes on a hiring checklist. Apply regardless of the boxes you tick! Who knows? You may have the missing piece of the puzzle we've been searching for all along.üéÅ PerksA tailor-made and dynamic career track. An inclusive work environment. And so much more to help you succeed.- Offices in Paris, Berlin, Milan, Barcelona, and Belgrade;- Tailor-made remote work policy depending on the job you apply for and where you live;- Competitive salary package;- A¬†meal voucher;- Public transportation reimbursement (part or global);- A great health insurance (depending on the country);- Employee well-being initiatives: access to Moka Care¬†to take care of your mental health and great offers for sports and wellness activities;- A progressive disability, and parenthood policy as part of our commitment to the¬†Parental Act¬†(1 in 6 of Qonto employees is a parent!) and childcare benefits with selected partners;- Monthly team events.üí™ Our hiring process:- Interviews with your Talent Acquisition Manager and future managers- A remote exercise to demonstrate your skills and give you a taste of what working at Qonto could be likeWe will send you an interview guide so you can best prepare yourself.On average, our process lasts 20 working days and offers usually follow within 48 hours ü§ûTo learn more about us:Qonto's Blog¬†|¬†Les √âchos I L'Usine Digitale |¬†Courrier CadresTo know how your personal data will be processed during your application process or to request its deletion, please¬†click here."}
{"job_title": null, "contract_type": "Stage(6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "Digital", "company_size": "1000", "creation_date": "2007", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null, "programming_languages": ["python", "python"], "databases": ["bigquery,", "bigquery"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez-nous en tant que Data Engineer pour participer √† l‚Äô√©volution de la plateforme Big Data de Webedia. Nous traitons plus de 500 To de donn√©es par mois, venant de sources de donn√©es vari√©es (tracking sur nos sites internet, revenus publicitaires,‚Ä¶)Vous travaillerez en √©troite collaboration avec nos data analystes afin de leur construire des jeux de donn√©es. Vous pourrez √©galement √™tre amen√© √† intervenir sur des t√¢ches de datavisualisation.Vous rejoindrez une √©quipe de 5 personnes en charge des fonctions data engineering, analysis and science pour le groupe.En tant que Data Engineer, vous :D√©velopperez des jeux de donn√©es √† destination de nos analyst √† l‚Äôaide de Bigquery, dbt et dagsterD√©velopperez des scripts d‚Äôingestion de donn√©es custom en python (en g√©n√©ral pour consommer une API REST)D√©velopperez des applicatifs de datavisualisation √† l‚Äôaide de lookerD√©velopperez des modules de monitoring de notre infrastructure data afin de nous aider √† piloter les co√ªts, identifier les anomalies et faciliter le quotidien d‚Äôun data-engineer.Concernant l‚Äôenvironnement de travail :Vous serez encadr√© par un membre senior de l‚Äô√©quipe data (ie un data analyst/engineer 3 √† 5 ans d‚Äôexp√©rience)Vous serez amen√© √† interagir avec nos clients internes (r√©dacteur chef, responsable de la mon√©tisation,‚Ä¶)En termes de stack technique, nous utilisons Bigquery (un data warehouse que vous pouvez interroger en SQL), Google Data Studio, DBT et python for data science."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Toulouse, Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Villeurbanne", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Saint-Herblain", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Aix-en-Provence‚Ä¶+2", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "IT / Digital, Organisation / Management, Big Data", "company_size": "300", "creation_date": "2010", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "40  ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala)"], "databases": ["snowflake", "snowflake,", "snowflake,conception", "snowflake"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.¬†Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !¬†Vous serez amen√© √† travailler sur :Elaboration d‚Äôarchitectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Boulogne-Billancourt‚Ä¶+2", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteL‚Äôenvironnement data vous anime, vous √™tes sensibles par les enjeux de transitions √©nerg√©tiques et environnementaux.MP DATA recrute un(e) Data Engineer - Data visualisation (H/F) afin de travailler pour des projets aupr√®s d‚Äôun acteur majeur du Transport.Conception et d√©veloppement de solutions permettant la collecte, l‚Äôorganisation, le stockage et la mod√©lisation des donn√©es. Ceux-ci doivent √™tre suffisamment s√©curis√©s et lisibles pour les Data Analysts et Data Scientists,Mise √† jour permanente sur les technologies et les langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement des projets,Contribution, sous la responsabilit√© op√©rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, m√©thodes, outils et proc√©dures sur le Cluster Big Data,Assurer l‚Äôacc√®s aux diff√©rentes sources de donn√©es, et veiller √† la qualit√© des donn√©es,Donner un acc√®s facilit√© aux Data Analysts et Data Scientists afin exploiter les donn√©es dans des conditions optimales,Accompagn√© par les √©quipes internes MP DATA, vous monterez en comp√©tences sur le management des flux de donn√©es pour l‚Äôing√©nierie (pr√© processing, feature engineering‚Ä¶), la mod√©lisation et enfin l‚Äôindustrialisation de vos mod√®les."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Boulogne-Billancourt", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteL‚Äôenvironnement data vous anime, vous √™tes sensibles par les enjeux de transitions √©nerg√©tiques et environnementaux.MP DATA recrute un(e) Data Engineer - Data visualisation (H/F) afin de travailler pour des projets aupr√®s d‚Äôun acteur majeur du Transport.Conception et d√©veloppement de solutions permettant la collecte, l‚Äôorganisation, le stockage et la mod√©lisation des donn√©es. Ceux-ci doivent √™tre suffisamment s√©curis√©s et lisibles pour les Data Analysts et Data Scientists,Mise √† jour permanente sur les technologies et les langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement des projets,Contribution, sous la responsabilit√© op√©rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, m√©thodes, outils et proc√©dures sur le Cluster Big Data,Assurer l‚Äôacc√®s aux diff√©rentes sources de donn√©es, et veiller √† la qualit√© des donn√©es,Donner un acc√®s facilit√© aux Data Analysts et Data Scientists afin exploiter les donn√©es dans des conditions optimales,Accompagn√© par les √©quipes internes MP DATA, vous monterez en comp√©tences sur le management des flux de donn√©es pour l‚Äôing√©nierie (pr√© processing, feature engineering‚Ä¶), la mod√©lisation et enfin l‚Äôindustrialisation de vos mod√®les."}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "P√©rols", "remote": "T√©l√©travail occasionnel", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Ing√©nieries Sp√©cialis√©es, Environnement / D√©veloppement durable, Energie", "company_size": "270", "creation_date": "1999", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableaux", "tableaux"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteSous la supervision du Product Owner SIG et DATA, en tant qu‚ÄôIng√©nieur.e Data en stage, vous serez impliqu√©(e) pour le d√©veloppement et la gestion des solutions de collecte et de stockage de donn√©es. Vos responsabilit√©s comprendront :¬†¬†¬†Recueil des besoins m√©tiers : Vous travaillerez en √©troite collaboration avec les diff√©rentes unit√©s m√©tiers afin de comprendre leurs besoins en mati√®re de collecte et de stockage de donn√©es.¬†¬†¬†D√©veloppement des solutions techniques : Vous participerez √† la conception et √† la mise en place de solutions techniques pour la collecte et le stockage de donn√©es.¬†¬†¬†Tests unitaires et d‚Äôint√©gration : Vous serez responsable de la r√©alisation de tests unitaires et d‚Äôint√©gration pour garantir la qualit√© et la fiabilit√© des solutions de donn√©es d√©velopp√©es.¬†¬†¬†S√©curisation et transparence : Vous travaillerez sur la s√©curisation des pipelines de donn√©es d√©ploy√©es et veillerez √† ce que les parties prenantes, notamment les business units et les data scientists, aient un acc√®s transparent aux flux de donn√©es.¬†¬†¬†¬†Automatisation du nettoyage de donn√©es : Vous contribuerez √† l‚Äôautomatisation du processus de nettoyage de donn√©es conform√©ment aux sp√©cifications d√©finies.¬†¬†¬†¬†Gestion du cycle de vie des donn√©es : Vous assurerez que les donn√©es sont g√©r√©es en conformit√© avec les directives du RGPD.¬†¬†¬†¬†Cr√©ation de tableaux de bord : Vous automatiserez la cr√©ation de tableaux de bord pour les √©quipes m√©tiers, offrant ainsi un acc√®s convivial aux donn√©es.¬†¬†¬†¬†Gestion, maintenance et documentation des bases de donn√©es : Vous serez charg√©(e) de la gestion et de la maintenance des bases de donn√©es d√©ploy√©es, en veillant √† une documentation compl√®te et √† jour.¬†¬†¬†¬†Veille technologique : Vous devrez rester constamment inform√©(e) des √©volutions technologiques dans le domaine de la gestion des donn√©es, en partageant vos connaissances pour contribuer √† l‚Äôavancement du projet.¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "70", "creation_date": "2016", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "6,5", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python", "scalables", "scalable"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["(aws,", "azure)tu"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud"], "raw_description": "Descriptif du postePr√©sentation SicaraCr√©√©e en novembre 2016 au sein du groupe M33 (Theodo group), un √©cosyst√®me de 10 filiales et +650 personnes situ√©es √† Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, bas√©e √† Paris.Notre mission : aider les startups, scaleups et grands comptes √† r√©soudre leurs probl√©matiques business gr√¢ce √† la tech. Nos √©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L‚Äôobjectif : capitaliser sur le potentiel de la donn√©e.Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en d√©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.Pourquoi on recrute un Data Software¬†Engineer ?Afin de contribuer √† la croissance de Sicara, nous recrutons un Data Engineer & Scientist pour renforcer l'√©quipe de Sicara !Tes missions Comprendre le m√©tier et les donn√©es de ton client. Travailler en √©quipe avec 2 √† 4 ing√©nieurs data, 1 Product Owner et 1 Lead TechCr√©er un produit qui cr√©e de la valeur pour ton client avec : les algorithmes les plus adapt√©s, une base de code maintenable, test√©e et scalable des flux de donn√©es robustes et fiablesConcevoir l‚Äôarchitecture du produit et l‚Äôint√©grer dans le SI du client pour le mettre en productionG√©n√©rer de la connaissance technique sur un sujet d'expertise et le propager au sein de SicaraParticiper √† la croissance de Sicara (selon tes pr√©f√©rences : recrutement, avant-ventes, marketing technique)Contribuer √† notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog.Contribuer √† am√©liorer nos savoir-faire en exp√©rimentant continuellement de nouvelles m√©thodes et de nouveaux outils afin d‚Äôam√©liorer l‚Äôefficacit√© des √©quipes.En fonction de tes envies et de tes comp√©tences, tu auras la possibilit√© de :Devenir un(e) expert(e) sur les sujets techniques qui te passionnentDevenir un(e) leader gr√¢ce au d√©veloppement de comp√©tences transverses : coaching, recrutement, commercial, management, marketing, etcMonter une tribe ou une guilde pour d√©velopper un nouvelle offre et am√©liorer nos pratiquesLes avantagesNotre √©cosyst√®me de startup tech est un v√©ritable tremplin pour acc√©l√©rer la progression et les carri√®res !Des bureaux au coeur du quartier des Batignolles √† Paris, partag√©s avec les autres startup tech du groupe TheodoUn coach d√©di√© pour acc√©l√©rer la progression de carri√®reLa possibilit√© de participer √† des¬†conf√©rences techniques internationalesDes conditions de t√©l√©travail flexiblesUn budget trimestriel pour acheter ton mat√©riel tech (laptop, smartphone, casque,...)Des √©v√©nements r√©guliers de team building et un WE d'entreprise √† chaque ann√©eLa possibilit√© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les in√©galit√©s et la s√©curit√© des donn√©esTon profilDipl√¥m√©(e) d‚Äôune √©cole d'ing√©nieur bac+5Tu as une forte app√©tence pour le secteur de la data et tu as id√©alement une premi√®re exp√©rience dans le conseil ou dans la techTu as une bonne connaissance de Python et tu connais ou as envie d‚Äôapprendre √† utiliser l‚Äôun des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure)Tu as envie de progresser et d‚Äô√©voluer dans un environnement challengeant et bienveillant au quotidienA tr√®s vite ! "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "70", "creation_date": "2016", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "6,5", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python", "scalables"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop,", "(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow,"], "IaC": ["terraform)tu"], "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePr√©sentation SicaraCr√©√©e en novembre 2016 au sein du groupe M33 (Theodo group), un √©cosyst√®me de 10 filiales et +650 personnes situ√©es √† Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, bas√©e √† Paris.Notre mission : aider les startups, scaleups et grands comptes √† r√©soudre leurs probl√©matiques business gr√¢ce √† la tech. Nos √©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L‚Äôobjectif : capitaliser sur le potentiel de la donn√©e.Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en d√©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.Pourquoi on recrute un Lead Data Software¬†Engineer ?Pour contribuer √† la croissance de Sicara et pour renforcer les √©quipes Data Software Engineering de Sicara, nous cherchons un profil exp√©riment√©.Tes missions Analyser les donn√©es sources et √©changer avec les experts m√©tier afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierLeader une √©quipe de 2 √† 5 data software engineers dans le delivery de la solution √† impl√©menter au quotidienConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)D√©finir les m√©thodologies de d√©ploiement et plans de migrationConstruire et d√©ployer les pipelines de donn√©es (ETL et ELT)Assurer la migration des donn√©es vers les nouveaux environnementsChoisir et mettre en oeuvre des outils de data analyse et/ou data visualisationMettre en place des outils de contr√¥le de la qualit√© de la donn√©eAccompagner et former les √©quipes clientsAu sein de Sicara :Tu seras amen√©(e) √† accompagner et former les √©quipes au data software engineeringTu assureras une veille technologique continue sur les solutions de l‚Äô√©tat de l‚ÄôartTu interviendras dans la r√©flexion sur la strat√©gie technique √† proposer en phases d‚Äôavant-vente de nos projetsEncadr√© par l‚Äô√©quipe dirigeante, tu g√©n√©reras de la connaissance technique sur des sujets d‚Äôexpertises pour les propager au sein de SicaraEn fonction de tes envies et de tes comp√©tences, tu auras la possibilit√© de :Devenir un(e) expert(e) sur les sujets techniques qui te passionnent.Devenir un(e) leader gr√¢ce au d√©veloppement de comp√©tences transverses : coaching, recrutement, commercial, management, marketing, etc.Monter une tribe ou une guilde pour d√©velopper un nouvelle offre et am√©liorer nos pratiques.Les avantagesNotre √©cosyst√®me de startup tech est un v√©ritable tremplin pour acc√©l√©rer la progression et les carri√®res !Des bureaux au coeur du quartier des Batignolles √† Paris, partag√©s avec les autres startup tech du groupe TheodoUn coach d√©di√© pour acc√©l√©rer la progression de carri√®reLa possibilit√© de participer √† des¬†conf√©rences techniques internationalesDes conditions de t√©l√©travail flexiblesUn budget trimestriel pour acheter ton mat√©riel tech (laptop, smartphone, casque,...)Des √©v√©nements r√©guliers de team building et un WE d'entreprise √† chaque ann√©eLa possibilit√© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les in√©galit√©s et la s√©curit√© des donn√©esTon profilTu as entre deux √† quatre ans d‚Äôexp√©rience sur des sujets de Data Software EngineeringTu es dipl√¥m√© d‚Äôune √©cole d‚Äôing√©nieur en Bac+5Tu as une bonne connaissance de Python et tu as d√©j√† utilis√© des technologies Big Data (Spark, Hadoop, Airflow, Terraform)Tu souhaites participer √† la conception de produits √† fort impact businessTu veux √™tre accompagn√© pour exploiter √† fond ton potentiel et r√©aliser ton ambitionA tr√®s vite ! "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "70", "creation_date": "2016", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "6,5", "proportion_female": "35", "proportion_male": null, "programming_languages": ["scalables"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableaux", "tableau‚Ä¶)tu"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePr√©sentation SicaraCr√©√©e en novembre 2016 au sein du groupe M33 (Theodo group), un √©cosyst√®me de 10 filiales et +650 personnes situ√©es √† Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, bas√©e √† Paris.Notre mission : aider les startups, scaleups et grands comptes √† r√©soudre leurs probl√©matiques business gr√¢ce √† la tech. Nos √©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L‚Äôobjectif : capitaliser sur le potentiel de la donn√©e.Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en d√©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.Tes missions¬†Int√©gr√©(e) aux √©quipes de Sicara et en immersion chez le client, tu r√©pondras aux besoins m√©tier en mati√®re d‚Äôanalyse tout en contribuant √† la construction d‚Äôune offre de BI et de Data Analysis avec le soutien de nos experts.Data Analysis (80%) : ¬†- Comprendre le m√©tier client, sa repr√©sentation dans l‚Äôinfrastructure de donn√©es pour proposer des solutions pertinentes¬†- Mener des ateliers avec le client pour identifier et formuler des besoins auxquels r√©pondre avec la donn√©e- R√©aliser des analyses et dashboards permettant √† nos clients de prendre les meilleures d√©cisions- Challenger les √©quipes m√©tiers de nos clients dans leur prise de d√©cision gr√¢ce √† la donn√©e - Accompagner les √©quipes data clients dans leur mont√©e en comp√©tence - Identifier les opportunit√©s chez le clients o√π notre expertise en Data Engineering ou/et Data Science pourront √™tre appel√©es Gestion de Projet (20%) : - Faire grandir l‚Äôoffre BI & Data Analysis chez Sicara¬†- Participer¬†√† l‚Äôenrichissement et l‚Äôint√©gration de l‚Äôoffre BI et Data Analysis dans le portefeuille de Sicara- Formaliser les apprentissages et les m√©thodologies d‚Äôanalyse de donn√©es utilis√©es chez nos clients ainsi que par les √©quipes Sicara- Assister nos Data Product Owners dans l‚Äôexploration de cas d‚Äôanalyse pertinents pour leurs clientsTon profilTu as une exp√©rience d'environ 2 ans sur une ou plusieurs √©tapes de l‚Äôanalyse de donn√©es (compr√©hension et formulation de la probl√©matique, r√©alisation du livrable, communication des r√©sultats et accompagnement des √©quipes m√©tier‚Ä¶)Tu as un tr√®s bon relationnel, tu aimes cr√©er du lien avec tes clients et comprendre leurs probl√©matiquesTu ma√Ætrises le SQLId√©alement, tu as d√©j√† r√©alis√© des tableaux de bord (Looker, Power BI, Tableau‚Ä¶)Tu as une √©norme envie de progresser, de challenger et d‚Äô√™tre challeng√©(e) !Tes avantagesCadre agr√©able : bureau aux Batignolles, t√©l√©travail flexible, tickets restaurants, after work ‚Ä¶Le groupe Theodo est un excellent tremplin pour acc√©l√©rer les carri√®resPossibilit√© de t'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les in√©galit√©s et la s√©curit√© des donn√©es"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "70", "creation_date": "2016", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "6,5", "proportion_female": "35", "proportion_male": null, "programming_languages": ["scalables", "scalablesveiller"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePr√©sentation SicaraCr√©√©e en novembre 2016 au sein du groupe M33 (Theodo group), un √©cosyst√®me de 10 filiales et +650 personnes situ√©es √† Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, bas√©e √† Paris.Notre mission : aider les startups, scaleups et grands comptes √† r√©soudre leurs probl√©matiques business gr√¢ce √† la tech. Nos √©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L‚Äôobjectif : capitaliser sur le potentiel de la donn√©e.Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en d√©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.Pourquoi on recrute un Engineering Manager (Data Software Engineering) ?Afin de contribuer √† la croissance de Sicara et pour renforcer les √©quipes Data Software Engineering de Sicara, nous cherchons un profil exp√©riment√© pour accro√Ætre la mont√©e en comp√©tences de nos Sicariotes et pour r√©pondre aux attentes techniques de nos clients.L'√©quipe technique de Sicara ; c'est 40 Data Engineers et Data Scientists, Tech Leads ou architectes issus des meilleures √©coles d'ing√©nieur, et en particulier 5 Engineering Manager et 1 CTO pour les faire r√©ussir.A chaque lancement de projets, nous mettons en place une √©quipe diverse d‚Äôexperts techniques, d‚Äôexperts m√©tiers, et d‚Äôexperts de l‚ÄôAgile et du Lean Management. Gr√¢ce √† ce fonctionnement, nous allons rapidement en production et avons un impact direct sur la r√©ussite des objectifs business de nos clients.Tes missions :Am√©liorer la qualit√© des produits r√©alis√©s par les tech leads sur leurs projetsGarantir la satisfaction du sponsor technique client, en aidant le tech lead √† concevoir les features qui d√©livrent un maximum de valeur et tout en √©tant intransigeant sur la qualit√©Aider le tech lead sur le delivery et la conception d‚Äôarchitectures robustes et scalablesVeiller √† la progression des techs en les aidant √† d√©velopper leur thought leadership et √† progresser en continu sur la TechEpauler notre CTO sur des sujets de positionnement technique, d'organisation d'√©quipe et d'√©volution des syst√®mes de Sicara Les avantagesNotre √©cosyst√®me de startup tech est un v√©ritable tremplin pour acc√©l√©rer la progression et les carri√®res !Des bureaux au coeur du quartier des Batignolles √† Paris, partag√©s avec les autres startup tech du groupe TheodoUn coach d√©di√© pour acc√©l√©rer ta progression de carri√®reLa possibilit√© de participer √† des¬†conf√©rences techniques internationalesDes conditions de t√©l√©travail flexiblesUn budget trimestriel pour acheter ton mat√©riel tech (laptop, smartphone, casque,...)Des √©v√©nements r√©guliers de team building et un WE d'entreprise √† chaque ann√©eLa possibilit√© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les in√©galit√©s et la s√©curit√© des donn√©esTes moyens pour r√©ussir Management en direct par le CTO de SicaraCollaboration avec les EM de Sicara et du groupe M33Formations au Lean management√âcosyst√®me M33 avec +500 expert(e)s tech & produit, Plusieurs dojos (sessions de mise en pratique) par semaine : \"archi dojo\", \"projet dojo\", etc...Ton profil Tu disposes d'une connaissance forte de la data (march√©, techno, archi)Tu es capable de d√©bloquer des tech leads sur des challenges techniques complexesTu as une exp√©rience significative en management d'√©quipe techniqueTu sais animer une √©quipe exigeante et performanteTu es dot√© d'un excellent leadership et contact client : tu donnes envie aux autres de te suivre !Tu es guid√© par une √©norme envie de progresser, dans un environnement startup, qui √©volue rapidement ? Alors Sicara pourrait √™tre le bon endroit pour toi !A tr√®s vite ! "}
{"job_title": null, "contract_type": "Freelance", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail total", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, FinTech / InsurTech, SocialTech / GreenTech", "company_size": "7", "creation_date": "2022", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNous recherchons un Freelance ‚ÄúData Science/AI Engineer‚Äù pour faire partie de notre √©quipe et avoir un impact direct sur notre produit et le monde de la finance durable.Responsabilit√©s :Travailler avec l‚Äô√©quipe tech pour int√©grer des solutions d‚Äôintelligence artificielle dans les syst√®mes existants.Veille technologique sur l‚ÄôIA g√©n√©rative et les plateformes de l‚Äô√©cosyst√®me.Id√©ation, cr√©ation et tests de nouveaux mod√®le d‚ÄôIA en rapport avec nos produits ESG.Reportez directement √† notre CTO.Missions:Une premi√®re mission de 2/3 semaine pour apprendre √† se conna√Ætre et valider le fit.Des missions plus p√©riodiques. 5 jours / mois."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 4", "education_level": null, "publication_date": "2024-05-06", "sector": "SaaS / Cloud Services, E-commerce", "company_size": "750", "creation_date": "2012", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "python,", "java/scalamirakl", "scalabilit√©,", "scalable", "java/scalamirakl"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,", "spark", "databricks,"], "ML_and_data_mining": ["tensorflow,"], "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "awsvous"], "dev_tools": ["digitaliser"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["ansible", "kubernetes,", "kubernetesvous", "airflow,", "airflow)accompagner", "(airflow,"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["kubernetes,", "kubernetesvous"], "collaboration": null, "skills": ["mlflow,", "mlops", "ml", "ci/cd"], "raw_description": "Descriptif du posteMirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work. A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days. A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©. Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible Au quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue Quelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML Vous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßais Les plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 4", "education_level": null, "publication_date": "2024-05-06", "sector": "SaaS / Cloud Services, E-commerce", "company_size": "750", "creation_date": "2012", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "python,", "java/scalamirakl", "scalabilit√©,", "scalable", "java/scalamirakl"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,", "spark", "databricks,"], "ML_and_data_mining": ["tensorflow,"], "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "awsvous"], "dev_tools": ["digitaliser"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["ansible", "kubernetes,", "kubernetesvous", "airflow,", "airflow)accompagner", "(airflow,"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["kubernetes,", "kubernetesvous"], "collaboration": null, "skills": ["mlflow,", "mlops", "ml", "ci/cd"], "raw_description": "Descriptif du posteMirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work. A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days. A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©. Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible Au quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes Labs Ce qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue Quelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML Vous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßais Les plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": "> 4", "education_level": null, "publication_date": "2024-05-06", "sector": "SaaS / Cloud Services, E-commerce", "company_size": "750", "creation_date": "2012", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "python,", "java/scalamirakl", "scalabilit√©,", "scalable", "java/scalamirakl"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,", "spark", "databricks,"], "ML_and_data_mining": ["tensorflow,"], "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "awsvous"], "dev_tools": ["digitaliser"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["ansible", "kubernetes,", "kubernetesvous", "airflow,", "airflow)accompagner", "(airflow,"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["kubernetes,", "kubernetesvous"], "collaboration": null, "skills": ["mlflow,", "mlops", "ml", "ci/cd"], "raw_description": "Descriptif du posteMirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work. A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days. A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©. Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible Au quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingue Quelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de ML Vous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßais Les plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi."}
{"job_title": null, "contract_type": "CDI", "salary": "‚â• 45K¬†‚Ç¨", "company": null, "location": "Le Haillan", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": "Bac +2", "publication_date": "2024-05-06", "sector": "Grande distribution, E-commerce, Distribution s√©lective", "company_size": "890", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": "299 ", "proportion_female": null, "proportion_male": null, "programming_languages": ["python‚Ä¶),ma√Ætrise", "(javascript,"], "databases": ["sqlserver/oracle/mysql/as400base", "snowflakem√©thodologie", "snowflakecapacit√©"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": ["linux,", "windowsconnaissances"], "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["agilejira/confluencecomp√©tences", "agilejira/confluencecomp√©tences"], "skills": ["cloudbase"], "raw_description": "Descriptif du posteQuel est notre contexte ?Rattach√© au Responsable IT BI de notre Groupe, vous rejoignez une √©quipe de 4 personnes au sein du Groupe Q√©rys en tant que¬†Data Engineer H/F¬†H/F en CDI.Quel sera votre quotidien ?Vous interviendrez sur l‚Äôensemble des projets Data :Participer √† la mise en place d‚Äôune architecture d√©cisionnelle performante en accord avec la strat√©gie du Groupe.R√©aliser la conception et l‚Äôimpl√©mentation des solutions de data engineering.Faire √©voluer et maintenir le Datawarehouse en place.Participer √† l‚Äôam√©lioration continue de l‚Äô√©quipe (pratiques de d√©veloppement, m√©thodologies, etc.)Assurer une veille technologique autour des sujets DataEnvironnement Technique :ETL : Talend (Talend Open Data Studio, Talend Data Integration, ETLTools)Restitution : Qliksense CloudBase de donn√©es Op√©rationnelle : SQLServer/Oracle/MySQL/AS400Base de donn√©es DATA : SnowflakeM√©thodologie Traditionnel et AgileJira/ConfluenceComp√©tences techniques et fonctionnelles :Connaissance des techniques et pratiques Data (alimentation, mod√©lisation, restitution)Connaissance du cycle de d√©veloppement d‚Äôun projet DataConnaissance approfondie de l‚Äôoutil TalendMa√Ætrise des langages structur√©s (Javascript, Python‚Ä¶),Ma√Ætrise de divers syst√®mes d‚Äôexploitation : Linux, WindowsConnaissances en solutions de bases de donn√©es (SQL, NoSQL‚Ä¶),Maitrise du d√©veloppement de flux de donn√©esExp√©rience sur SnowflakeCapacit√© de mod√©lisation d√©cisionnelleCe que nous vous apportons pour assurer un bon √©quilibre vie pro/vie perso (sous conditions d‚Äô√©ligibilit√©) :32 jours de cong√©s pay√©s (25 + 7 jours ouvr√©s)Lundi de pentec√¥te ch√¥m√© et pay√© (Journ√©e de solidarit√© offerte)Des jours suppl√©mentaires¬†offerts : anciennet√©, d√©m√©nagement, mariage/pacs‚Ä¶Jusqu‚Äô√†¬†2 jours de t√©l√©travail par semaine selon le postePartenariat Klaxit (favoriser le covoiturage)Une¬†mutuelle gratuiteUn int√©ressementPr√©voyanceR√©duction Partenaires - D√©jeunerUne prime de¬†cooptation¬†pour tout collaborateur recrut√© suite √† votre recommandationConditions du contrat : CDI - Temps pleinSalaire et avantages : √† partir 45K‚Ç¨brut/an + int√©ressement + mutuelle Groupe + partenariat d√©jeunerHoraires : 38h45 du lundi au vendrediLocalisation du poste : Le HaillanInformations compl√©mentaires :d√©placements occasionnels sur nos diff√©rents sites √† l‚Äô√©chelle nationalet√©l√©travail possible jusqu‚Äô√† deux jours/semaine"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Vitrolles", "remote": "T√©l√©travail non autoris√©", "experience": "< 6 mois", "education_level": "Bac +4", "publication_date": "2024-05-06", "sector": "Loteries / Jeux de hasard", "company_size": "3000", "creation_date": "1933", "address": null, "average_age_of_employees": "42", "turnover_in_millions": "2 500 ", "proportion_female": "45", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["gitlab,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["ci/cd,"], "raw_description": "Descriptif du posteLe Centre d'Ing√©nierie de Performance (CIP) de la Direction des Op√©rations est √† la recherche de son alternant pour l'ann√©e 2024 ! Ce d√©partement a la charge de garantir la conformit√© des applications mises en production par rapport √† la performance attendue ; faire face √† l'√©volution de l'offre et √† l'augmentation du nombre des joueurs ; limiter le nombre d'incidents de Performance en production. Votre quotidien Embarquons ensemble pour vos futures missions !Sous la tutelle d'un Leader Technique Performance, vous vous attaquerez au d√©fi de perfectionner les applications \"Datawharehouse\" et \"Datalake\" pour traiter efficacement les donn√©es √† grande √©chelle.Vous serez charg√© d'√©laborer un Pipeline d'industrialisation de tests sur la DATA, en commen√ßant par l'usage de l'outil KCR, tout en vous familiarisant avec des technologies telles que Gitlab, CI/CD, et Grafana.Vous d√©velopperez des comp√©tences dans la simulation d'utilisateurs virtuels pour tester les sites web et les applications mobiles de la FDJ, ainsi que dans l'am√©lioration des outils de tests de charges, de la pr√©paration √† l'analyse des r√©sultats.Vous plongerez dans les activit√©s de production et d'int√©gration/qualification, acqu√©rant ainsi une compr√©hension approfondie du processus global.Vous aurez l'opportunit√© de prendre en charge, avec le soutien de votre tuteur, le d√©veloppement et l'int√©gration de plusieurs scripts pour automatiser les √©tapes de pr√©paration jusqu'au reporting final des campagnes de Performance ax√©es sur la DATA. Pourquoi rejoindre l'√©quipe :Vous travaillez sur les applications FDJ, tout en acqu√©rant des comp√©tences cl√©s en mati√®re de testing et de technologies innovantes. Vous d√©veloppez vos comp√©tences dans un environnement dynamique et stimulant.Vous contribuez directement √† l'am√©lioration des processus de tests de performance.   "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Boulogne-Billancourt", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste¬∑¬†¬†¬†¬†¬† Concevoir et d√©velopper des solutions Data pour la collecte, l‚Äôorganisation, le stockage et la mod√©lisation des donn√©es,¬∑¬†¬†¬†¬†¬† Assurer l‚Äôacc√®s fiable, efficace et s√©curis√© aux diff√©rentes sources de donn√©es m√©tier et processus, tout en mettant en place des outils et m√©thodes de contr√¥le et de validation de la qualit√© des donn√©es,¬∑¬†¬†¬†¬†¬† Optimiser les processus de collecte, transfert et stockage des donn√©es (ETL), en assurant l‚Äôad√©quation avec les contraintes techniques et op√©rationnelles,¬∑¬†¬†¬†¬†¬† Maintenir les outils, technologies et processus √† jour, en assurant une veille technique assidue et une supervision permanente de l‚Äôenvironnement."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Logistique, SaaS / Cloud Services, E-commerce", "company_size": "2000", "creation_date": "1998", "address": null, "average_age_of_employees": "38", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null, "programming_languages": ["scalabilit√©,"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteInt√©gr√© √† la DSI en tant que Data Visualization Engineer, au sein de la direction IT DATA, vous viendrez apporter votre expertise technique sur l'industrialisation et la mise en place des briques de reporting de la soci√©t√©.Vous serez notamment charg√© de : Mettre √† disposition d'outillage d'aide aux d√©veloppement, monitoring‚Ä¶ , Contribuer √† la r√©duction des co√ªts dans une d√©marche FinOps, Encadrer l‚Äôindustrialisation du d√©ploiement des applications de reporting en utilisant les bonnes pratiques de la CICD, Proposer des architectures techniques en mettant en ≈ìuvre les principes de l‚ÄôAgilit√©, d'int√©gration et de d√©ploiement continu, en anticipant les besoin de scalabilit√©, Former et accompagner les utilisateurs aux bonnes pratiques de d√©veloppement des reporting, Participer √† l'animation de la communaut√© Power BI, Optimisation des datasets et dashboard, Faire une veille technologique autour des architectures de reporting. ¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "55K √† 60K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-06", "sector": "Application mobile, Logiciels, SaaS / Cloud Services, Marketing / Communication", "company_size": "450", "creation_date": "2014", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "48", "proportion_male": null, "programming_languages": ["python"], "databases": ["postgresql", "bigquery."], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableau.profils"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePartoo, who are we? üëÄPartoo¬†est une scale-up saas B2B qui a √† c≈ìur d‚Äôaider les commerces locaux, grandes entreprises ou PME √† se rapprocher de leurs clients. Pour cela, ils ont d√©velopp√© une plateforme tout-en-un et diff√©rentes solutions qui s‚Äôarticulent autour de 3 propositions de valeur : Get found, Get chosen & Get clients.√Ä travers ces 3 propositions, ils ont d√©velopp√© plusieurs produits qui s‚Äôadaptent aux √©volutions du parcours d‚Äôachat des clients :üîé¬†Get found- Presence: Synchroniser les informations des magasins sur les principales plateformes (Google, Facebook, Waze, etc.), annuaires et GPS.- Store Locator: Aider les clients √† trouver le magasin qui leur convient gr√¢ce √† des donn√©es locales actualis√©es et des filtres d√©di√©s sur les sites web des enseignes.- R√©seaux sociaux: G√©rer les publications sur Facebook, Google, Instagram, etc.üéØ Get chosen- Review: Centraliser, r√©pondre et analyser les avis clients re√ßus sur Google et Facebook.- Booster: Obtenir des avis positifs suppl√©mentaires sur Google par le biais de SMS et de QR codes.ü§ó Get clients- Messages: Centraliser et r√©pondre √† tous les messages de chat re√ßus via Google Business Messages, Messenger et bient√¥t aussi via Instagram, whatsapp, etc. (templates messages, conversations starter, appels manqu√©s...)Quelques chiffres¬†üóùÔ∏è--> Un label Happy at Work et l'une des meilleures notes¬†Glassdoor¬†de l'√©cosyst√®me avec 4.6/5 pour plus de 260 avis‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è  Ô∏èÔ∏èÔ∏èÔ∏èÔ∏èÔ∏è--> 450+ employ√©s heureux, 37 nationalit√©s diff√©rentes, des bureaux √† Paris et Barcelone¬†üöÄ--> Ils g√®rent 300 000 points de vente et travaillent de mani√®re transversale avec +1000 cha√Ænes (Carrefour, Generali, Toyota, D√©cathlon, Leroy Merlin etc.) et +6000 pme dans environ 150 pays.Notre m√©mo 2024: le mot du CEO (https://www.partoo.co/fr/blog/memo-2024/)IMPACT üí•Partoo compte aujourd‚Äôhui pas moins de 400 collaborateurs, qui ≈ìuvrent au quotidien √† maintenir une croissance saine, en phase avec les enjeux et challenges √©conomiques du moment. Une des composantes clefs pour y parvenir r√©side en notre capacit√© √† d√©velopper et maintenir un haut niveau d‚Äôefficacit√© op√©rationnelle. Dans cette logique, am√©liorer notre capacit√© √† exploiter et utiliser la donn√©e pr√©sente dans nos syst√®mes est indispensable. Si nous avons d√©j√† une √©quipe Data en place, celle-ci est aujourd‚Äôhui mobilis√©e presque exclusivement sur les th√©matiques data relatives au fonctionnement de notre application ainsi qu‚Äô√† la construction d‚Äô√©l√©ments de visibilit√© pour nos clients. Nous souhaitons donc recruter un Data Engineer & Analyst dont l‚Äôobjectif principal sera de permettre aux √©quipes Op√©rations et client-facing de visibiliser et tirer le meilleur parti d‚Äôune donn√©e aujourd‚Äôhui difficile d‚Äôacc√®s.¬†Manager : Adel Adman¬† (cc. Cl√©ment Bouillaud, en charge de la team Operations)TEAM üíôMeetings r√©current avec les membres de Partoo :¬†Membre √† part enti√®re de l‚Äô√©quipe Data (elle-m√™me int√©gr√©e dans l‚Äô√©quipe Produit), tu seras n√©anmoins en contact r√©gulier avec les √©quipes Op√©rations, qui seront tes principales interlocutrices. En d‚Äôautres termes, tu seras le pilier central entre les √©quipes Ops et Data.¬†Dans un premier temps, tu auras un meeting hebdomadaire avec Adel (Lead Data) et avec Cl√©ment (COO), le temps de cadrer tes premi√®res priorit√©s et de trouver la bonne r√©currence de rencontre avec les √©quipes Op√©rations.  MISSIONS üî•Ton principal objectif consiste √† faire en sorte que chaque personne, des √©quipes Op√©rations comme des √©quipes¬† client-facing,¬†ait acc√®s √† la donn√©e dont elle a besoin, au moment o√π elle en a besoin, sur le support le plus ad√©quat.¬†¬†Pour y parvenir, plusieurs missions seront tiennes :Architecture¬†:¬†Cr√©er des architectures de donn√©es robustes et √©volutives pour collecter, stocker et analyser de grandes quantit√©s de donn√©es provenant de diverses sources (Salesforce, Intercom, Chargebee, back office de Partoo, etc.)Analyser et am√©liorer continuellement le mod√®le de donn√©es Salesforce (SF), en accompagnant l'√©quipe Ops dans le monitoring des anomalies et l'optimisation des performances.Int√©grations et flux : D√©velopper et optimiser des pipelines de donn√©es, assurant l'int√©gration fluide des donn√©es dans notre Data Warehouse depuis diff√©rentes sources, et inversement.Transformation & analyse :¬†Concevoir et ex√©cuter des requ√™tes SQL complexes pour l'analyse de donn√©es, permettant de soutenir les d√©cisions business.Identifier et construire des KPI cruciaux, fournissant des insights pr√©cieux aux √©quipes business.Visualisation : Fournir aux √©quipes Ops et client-facing des outils de visualisation de donn√©es (Looker Studio, embedding, etc.), cl√©s dans l'optimisation de notre gestion de client√®le. Formation : Former les √©quipes Op√©rations sur l‚Äôexploitation des tables de notre Datawarehouse ainsi que sur l‚Äôusage de Looker Studio et propager les principales best practices associ√©es.¬†Tout √ßa, en collaboration au quotidien avec les √©quipes Ops ! DESIRED PROFILE üéØComp√©tences recherch√©es : Une tr√®s bonne connaissance du langage SQL, notamment PostgreSQL et BigQuery. Ma√Ætrise du scripting Python et des notebooks pour l'analyse de donn√©es.D‚Äôexcellentes capacit√©s d'analyse pour comprendre les besoins business, identifier les anomalies dans les donn√©es et proposer des am√©liorations pertinentes.Une bonne aptitude √† manipuler et analyser de grands ensembles de donn√©es et en extraire des insights actionnables.Une tr√®s bonne ma√Ætrise d'au moins un outil de business intelligence tel que Looker Studio, PowerBI ou Tableau.Profils recherch√© :¬†Tu as plus de 3 ans d'exp√©rience en Data Engineering /Advanced Data Analysis.Tu ma√Ætrises les stacks de data les plus r√©centes (dbt, Airflow, Airbyte, etc.) et les meilleures pratiques en mati√®re de donn√©es (ETL, reverse-ETL, etc.).Tu es orient√©(e) utilisateur et sais convertir les besoins commerciaux en solutions techniques.Tu sais communiquer avec les √©quipes et t'assurer que les meilleures pratiques sont adopt√©es.Tu es un team player ! Tu souhaites apprendre et grandir avec nous.RECRUITMENT PROCESS üõ†Ô∏èA first video call with Marine, Talent Acquisition Specialist, 45 min  Interview with Adel, Lead Data Engineer, 1h Case Study Interview with Cl√©ment, Chief Operations Officer, 1h √Ä comp√©tences √©gales, ce poste est ouvert aux travailleurs et travailleuses en situation de handicap ou assimil√©s au sens de l‚Äôarticle L5212-13 du Code du travail. Partoo s‚Äôengage en faveur de la diversit√©, l‚Äô√©galit√© professionnelle, l‚Äôemploi des travailleurs handicap√©s.With equal skills, this position is open to disabled workers or those considered to be disabled within the meaning of Article L5212-13 of the French Labour Code. Partoo is committed to diversity, professional equality and the employment of disabled workers."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Neuilly-sur-Seine", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation", "company_size": "70", "creation_date": "2016", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null, "programming_languages": ["python,", "javascript¬∑", "scala,"], "databases": ["mysql,", "bigquery,"], "data_analyze": null, "big_data_tools": ["spark,", "databricks/"], "ML_and_data_mining": null, "data_viz": ["tableau,"], "statistics": null, "cloud_computing": ["#aws¬∑", "#azure,", "azure", "azure", "#gcp,"], "dev_tools": ["git,"], "OS": ["linux,", "windows"], "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["#cloud¬∑", "cloud", "cloud,", "cloud", "ci/cd"], "raw_description": "Descriptif du posteVOTRE FUTURE MISSION :Vous travaillerez¬†pour le compte de¬†l‚Äôun de nos clients, au sein de l‚Äô√©quipe Data sur le d√©veloppement de solutions Data Analytics. Vos principales missions seront les suivantes :¬∑¬†¬†¬†¬†¬†¬†¬†¬† Concevoir et mettre en ≈ìuvre des solutions de traitement de donn√©es¬†dans un environnement¬†#Cloud¬∑¬†¬†¬†¬†¬†¬†¬†¬† Mener des √©tudes de faisabilit√© et pr√©coniser les architectures data cibles¬∑¬†¬†¬†¬†¬†¬†¬†¬† Cr√©er, tester et d√©ployer des pipelines de donn√©es d‚Äôextraction, de transformation et de chargement¬∑¬†¬†¬†¬†¬†¬†¬†¬† Mettre en application les concepts de CI/CD via les outils d√©di√©s¬∑¬†¬†¬†¬†¬†¬†¬†¬† Participer √† la mise en ≈ìuvre de produits de Data visualisation : dashboard, reporting‚Ä¶¬∑¬†¬†¬†¬†¬†¬†¬†¬† Participer aux ateliers de collecte des besoins aupr√®s des √©quipes m√©tiers¬∑¬†¬†¬†¬†¬†¬†¬†¬† R√©diger la documentation (sp√©cification techniques, document d‚Äôexploitation, dossier d‚Äôarchitecture‚Ä¶) et analyser les solutions les plus adapt√©es¬∑¬†¬†¬†¬†¬†¬†¬†¬† Assister les phases de recette utilisateurs (identification ou mise en place de jeux de tests, recueil et traitement des demandes de changements)¬∑¬†¬†¬†¬†¬†¬†¬†¬† Accompagner et former les utilisateurs √† la prise en main des solutionsEnvironnement technique :¬∑¬†¬†¬†¬†¬†¬†¬†¬† Cloud : #Azure, #GCP, #AWS¬∑¬†¬†¬†¬†¬†¬†¬†¬† Langages : SQL, Python, Spark, Scala, Javascript¬∑¬†¬†¬†¬†¬†¬†¬†¬† Base de donn√©es : SQL Server/SQL Cloud, Google BigQuery, Oracle, MySQL, MongoDB¬∑¬†¬†¬†¬†¬†¬†¬†¬† Datamanagement : Azure Data Factory / Databricks/ Synapse (id√©alement), Google Cloud Data Fusion / Datafllow, DBT, Talend, SQL Server Integration Services.¬∑¬†¬†¬†¬†¬†¬†¬†¬† Datavisualisation : Power BI (id√©alement), Tableau, Qlik, DataStudio/Looker¬∑¬†¬†¬†¬†¬†¬†¬†¬† Repository : GIT, Azure DevOps, SVN¬∑¬†¬†¬†¬†¬†¬†¬†¬† Syst√®mes d‚Äôexploitation : Unix, Linux, Windows"}
{"job_title": null, "contract_type": "Stage(6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "E-commerce", "company_size": "50", "creation_date": "2014", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "60", "proportion_male": null, "programming_languages": ["donn√©estackpythonairflowaws"], "databases": ["postgresqldocker", "gcpbigquery,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["donn√©estackpythonairflowaws", "gcpbigquery,"], "dev_tools": ["postgresqldocker"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["donn√©estackpythonairflowaws"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["postgresqldocker"], "collaboration": null, "skills": null, "raw_description": "Descriptif du posteEn tant que Data Engineer tu seras en charge de concevoir, d√©velopper et maintenir l‚Äôinfrastructure et les syst√®mes de donn√©es. Tu travailleras √† la fois en √©troite collaboration avec les Data Analysts mais aussi avec les √©quipes Growth et Techs afin de mettre en place de nouveaux outils √† destination de nos utilisateurs.MISSIONSParticiper au d√©veloppement d‚Äôune stack data dans son enti√®ret√© (collecte, stockage, transformation, diffusion)Optimiser les performances des syst√®mes de donn√©es en am√©liorant les temps de traitement et la qualit√© des donn√©esAider les √©quipes produits pour d√©velopper de nouvelles fonctionnalit√©s qui reposent sur de la donn√©eSTACKPythonAirflowAWS / GCPBigQuery, PostgreSQLDocker"}
{"job_title": null, "contract_type": "CDI", "salary": "40K √† 90K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-06", "sector": "Logiciels, IT / Digital, Big Data", "company_size": "35", "creation_date": "2021", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "4.2 ", "proportion_female": "10", "proportion_male": null, "programming_languages": ["python,", "scalable,tu", "scalaframework"], "databases": null, "data_analyze": null, "big_data_tools": ["sparkcloud"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["awset"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["sparkcloud"], "raw_description": "Descriptif du poste‚ú® Ta missionEn tant que Buster :Tu veilles √† d√©livrer les meilleures interventions clients :Tu contribues au d√©veloppement de produits √† fort impact business,Tu d√©veloppes de nouvelles features sur divers projets clients en fournissant un code de qualit√©: maintenable & scalable,Tu es proactif et tends vers une approche conseil pour tes clients en leur proposant de nouvelles technos, et nouvelles m√©thodologies pour les rendre plus performants.Tu aspires √† devenir meilleur de jour en jour :La Tech est un environnement exigeant et en perp√©tuelle √©volution. Afin de d√©livrer les meilleures interventions, tu dois apprendre sans cesse et rester √† jour. Faire preuve d‚Äôhumilit√© et √™tre capable de remettre en question tes acquis.Tu as de l‚Äôimpact au sein de la communaut√© :C‚Äôest le r√¥le de chaque Buster de contribuer au d√©veloppement de la communaut√©. Tu pourras t‚Äôimpliquer sur les sujets suivants :Construction du SI de la communaut√©,Recrutement de nouveaux Busters,Coaching et diffusion de tes comp√©tences,D√©velopper des comp√©tences transverses : coaching, recrutement, commercial, management.Ton environnement technique:Back : Python, ScalaFramework : SparkCloud : AWSEt les plus de Code Busters alors ?üí∞Une r√©mun√©ration transparente compos√©e d‚Äôun salaire fixe entre 40k‚Ç¨ et 70k‚Ç¨ qui d√©pend de ton grade et un bonus d√©plafonn√© d√©pourvue de toute subjectivit√© !üí•Un environnement de travail √©nergique et bienveillantüíªUn budget formation annuel de 2000‚Ç¨ü§ùUne ascension professionnelle √©paul√©e par ton squad leader au quotidienü§´Un s√©minaire annuel, pas besoin de t‚Äôen dire plus on te laisse d√©couvrir‚Ä¶üçΩ Carte tickets restaurants SwileüöáTitre de transport pris en charge √† 100%üòçAssurance sant√© prise en charge √† 100%Tes Perspectives d‚Äô√©volutionNotre ambition est de former les leaders de la tech de demain. Nous avons cr√©er un parcours en grade pour t‚Äôaider √† construire ta carri√®re par √©tapes. Gr√¢ce au coaching et formations que l‚Äôon propose, tu pourras :D√©velopper de l‚Äôexpertise technique sur les sujets tech qui te passionnent,D√©velopper des comp√©tences transverses : coaching, recrutement, commercial, management,Participer √† des guildes d‚Äôexpertises pour am√©liorer tes pratiques et celles de ton √©quipe."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Malakoff", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": null, "publication_date": "2024-05-06", "sector": "Banque, Assurance, FinTech / InsurTech", "company_size": "34244", "creation_date": "1985", "address": null, "average_age_of_employees": "41", "turnover_in_millions": null, "proportion_female": "55", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteReportant au Head of HR Data, vous √™tes responsable du design, de la maintenance et √©volution de l‚Äôinfrastructure data de la RH centrale AXA Partners. C‚Äôest un poste global qui impacte plus de 8500 collaborateurs pr√©sents dans 25 pays. Ce poste √† une forte dimension op√©rationnelle et technique, pour produire des analyses intervenant dans les d√©cisions strat√©giques de l‚Äôentreprise.Vous participez activement au d√©veloppement de la strat√©gie data RH, et de l‚Äôoffre HR Analytics √† destination des √©quipes HR et non HR. Vos missions seront :√ätre le responsable technique du data lake RH, cubes et des environnements utilis√©s pour les rapports et analyses-¬†¬†¬†¬†¬†¬†¬†¬†¬† Assurer une qualit√© de service d‚Äôacc√®s aux donn√©es, avec les mises √† jour n√©cessaires-¬†¬†¬†¬†¬†¬†¬†¬†¬† Industrialiser les activit√©s de BAU-¬†¬†¬†¬†¬†¬†¬†¬†¬† Con√ßoit et met en ≈ìuvre les √©volutions fonctionnelles et techniques requises pour l‚Äôint√©gration de nouvelles donn√©es -¬†¬†¬†¬†¬†¬†¬†¬†¬† Contribue au design et met en ≈ìuvre des solutions d‚Äôintelligence artificielle avec les √©quipes IT pour am√©liorer l‚Äôefficacit√© des process RH -¬†¬†¬†¬†¬†¬†¬†¬†¬† Coordonne les actions n√©cessaires avec le Data Office d‚ÄôAXA Partners et AXA GO pour la gestion des infrastructures-¬†¬†¬†¬†¬†¬†¬†¬†¬† Garanti la s√©curit√© des donn√©es dans le respect des r√®gles √©tablies avec les parties (audit, m√©tiers, IT, ‚Ä¶) -¬†¬†¬†¬†¬†¬†¬†¬†¬† Pouvez d√©velopper et maintenir des rapports PowerBI pour des analyses sp√©cifiques ou s‚Äôint√©grant dans l‚Äôoffre globale HR Analytics.¬†Assister le Head of data RH dans la d√©finition et le d√©ploiement de la strat√©gie des donn√©es RH pour AXA Partners-¬†¬†¬†¬†¬†¬†¬†¬†¬† Identifie les donn√©es manquantes et les solutions pour r√©pondre √† des besoins sp√©cifiques-¬†¬†¬†¬†¬†¬†¬†¬†¬† D√©finit des strat√©gies de collecte, stockage et de partage des donn√©es RH. Les pr√©sente de mani√®re √† pouvoir les int√©grer dans les sp√©cifications m√©tiers ou les solutions en place. ¬†Employez vos comp√©tences, pour repr√©senter l‚Äô√©quipe HR Analytics en face de nos interlocuteurs IT et RH -¬†¬†¬†¬†¬†¬†¬†¬†¬† Collecte des besoins et transformation en propositions hi√©rarchis√©es de solutions possibles-¬†¬†¬†¬†¬†¬†¬†¬†¬† Planifier et mettre en ≈ìuvre les solutions valid√©es, dans le respect du budget et du planning-¬†¬†¬†¬†¬†¬†¬†¬†¬† Cr√©er et maintenir des documentations des solutions mises en ≈ìuvre √† destination des interlocuteurs techniques ¬†¬† ¬†En rejoignant AXA Partners, vous travaillerez dans une entreprise responsable qui offre une v√©ritable culture d'expertise et de diversit√©. Notre objectif est d'acc√©l√©rer le d√©veloppement des comp√©tences de nos collaborateurs, tout en proposant une r√©mun√©ration attractive et comp√©titive ainsi que des opportunit√©s d‚Äô√©volution professionnelle. Au sein du Groupe AXA, nous ≈ìuvrons tous ensemble pour donner √† chacun les moyens de vivre une vie meilleure et c‚Äôest une fiert√© extraordinaire. ¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Grenoble", "remote": "T√©l√©travail non autoris√©", "experience": "> 2", "education_level": null, "publication_date": "2024-05-05", "sector": "Ing√©nieries Sp√©cialis√©es, IT / Digital, Organisation / Management", "company_size": "1500", "creation_date": "1991", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "155 ", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteCe que nous pouvons accomplir ensemble :Rattach√©(e) √† notre site de Grenoble compos√©e d'une trentaine de personnes, vous serez accueilli(e) par une chaleureuse √©quipe d'ing√©nieurs et techniciens passionn√©s, investis, dynamique et reconnus pour leurs expertises m√©tiers d√©velopp√©es au service des plus grands industriels.Ce poste vous offrira l'opportunit√© d'intervenir sur l‚Äôun de nos projets pour un grand compte industriel de l'√©nergie dans le domaine de la DATA.Votre r√¥le :Gouvernance des donn√©es :S'assurer que les donn√©es de maintenance ou d‚Äôinfrastructure de son p√©rim√®tre respectent les principes et les r√®gles d√©finies nationalement et r√©gionalementAppliquer les r√®gles √©tablies de la gestion des donn√©esContr√¥ler la qualit√© des donn√©es de son p√©rim√®treSupport aux consommateurs de donn√©es :Assister les personnes souhaitant exploiter des donn√©es dans la recherche des sources de donn√©es ad√©quates et en diffusant les bonnes pratiques d'exploitation des donn√©es et de documentation des traitements.Traduire et soumettre les besoins des sp√©cialistes m√©tiers en requ√™te de gouvernance sur son p√©rim√®treS'assurer de la mise en place des standards et des bonnes pratiques de gestion des donn√©es de mani√®re homog√®ne entre les diff√©rents m√©tiers (op√©rationnels et fonctions supports)Diriger les analyses d'impact des requ√™tes de gouvernance sur son p√©rim√®tre en mobilisant les sp√©cialistes m√©tiers et autres sp√©cialistes (garants fonctionnels, architectes, etc‚Ä¶)"}
{"job_title": null, "contract_type": "Autres", "salary": "Non sp√©cifi√©", "company": null, "location": "Poitiers", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-04", "sector": "SaaS / Cloud Services, Big Data, Cybers√©curit√©", "company_size": "3000", "creation_date": "1976", "address": null, "average_age_of_employees": null, "turnover_in_millions": "232", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", ":sqlpython/sparkcloud", "java", "java).vous", "scala.maintenance", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop", "spark", "spark.d√©veloppement", "spark", ":sqlpython/sparkcloud"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws)", "aws:", "aws", "aws", "aws)stockage", "(aws", "aws", "azure,"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow.support", "airflow)bases"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "cloudera,", ":sqlpython/sparkcloud"], "raw_description": "Descriptif du posteOffre d'Emploi : DATA ENGINEER H/F chez ApsideDescription du poste : Nous sommes √† la recherche d'un Data Engineer passionn√© pour rejoindre notre √©quipe dynamique. Si vous avez une expertise dans le Big Data, la Data Science, l'analyse de donn√©es et l'architecture de donn√©es, cette opportunit√© est faite pour vous. Int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Vos missions :D√©veloppement des jobs Spark pour la collecte et la transformation des donn√©es comptables disponibles dans les bucket S3.Optimisation des jobs Spark.D√©veloppement des batchs Java et √©criture des donn√©es au formats comptables.√âcriture et ordonnancement des DAGs Airflow.Support du d√©veloppement Spark Scala.Maintenance applicative.Production des √©v√©nements d√©di√©s √† la plateforme de donn√©es..Votre r√¥le, vos comp√©tences :Vous ma√Ætrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (SQL, Scala, Python, Java).Vous √™tes passionn√© par le Big Data et le Machine Learning.Vous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©es.Vous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks).Environnement technique :SQLPython/SparkCloud AWS: AWS Glue, AWS Lambda (possibilit√© de vous former sur AWS)Stockage objet (AWS S3)Orchestration et scheduling de t√¢ches (Apache Airflow)Bases analytiques et bases NoSQL (ElasticSearch, AWS Athena)Rejoignez-nous et apportez votre touche √† l'√©volution d'Apside !Apside s'engage pour l'emploi des personnes en situation de handicap avec Apsid'EA.Apside : L'expertise technologique avec une touche humaine."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-04", "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "10", "creation_date": "2021", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": ["!python,"], "databases": ["postgresql,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": ["pytorch,"], "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "gcp,"], "dev_tools": ["github", "github"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["slack"], "skills": null, "raw_description": "Descriptif du posteNotre Stack Technique !Python, PostgreSQL, OpenCV, Pillow, Pytorch, IAInt√©gration continue et d√©ploiement continue avec Github actionsTest unitaire avec PytestNotion & Github & SentryAgile & ScrumGPU, Serverless AWS, GCP, S3, IoT, PubNubTous les tools sont connect√©s √† notre Slack"}
{"job_title": null, "contract_type": "Stage(4 √† 6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-05-04", "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "10", "creation_date": "2021", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": ["!python,"], "databases": ["postgresql,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": ["pytorch,"], "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "gcp,"], "dev_tools": ["github", "github"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["slack"], "skills": null, "raw_description": "Descriptif du posteNotre Stack Technique !Python, PostgreSQL, OpenCV, Pillow, Pytorch, IAInt√©gration continue et d√©ploiement continue avec Github actionsTest unitaire avec PytestNotion & Github & SentryAgile & ScrumGPU, Serverless AWS, GCP, S3, IoT, PubNubTous les tools sont connect√©s √† notre Slack"}
{"job_title": null, "contract_type": "Stage", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-04", "sector": "AdTech  / MarTech", "company_size": "600", "creation_date": "2001", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "(java", "scalable,", "scalable", "scala..)."], "databases": ["snowflake,", "bigquery,", "bigquery", "(bigquery,"], "data_analyze": null, "big_data_tools": ["flink,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digital", "(git,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow,", "airflow-"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["sub-teams"], "skills": ["cloud", "cloud", "cloud-", "cloud", "cloud", "ci/cd", "ci/cd,"], "raw_description": "Descriptif du posteüë´¬†About the teamAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers. Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges. Our data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.The data engineers are split in two sub-teams working in close collaboration:- Pipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs. - Feature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses.Our Mission üëáOur Data Engineering team is central to Equativ‚Äôs data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.We enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.We rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBT‚Ä¶) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.What you'll do ‚úèÔ∏è¬†As a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:Take a leading part on a data engineering project such as but not limited to:- Proof of Concept of Clickhouse Cloud- Improvement of the data transformation process with DBT, BigQuery and Airflow- Development of new functionalities on our internal tools (APIs, software applications)- Setup a data lineage application (castor doc)¬†Support the data engineering team in their day-to-day activities:- Enhance our DevOps process with CI/CD and testing framework.- Monitor performances and workflow of our applications using reporting tool (Grafana)Take part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativüí™ About youMaster degree in Computer Science or similar technical field of study.Prior experience in data or software development related environment is desired.Experience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus.Good knowledge of SQL and one other data programming language (Java preferred, Python, Scala..).¬†Knowledge on the software development process (Git, CI/CD, test, scrum)Working proficiency and communication skills in verbal and written EnglishStrong interest in big data and cloud computing technologies.¬†üëã About us¬†Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!----------------------Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-04", "sector": "IT / Digital, Transformation, Big Data", "company_size": "14500", "creation_date": "1976", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "12 Mds ‚Ç¨ en 2022", "proportion_female": "35", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste Tu es encadr√© par un Chef de projet et tu peux t‚Äôappuyer sur les comp√©tences d‚Äôune √©quipe incluant quelques dizaines de collaborateurs dont des experts techniques.- Tu d√©veloppes des √©volutions sur les applicatifs de la TMA- Tu participes √† la conception d√©taill√©e- Tu r√©diges des sp√©cifications techniques simples- Tu r√©diges des cahiers de tests unitaires- Tu participes √† la recette d‚Äôint√©gration des lots √©volutifs- Tu apprends et respectes la m√©thodologie d‚Äôun cycle Projet- Tu apprends le domaine fonctionnel du m√©tier ClientRejoindre CGI dans le cadre de ton alternance, c‚Äôest intervenir sur des projets d‚Äôenvergure et vari√©s en lien avec ta formation tout en b√©n√©ficiant d‚Äôun accompagnement de proximit√© pour construire ta carri√®re. C‚Äôest aussi s‚Äôinvestir aupr√®s d‚Äôune entreprise responsable qui propose de nombreux avantages (prise en charge jusqu‚Äô√† 100% des transports en commun) et partager des moments de convivialit√©¬†! "}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Aix-en-Provence", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "M√©dia, T√©l√©vision / Production audiovisuelle, Electronique / T√©l√©communications", "company_size": "11000", "creation_date": "1987", "address": null, "average_age_of_employees": null, "turnover_in_millions": "11 milliards en 2022", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "python,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop/cloudera.la"], "ML_and_data_mining": null, "data_viz": ["tableau", "tableau"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["hadoop/cloudera.la"], "raw_description": "Descriptif du posteIntitul√© du posteAu sein de la Direction Ex√©cutive R√©seau et plus particuli√®rement de la Direction de l'Exploitation, vous int√©grez l'√©quipe Support Technique R√©seaux Mobiles.¬†Vous assurerez un r√©el travail d'analyses de donn√©es sur le p√©rim√®tre de l'acc√®s radio particuli√®rement au niveau du post traitement des BDD de Mesures Radio VOIX/DATA, des BDD de KPI remont√©s des √©quipements radio, et plus globalement sur le BIG DATA SFR, dans le but de merger et faire converger les diff√©rents univers de donn√©es.Rattach√©(e) au manager du service, vous int√©grez une √©quipe de 10 personnes ayant des profils d'ing√©nieurs Radio & T√©l√©coms. Dans le cadre de votre alternance, vous prendrez en charge les missions suivantes :- D√©velopper un outil d'automatisation de pr√© diagnostics (Programmation script SQL, PYTHON, PHP, PERL, ...) des mesures radio trimestrielles effectu√©es par SFR en VOLTE et DATA 4G/5G sur les Agglom√©rations du TOP 15 et les Axes de Transport.- Etablir les algorithmes et r√®gles de corr√©lation afin d'identifier de mani√®re automatique les zones g√©ographiques d√© positionn√©es versus la concurrence par typologie de dysfonctionnement : Bas D√©bits 4G/5G, MOS Volte d√©grad√©, Coupures, Accessibilit√© WEB ...¬†- Mettre en corr√©lation les zones identifi√©es avec les KPIs issus des √©quipements radio pour effectuer une premi√®re caract√©risation des probl√©matiques (saturation, couverture, d√©faut baie radio) en y associant un premier niveau d'analyse automatis√©e via la production de vos d√©veloppements.¬†- Mettre en place des Dashboard automatiques sur Tableau Serveur / Grafana afin de d√©terminer des zones g√©ographiques pr√© diagnostiqu√©es n√©cessitant de mener des analyses et actions d'optimisation ou de lancer du correctif pour en am√©liorer la performance.¬†¬†ProfilIssu(e) d'une formation d'ing√©nieur BAC+4/5 orient√©e BI/BIG DATA, vous avez acquis de fortes comp√©tences en d√©veloppement informatique, m√©thode de corr√©lation statistique, et Big Data.¬†Vous ma√Ætrisez les langages informatiques : Python, PHP, Perl, SQL ainsi que les environnements Hadoop/Cloudera.La connaissance des logiciels de Business Intelligence et de Data Visualisation type ¬´ TABLEAU ¬ª seraient un plus ainsi qu'une premi√®re exp√©rience au niveau la r√©alisation d'analyse de donn√©es complexes et leur interpr√©tation.Vous aimez l'innovation, les nouvelles technologies et le travail en √©quipe. Vous √™tes reconnu(e) pour votre curiosit√© et votre sens relationnel,¬†Vous √™tes force de proposition, d√©sireux (se) de rejoindre une entreprise renomm√©e et des √©quipes engag√©es ?Vous souhaitez concr√©tiser vos projets ? Booster vos comp√©tences ? Rejoignez-nous"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Aix-en-Provence", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "M√©dia, T√©l√©vision / Production audiovisuelle, Electronique / T√©l√©communications", "company_size": "11000", "creation_date": "1987", "address": null, "average_age_of_employees": null, "turnover_in_millions": "11 milliards en 2022", "proportion_female": null, "proportion_male": null, "programming_languages": ["python),-", "python)"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": ["linux.vous"], "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteIntitul√© du posteAu sein de la Direction Ex√©cutive R√©seau et plus particuli√®rement de la Direction de l'Exploitation, vous int√©grez l'√©quipe Support Technique R√©seaux Mobiles.¬†Dans le cadre de votre alternance, nous vous proposons de travailler sur l'acc√®s radio et notamment les alarmes, incidents et remont√©s de donn√©es issus des √©quipements.Rattach√©(e) au manager du service, vous int√©grer une √©quipe de 7 personnes ayant des profils d'ing√©nieurs T√©l√©coms. Vous prendrez en charge progressivement les missions suivantes :- Optimisation de l'architecture Big Data (Bdd) et webserveur, m√©thode de requ√™tage et temps de r√©ponses pour le support acc√®s radio,¬†- Mise en forme et analyse des donn√©es issues de la BDD des alarmes (programmation script SQL, PHP, Perl et Python),- Vous prendrez part aux travaux de pr√©diction des √©volutions de temp√©rature, des baisses de d√©bits des fibres optiques et des pannes des √©metteurs radio 4G / 5G du r√©seau mobile de SFR.ProfilTitulaire d'un Bac +4 ou √©quivalent, vous pr√©parez une formation informatique Big Data.¬†Vous poss√©dez des comp√©tences en Big Data (architecture SI, traitement de Bdd,...), en programmation (script SQL, PHP, Perl et Python) et des syst√®mes d'exploitation Linux.Vous avec √©galement des comp√©tences en m√©thode de corr√©lation statistique et du langage R. Une connaissance des r√©seaux IP et radio seraient un plus.Vous aimez l'innovation, les nouvelles technologies et le travail en √©quipe. Vous √™tes reconnu(e) pour votre curiosit√©, votre autonomie et votre sens relationnel, Vous √™tes force de proposition, d√©sireux (se) de rejoindre une entreprise renomm√©e et des √©quipes engag√©es ?Vous souhaitez concr√©tiser vos projets ? Booster vos comp√©tences ? Rejoignez-nous !¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Aix-en-Provence", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "M√©dia, T√©l√©vision / Production audiovisuelle, Electronique / T√©l√©communications", "company_size": "11000", "creation_date": "1987", "address": null, "average_age_of_employees": null, "turnover_in_millions": "11 milliards en 2022", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["(tableau"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteIntitul√© du posteAu sein de la Direction R√©seaux, et plus particuli√®rement au Support Technique, vous int√©grez l'√©quipe Performance Mobile & Transmission en charge de corriger les d√©rives de performances du r√©seau mobile 2G/3G/4G/5G afin de garantir le meilleur r√©seau possible √† nos clients.Dans le cadre de votre alternance nous vous proposons de travailler sur la transformation de notre mode de traitement de la performance r√©seau mobile vers le \"data driven\".Accompagn√©(e) de votre tuteur, et en vous appuyant sur le manager de service, vos principales missions seront les suivantes :- Cr√©er un rapport de data visualisation sur les donn√©es voix en vous basant sur les bases du Big data de SFR- Accompagner la transformation de l'√©quipe vers le \"data driven\" pour continuer √† am√©liorer le niveau de performance du r√©seau mobile de SFR- Documenter les rapports mis en place et leurs applications op√©rationnelles- Etre support de l'√©quipe sur les besoins \"outils\" (bases Access, Excel avec macros, ...)ProfilTitulaire d'un BAC +3 vous int√©grez un Master ou une formation d'Ing√©nieur en alternance dans la Data Science ou dans le traitement de donn√©es¬†Vous disposez des connaissances / comp√©tences suivantes :¬†- outil de Data Visualisation (Tableau de pr√©f√©rence)¬†- univers microsoft (excel, access, ...)¬†- t√©l√©communications mobiles seraient un plusVous aimez l'innovation, les nouvelles technologies et le travail en √©quipe. Vous √™tes reconnu(e) pour votre curiosit√© et votre sens relationnel, vous √™tre force de propositions, d√©sireux (se) de rejoindre une entreprise renomm√©e¬†et des √©quipes engag√©es ?Vous souhaitez concr√©tiser vos projets ? Booster vos comp√©tences ? Rejoignez-nous !¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "M√©rignac", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-03", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["javaexploration", "scala,"], "databases": ["postgresql,"], "data_analyze": null, "big_data_tools": ["spark,", "pyspark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["gitlab,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetesingestion", "airflow/argostockage"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["kubernetesingestion", "openshift"], "collaboration": null, "skills": ["cloudera", "dataikuci/cd"], "raw_description": "Descriptif du posteVotre futur environnement de travail :Int√©gr√©(e) au sein de l‚Äôagence ¬´ Services Publics ¬ª de Bordeaux, vous rejoignez une √©quipe Data et prenez une part active aux projets d√©livr√©s pour le compte d‚Äôun grand client public.Votre r√¥le et vos missions :Vous int√©grez l‚Äô√©quipe d‚ÄôInt√©gration de la Donn√©e, √©quipe responsable de la gestion des donn√©es, garantissant qu‚Äôelles sont collect√©es, pr√©par√©es et int√©gr√©es de mani√®re fiable pour alimenter les analyses et les applications de l'√©quipe Big Data. Vous jouez un r√¥le cl√© dans la transformation des donn√©es brutes en informations exploitables.Collecte de Donn√©esExtraction, Transformation et Chargement (ETL)Int√©gration des Donn√©es Structur√©es et Non Structur√©esGestion des Flux de Donn√©es en ContinuS√©curit√© des Donn√©esGestion des M√©tadonn√©es¬†Performance et √âvolutivit√©Collaboration avec les Autres √âquipesPlanification et AutomatisationMaintenance et SurveillanceEnvironnement technologique :¬†Plateformes :¬†Cloudera Data Platform et Openshift / KubernetesIngestion : Kafka, Camel, BenthosOrchestration : Airflow/ArgoStockage donn√©es brutes : Ceph/MinIO, Parquet, Avro, IcebergStockage donn√©es structur√©es : PostgreSQL, MongoDB, Oracle DatabaseTraitements : Spark, Pyspark, Scala, JavaExploration : Trino/Dremio, Jupyter, Hive/Beeline, DataikuCI/CD : Gitlab, HarborDatavisualisation : Superset, DigDash, IHM AngularInformations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.¬†Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore‚Ä¶).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "M√©rignac", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["ooziescala,"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["shellgitlab,", "jenkins,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travailInt√©gr√©(e) au sein d‚Äôune √©quipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participerez √† un projet Big Data, en mode Agile,¬†et interviendrez en tant que r√©f√©rent technique au sein de votre √©quipe.Votre r√¥le et missions :A cette occasion vous serez amen√© √† :Apporter votre expertise et votre exp√©rience √† vos coll√®gues lors des phases de conception et d√©veloppement¬†;Accompagner vos coll√®gues dans leur mont√©e en comp√©tence technique au sein du projet¬†;D√©finir et impl√©menter des solutions au sein d‚Äôun p√©rim√®tre applicatif existant¬†;Proposer des id√©es d‚Äôam√©lioration continue √† votre client et √† votre √©quipe (revue de proc√©dures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualim√©trie)¬†;Concevoir et d√©velopper des sujets complexes.Environnement du projet¬†: M√©thodologie projet¬†: Mode Agile (Framework Scrum).Environnement technique :Hdfs, hive, spark, oozieScala, HQL, ShellGitLab, Nexus, Maven, Jenkins, SonarEnvironnement fonctionnel¬†:Alimentation d‚Äôun DataLake jusqu‚Äòau build d‚Äôun moteur de calculIntervention sur la mise en place de r√®gles relatives aux normes B√¢loisesInformations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.¬†Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore‚Ä¶).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "M√©rignac", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["ooziescala,"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["shellgitlab,", "jenkins,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travailInt√©gr√©(e) au sein d‚Äôune √©quipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participerez √† un projet Big Data, en mode Agile,¬†et interviendrez en tant que r√©f√©rent technique au sein de votre √©quipe.Votre r√¥le et missions :A cette occasion vous serez amen√© √† :Apporter votre expertise et votre exp√©rience √† vos coll√®gues lors des phases de conception et d√©veloppement¬†;Accompagner vos coll√®gues dans leur mont√©e en comp√©tence technique au sein du projet¬†;D√©finir et impl√©menter des solutions au sein d‚Äôun p√©rim√®tre applicatif existant¬†;Proposer des id√©es d‚Äôam√©lioration continue √† votre client et √† votre √©quipe (revue de proc√©dures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualim√©trie)¬†;Concevoir et d√©velopper des sujets complexes.Environnement du projet¬†: M√©thodologie projet¬†: Mode Agile (Framework Scrum).Environnement technique :Hdfs, hive, spark, oozieScala, HQL, ShellGitLab, Nexus, Maven, Jenkins, SonarEnvironnement fonctionnel¬†:Alimentation d‚Äôun DataLake jusqu‚Äòau build d‚Äôun moteur de calculIntervention sur la mise en place de r√®gles relatives aux normes B√¢loisesInformations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.¬†Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore‚Ä¶).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-03", "sector": "Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech", "company_size": "170", "creation_date": "2018", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "24", "proportion_male": null, "programming_languages": ["python", "python"], "databases": null, "data_analyze": null, "big_data_tools": ["spark);"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "azure);", "gcp", "gcp", "(gcp,"], "dev_tools": ["git", "gitlab", "github", "docker", "docker;"], "OS": ["linux"], "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes", "kubernetes;", "airflow"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker", "docker;", "kubernetes", "kubernetes;"], "collaboration": ["slack", "teams;", "teams;", "teams", "teams"], "skills": ["cloud", "cloud", "cloud", "ci/cd", "ci/cd", "ci/cd", "ci/cd"], "raw_description": "Descriptif du posteABOUT DESCARTES UNDERWRITINGDescartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.ABOUT YOUR ROLEDue to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects.You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events. üîî  KEY MISSIONS üîî  Setup, automate, maintain and update:      Connections to external and internal APIs;   Data preparation process;   Model training and inference process;   Data storage process;   Associated CI/CD pipelines;   Associated package versioning and       releasing pipeline;   Modularization of code base;   Notification tools to inform the team of       the status of the operations.     Setup data storage, data processing and      data visualizing tools, by :     Assessing the pains and needs of the teams;   Benchmarking the open source and private       solutions;   Assessing the security, price and       reliability of data architecture;Following the development the evolution of       technologies on the topic;   Forecasting the usage of the tools;   Tracking the cost of the tools.     Participate in:       Tech stack selection;   Discussions with tech partners;   Training of software and underwriting       teams;   Support and debug of internal users.    TECH STACK üñ•Ô∏è Cloud provider: GCP Code versioning tool: Git + Gitlab OS: Linux Container: Docker Container orchestrator: Kubernetes Website architecture: LAMP Code base: Python Notification tool: Slack  DATA STACK üóÑÔ∏è Types: images, timeseries,  Storage: GCP bucket Version: DVC (roll out in progress) Pipeline: Airflow (PoC stage) Data base: to be setup depending on the use cases In our project, data is collected by sensors (satellite, weather station, IoT). We don‚Äôt work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation ‚Ä¶).  ABOUT YOU¬†EXPERIENCE & QUALIFICATIONS üíªüñ•Ô∏è‚Äçüíª[Hard skills]  Knowledge of the tech stack or equivalent tools;  Experience converting      python code to efficient data engineering tools (eg: spark);  Experience with Docker;  Experience with a cloud      provider (GCP, AWS or azure);  Experience automating a      CI/CD pipeline;  Good knowledge in English      and fluency in French. [Soft skills]  Desire to train junior developers and explain CI/CD and cloud      tools;  Desire to suggest      improvements to the architecture. [Nice-to-have] Experience working data science project or scientific code;  Experience with Kubernetes; Experience in HPC; Contribution to an open source project.   MINDSET üí• Strong interest with climate issue (it‚Äôs not a hoax, many people suffer from it); Being comfortable to work alongside corporate insurers (some still wear suits üëî); You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline); Strong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed); Rigorous, creative and meticulous mind (we handle large insurance, we take our time); Strong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools); Eagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è).WHY JOIN DESCARTES UNDERWRITING?Opportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence; Commitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ;Work in a collaborative & professional environment ;Be part of an international team, passionate about diversity ;Join a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks;A competitive salary, bonus and benefits;You can benefit from a punctual home office days.At Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.With equal skills, all our positions are open to people with disabilities.RECRUITMENT PROCESS Step 1: Call and HR Interview with our Talent Recruiter Step 2: Technical project submitted via GitHub Step 3: Technical interview  Step 4: Manager interview Step 5: Final round interview with the team  (Candidates can opt to have the manager interview before the technical project and interview) "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-03", "sector": "Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech", "company_size": "170", "creation_date": "2018", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "24", "proportion_male": null, "programming_languages": ["pythonnotification", "python", "python"], "databases": ["bigqueryin"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "azure);ci/cd", "gcpcode", "(gcp,"], "dev_tools": ["git", "gitlabos:", "dockercontainer", "docker;production"], "OS": ["linuxcontainer:"], "big_data_and_processing": null, "automation_and_orchestration": ["kubernetescode", "airflow"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["dockercontainer", "docker;production", "kubernetescode"], "collaboration": ["slackdata", "teams;benchmarking", "teams;support", "teams;well", "teams", "teams"], "skills": ["cloud", "üñ•Ô∏ècloud", "cloud", "cloud", "ci/cd", "azure);ci/cd", "ci/cd"], "raw_description": "Descriptif du posteABOUT DESCARTES UNDERWRITINGDescartes was born out of the conviction that the ever-increasing complexity of risks faced by corporations, governments and vulnerable communities calls for a renewed approach in insurance. Our team brings together industry veterans from the most renowned institutions (AXA, SCOR, Swiss Re, Marsh, Aon, ...) and scientists on top of their field to bring underwriting excellence. After 5 years of existence, Descartes has secured a leading position in parametric insurance for weather and climate-related risks utilizing machine learning, real-time monitoring from satellite imagery & IoT. After a successful Series B raise of $120M USD, we launched Descartes Insurance, a 'full stack' insurer licensed to underwrite risk by the French regulator ACPR. With a growing corporate client base (350+ and counting), our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. Descartes is trusted by a panel of A-rated (re)insurers to carry out its activities.ABOUT YOUR ROLE¬†Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenarios to make a climate risk assessment. You will have to take initiative and assess the viability of proof-of-concept projects.You will have to work with data scientists and software engineers to run and develop our models. You will be working alongside DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.üîî KEY MISSIONS üîîDesign, setup, and maintain:Data pipelines and associated datalakes;Connections to external and internal APIs;Associated CI/CD and release pipelines;Notification tools to inform the team of the status of the operations.Propose and setup data storage, data processing and data visualizing tools including:Assessing the pains and needs of the teams;Benchmarking different solutions;Assessing the security, price and reliability of data architecture;Following the development the evolution of technologies on the topic;Forecasting and tracking cloud spend.Participate in:Tech stack evolution;Discussions with tech partners;Training of other tech teams;Support and debug of internal users.TECH STACK üñ•Ô∏èCloud provider: GCPCode versioning tool: Git + GitlabOS: LinuxContainer: DockerContainer orchestrator: KubernetesCode base: PythonNotification tool: SlackDATA STACK Types: images, time series, data frames, etc.Pipeline orchestrator: Apache Airflow Data stores:  Cloud SQL, FireStore, BigQueryIn our project, data is collected by sensors (satellite, weather station, IoT). We don‚Äôt work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation ‚Ä¶).¬†ABOUT YOU¬†EXPERIENCE & QUALIFICATIONS üíªüñ•Ô∏è[Hard skills]Knowledge of the tech stack and demonstrated proficiency in production environments;Minimum 3 years‚Äô experience in Python object-oriented programming;Experience converting Python code to efficient data engineering tools;Production experience with Docker;Production experience with a cloud provider (GCP, AWS or Azure);CI/CD and release pipelines;Good knowledge in English and fluency in French. [Soft skills]Excellent communication skills, in both formal and informal settings, and in English and French;Contribute to a rigorous data engineering culture;Propagate Data Engineer best practices to other tech teams;Well versed in Agile;Mentoring junior engineers. [Nice-to-have]Prior experience working in data science or scientific computing projects;Working knowledge of DevOps;Contribution to an open source project. MINDSET üí•Strong interest with climate issue (it‚Äôs not a hoax, many people suffer from it);Being comfortable to work alongside corporate insurers (some still wear suits üëî);You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline);Strong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed);Rigorous, creative and meticulous mind (we handle large insurance, we take our time);Strong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools);Eagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è). WHY JOIN DESCARTES UNDERWRITING?Opportunity to work and learn with teams from the most prestigious schools and research labs in the world, allowing you to progress towards technical excellence;¬†Commitment from Descartes to its staff of continued learning and development (think annual seminars, training etc.) ; Work in a collaborative & professional environment ;Be part of an international team, passionate about diversity ;Join a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks;A competitive salary, bonus and benefits;You can benefit from a punctual home office days.¬†At Descartes Underwriting, we cherish value of diversity whatever it may be. We are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences. With equal skills, all our positions are open to people with disabilities."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Environnement / D√©veloppement durable, Transports maritime et routier, Mobilit√©", "company_size": "68100", "creation_date": "2001", "address": null, "average_age_of_employees": null, "turnover_in_millions": "7 milliards d'euros", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "java,"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["(tableau,"], "statistics": null, "cloud_computing": ["azure", "(azure,", "azure)"], "dev_tools": null, "OS": ["linux", "windows"], "big_data_and_processing": null, "automation_and_orchestration": ["ansiblema√Ætriser"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste¬†Data Ing√©nieur H/F¬†Syst√®mes d'Information¬†¬†Keolis est un des leaders mondiaux de la mobilit√© partag√©e et le partenaire privil√©gi√© des Autorit√©s Organisatrices de Mobilit√©. Ensemble, nous co-construisons des solutions de transport en commun s√ªres, performantes et durables qui renforcent l'attractivit√© des territoires.En 2023, le Groupe a connu une croissance significative avec un chiffre d'affaires de 7 milliards d'euros. Pr√©sent dans 13 pays, nos 68 100 collaborateurs ≈ìuvrent chaque jour √† la proposition d'une alternative cr√©dible √† la voiture individuelle et ainsi √† l'acc√©l√©ration de la transition √©cologique.Notre ambition est d'imaginer et de d√©ployer des mobilit√©s s√ªres et durables, au service de chaque territoire, pour une meilleure qualit√© de vie de tous et de chacun.¬†¬†Filiale du groupe Keolis (premier op√©rateur priv√© de transport public de voyageurs en France), Keolis Bordeaux M√©tropole Mobilit√©s est d√©l√©gataire de service public pour le compte de Bordeaux M√©tropole qui lui confie l'exploitation du r√©seau de transport en commun ainsi que la maintenance du mat√©riel et des infrastructures. Les 2800 collaborateurs contribuent chaque jour √† garantir la qualit√© de fiabilit√©, de s√©curit√© et de confort sur le r√©seau TBM. Le professionnalisme de chacun est d√©terminant dans le d√©veloppement du transport public urbain.Rejoindre Keolis Bordeaux M√©tropole Mobilit√©s, c‚Äôest rejoindre une entreprise engag√©e en RSE et exercer au quotidien une activit√© professionnelle porteuse de sens et contribuer √† la r√©alisation d‚Äôune mission de service public inscrite dans l‚Äôactivit√© et les valeurs du groupe.¬†¬†Missions du Data Ing√©nieur H/F:¬†¬†Pr√©pare et met en service le socle mat√©riel et logiciel qui permet d‚Äôex√©cuter des traitements informatiques optimis√©s :Identifie les besoins des m√©tiers et d√©finit les donn√©es √† collecter depuis les SI de l‚ÄôentrepriseInt√©gration de volumes de donn√©es √† partir de diverses sourcesNormalisation, nettoyage et enrichissement des donn√©esImpl√©mente la collecte de donn√©es : BDD, API, FTP ou autresOrganise et met en place les r√®gles sur la s√©curisation de la donn√©e en lien avec les DPO et le RSSIGarant de la structuration, la segmentation des gisements et des r√©f√©rentiels de donn√©esOrganise et met en place les r√®gles de distribution de la donn√©eParticipe √† la conception de plateformes permettant de traiter les enjeux DataMet en place l‚Äôarchitecture des plateformes et des donn√©es et assure sa maintenanceD√©veloppement et maintient de pipelines de donn√©es pour la m√©diation de donn√©es ¬†Activit√©s compl√©mentaires :¬†Assure la veille technique sur son p√©rim√®treParticipe aux comit√©s de gouvernance Data¬†Contribue √† l‚Äô√©volution des pratiques dans son domaine de comp√©tences¬†Comp√©tences techniques¬† :Int√©gration de donn√©es (ELT, MDM, ESB, Micro-services) dans des syst√®mes d‚Äôinformations complexes D√©veloppement / programmation : Python, java, RUtilisation de bases de donn√©es SQL ou NoSQLBonne connaissance des outils de data visualisation (Tableau, Power BI)Environnement Azure (Azure, ADF, Datafactory‚Ä¶) et mixte Windows / Linux Debian avec AnsibleMa√Ætriser l‚Äôanglais¬†Savoir-√™tres attendus :¬†Sens du service, agir en partenaire des m√©tiersCapacit√© √† collecter les besoins m√©tiersCapacit√© √† travailler en √©quipe, et en transverse au sein de l‚ÄôentrepriseEsprit de synth√®seAutonomeRigueur¬†Rattachement :¬†Sous la responsabilit√© directe du Responsable data¬†¬†Liaisons fonctionnelles :¬†¬†¬†Interne :Data AnalystUrbaniste/ArchitecteResponsable P√¥le Fili√®res M√©tiersResponsable P√¥le Op√©rationsRSSIDPOServices m√©tiers : R√©f√©rents SI et/ou r√©f√©rents data et op√©rationnels¬†¬†¬†¬†¬†¬†¬†¬† Externe¬†: Prestataires et sous-traitantsPartenaires institutionnels : Keolis si√®ge, Bordeaux M√©tropole notamment¬†¬†Salaires, avantages et Conditions de travail :¬†Contrat : CDI, Temps plein, du lundi au vendredi.Statut : Cadre¬†Salaire : 3846‚Ç¨ brut /mois sur 13 mois, soit¬† 50 000‚Ç¨ brut annuelPrime sur objectifsCSE AttractifMutuelle et pr√©voyanceAcc√©s au restaurant d'entreprise, carte de transport.CSE ActifProfil :Formation Bac+5, type Ecole d‚Äôing√©nieur ou √©quivalent3 ans d‚Äôexp√©rience minimum sur un poste d‚Äôing√©nieur data, en ESN ou en client final (orient√© azure)¬†Information compl√©mentaire :Si votre poste est en lien direct avec la s√©curit√© des personnes et des biens vous serez susceptible de faire l'objet d'une enqu√™te administrative.D√©cret n¬∞2017-757 du 3 mai 2017 et¬†n¬∞2022-770 du 2 mai 2022."}
{"job_title": null, "contract_type": "Stage", "salary": "Non sp√©cifi√©", "company": null, "location": "Gennevilliers", "remote": "T√©l√©travail non autoris√©", "experience": "< 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "Pharmaceutique / Biotechnologique, IT / Digital, Sant√©", "company_size": "2600", "creation_date": "1945", "address": null, "average_age_of_employees": "40", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["azure"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePr√©sentation STAGO¬†:Choisir Stago c‚Äôest contribuer √† la sant√©, dans une entreprise √† taille humaine et √† dimension internationale.¬†R√©f√©rence mondiale en diagnostic in vitro et partenaire privil√©gi√© des laboratoires de biologie m√©dicale, Stago con√ßoit, fabrique et commercialise, √† travers le monde, la plus large gamme de r√©actifs et d‚Äôinstruments d‚Äôanalyses en h√©mostase.Venez participer √† une aventure unique au sein d‚Äôune soci√©t√© reconnue pour son expertise et avec des valeurs humaines fortes¬†!A la recherche de nouveaux d√©fis¬†?Vous souhaitez contribuer √† la performance de nos applications logicielles en apportant votre expertise m√©tier ?Ne cherchez plus, nous avons un stage pour vous !¬†Descriptif du poste¬†:Nous recherchons pour notre direction R&D un futur Ing√©nieur Data H/F pour un stage de 4 √† 6 moisInt√©gr√© dans une √©quipe de data scientists, vous travaillerez sur des projets de data engineering et de data science avec la plateforme Azure¬†Vous assurerez les missions suivantes :Cr√©er des mod√®les de donn√©es et des tables afin d‚Äôexploiter de nouvelles donn√©esoptimiser les flux de donn√©es existantsparticiper aux activit√©s de l‚Äô√©quipe et r√©aliser des analyses cibl√©es selon les besoins"}
{"job_title": null, "contract_type": "CDI", "salary": "65K √† 75K¬†‚Ç¨", "company": null, "location": "Lyon", "remote": "T√©l√©travail fr√©quent", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "FinTech / InsurTech", "company_size": "266", "creation_date": "2016", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": ["python,", "scalable.nous", "scalabilit√©"], "databases": ["postgresql,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNotre √©quipe :En raison de notre forte croissance, nous avons la volont√© de mettre en place une stack robuste, performante et scalable.Nous avons besoin de mieux utiliser les donn√©es en pr√©sence, et c‚Äôest une super opportunit√© pour toi : cela te permettra de cr√©er de la valeur pour l‚Äôentreprise !Aujourd‚Äôhui, l‚Äô√©quipe Data est compos√©e de 4 personnes, dans une √©quipe Tech globale de 45 personnes. Notre objectif √† terme est d‚ÄôavoirUn p√¥le IA avec 2 AI EngineersUn p√¥le BI avec un Lead Data Engineer (toi) et 3 Data EngineersTu rejoindras :Benoit, Lead Data EngineerElo√Øse, Data EngineerMaud, Data EngineerMaxime, Data ScientistLes missions de l‚Äô√©quipeFournir des donn√©es up-to-date, utiles et fiables aux √©quipes Business de Indy pour leur permettre d‚Äôanalyser et piloter leur activit√©.Am√©liorer notre syst√®me de cat√©gorisation automatique des transactions bancaires.L‚Äôun de nos challenges du moment est que la BI soit la source de v√©rit√© et alimente directement les outils des √©quipes Customer Support, Sales et Marketing.Avec la croissance de notre base utilisateurs, notre volume de donn√©es augmente. Nous en avons plus √† r√©cup√©rer, √† traiter, √† stocker‚Ä¶ Tu vas pouvoir intervenir sur les pipelines de donn√©es pour am√©liorer leur robustesse et la vitesse de traitement. De plus, tu participeras √† l‚Äô√©volution de notre stack technique pour relever ces challenges. En d‚Äôautres termes, la scalabilit√© de nos outils et de notre stack data !Notre stack actuelle se compose de: PostgreSQL, Airbyte, DBT, Metabase, Dagster, Census, Python, Heroku, AWS ECS, DataDog.Tu auras pour missions de :Organiser le fonctionnement de l‚Äô√©quipe Data - BI pour d√©velopper une BI utile et disponible √† tous les indiesManager une √©quipe de 3 Data EngineerParticiper aux d√©veloppements, aux choix techniques, et aux t√¢ches de support de l‚Äô√©quipe√ätre l‚Äôinterface de l‚Äô√©quipe vis √† vis des autres √©quipes et d√©partementsDonner de la visibilit√© sur les r√©alisations de l‚Äô√©quipe et leur avancementLivrer la roadmap n√©cessaire √† la bonne marche d‚ÄôIndy et son d√©veloppementGarantir la stabilit√© et le d√©veloppement de la plateforme en veillant √† am√©liorer les pratiques et faisant √©voluer la stack technique"}
{"job_title": null, "contract_type": "Stage(6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Montpellier", "remote": "T√©l√©travail fr√©quent", "experience": "< 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "IT / Digital", "company_size": "49000", "creation_date": "1997", "address": null, "average_age_of_employees": null, "turnover_in_millions": "5,6 milliards ‚Ç¨", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteLe poste en quelques mots :Au sein de l‚Äô√©quipe du P√¥le data de Montpellier, vous participer aux activit√©s d‚Äôint√©gration et de traitement de la donn√©e sur nos projets IA et Big Data.Vous participerez aux travaux pour nos clients sur la mise en place d‚Äôoutil allant du prototype √† la solution industrialis√©.Ce que vous allez faire si vous nous rejoignez : La conception, le d√©veloppement et optimisation de flux de donn√©es. La proposition et l‚Äôimpl√©mentation d‚Äôapproches d‚Äôextraction, de traitement et d‚Äôanalyse de l‚Äôinformation. Le d√©ploiement, le test et la maintenance des r√©alisations. En compl√©ment de ces travaux, vous‚ÄØ:¬† La conception et d√©veloppement des briques logicielles d‚Äôimpl√©mentation des briques IA et de gestion de flux de donn√©. Participez aux diff√©rents rituels de gestion de projet (Agile, ou cycle en V). R√©digez les documentations techniques. Assurez une veille technologique autours de la donn√©e et de son traitement. ¬†¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Cestas", "remote": "T√©l√©travail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "Logiciels, SaaS / Cloud Services", "company_size": "2500", "creation_date": "1973", "address": null, "average_age_of_employees": "43", "turnover_in_millions": "522 ", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python,", "java,", "scala", "kotlin,"], "databases": ["snowflake,"], "data_analyze": null, "big_data_tools": ["spark", "databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "azure,", "azure"], "dev_tools": ["docker,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker,"], "collaboration": null, "skills": ["cloud", "ci/cd"], "raw_description": "Descriptif du posteNotre √©quipe Data Foundation bas√©e √† Bordeaux/Cestas, recherche son/sa futur(e) Architecte data exp√©riment√©(e)¬†H/F en CDI.¬†Missions :¬†A ce titre, vous serez amen√©(e) √†¬†: D√©finir une vision et une strat√©gie globale pour le Datahub et les donn√©es en collaborant √©troitement avec les parties prenantes de l'entreprise afin de soutenir les objectifs m√©tier de Lectra.¬† √âlaborer des principes d'architecture des donn√©es, des guides et des mod√®les de conception pour orienter le d√©veloppement de solutions de donn√©es conformes aux normes √©tablies.¬† Promouvoir une culture ax√©e sur les donn√©es en sensibilisant aux avantages des donn√©es et en agissant en tant qu'√©vang√©liste de l'architecture des donn√©es au sein de l'organisation.¬† Contribuer √† la r√©alisation d'√©tudes exploratoires et pr√©senter les solutions propos√©es aux autres architectes de Lectra et au management d√©cisionnaire.¬† Favoriser le d√©veloppement des comp√©tences en architecture des donn√©es au sein de l'√©quipe Data et des autres √©quipes de Lectra.¬† Participer activement √† la conception, √† l'impl√©mentation, √† l'√©volution et √† la maintenance des Data Products de l'√©quipe Data Foundation avec un engagement envers l'excellence technique.¬† ¬†¬†Stack technique data:¬†  Cloud Microsoft Azure, AWS¬†¬†  ¬†  Snowflake, DBT, Spark Databricks, Azure Datalake, Apache Kafka, RabbitMQ, MongoDB, Airflow, K8S, Docker, Spring boot‚Ä¶¬†  ¬†  SQL, Kotlin, Python, Java, Scala¬†  ¬†  M√©thodologie‚ÄØagile, CI/CD¬†  ¬†¬†"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Rennes", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["(python", "javascript)"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef", "cheffe", "chefs"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["html,", "(statistiques,"], "raw_description": "Descriptif du poste      Vos missions en quelques mots    GROUPE RIFSEEP : 2  Vos activit√©s principales  Cette fiche de poste n'est pas contractuelle et peut √™tre soumise √† √©volution en fonction des r√©organisations internes et des besoins d√©finis par la hi√©rarchie.  Au sein d'une √©quipe intervenant dans le domaine de la lutte contre la cybercriminalit√©, vous aurez pour missions principales de :  ‚Ä¢  g√©rer, maintenir et documenter plusieurs bases de donn√©es (via l'importation de donn√©es externes en open data ou de donn√©es internes par exemple)  ‚Ä¢  apporter votre expertise pour l'exploration et l'analyse complexe de donn√©es au moyen de techniques vari√©es (statistiques, analyse de texte, analyse comportementale, g√©olocalisation)  ‚Ä¢  caract√©riser des donn√©es (qualit√©, richesse, contenu) en vue de leur int√©gration dans le syst√®me d'information cible du m√©tier  ‚Ä¢  concevoir l'architecture de base de donn√©es par le codage (python appr√©ci√©, html, javascript) et les technologies (ElasticSearch, SQL, no SQL)  ‚Ä¢  s'assurer de la qualit√© des donn√©es  ‚Ä¢  mettre en place une data warehouse (entrep√¥t de donn√©es)  ‚Ä¢  industrialiser le proc√©d√© pour les donn√©es les plus int√©ressantes  ‚Ä¢  produire des rapports et des repr√©sentations graphiques √† partir des donn√©es pertinentes  ‚Ä¢  synth√©tiser et traduire des informations pour faciliter la prise de d√©cision  ‚Ä¢  √©crire la documentation relative aux bases de donn√©es (r√®gles de gestion, dictionnaire des variables...)  Votre environnement professionnel  Activit√©s du service  L'Office anti-cybercriminalit√© est charg√© du d√©veloppement de la politique globale de lutte contre la cybercriminalit√© ainsi que de la d√©finition des strat√©gies √† mettre en ≈ìuvre dans les enqu√™tes et dans le domaine de la pr√©vention.  Le plateau technique d√©pend du p√¥le de l'appui op√©rationnel cyber situ√© √† Nanterre, en charge d'appuyer les investigations num√©riques de la police nationale. Ce p√¥le d√©veloppe une expertise de haut niveau dans les domaines de la recherche forensique, de l'OSINT, des investigations en crypto-monnaie, des enqu√™tes sous pseudonyme, du traitement des donn√©es de masse.  Le plateau technique de Rennes a pour objectif de d√©velopper l'activit√© de traitement de la donn√©e op√©rationnelle qui provient de multiples sources (proc√©dures judiciaires, CSIRT-PJ, flux commerciaux de CTI, OSINT, analyse de cryptomonnaie) et se pr√©sente sous de multiples formats. Elle a vocation √† √™tre analys√©e afin d'alimenter les enqu√™tes judiciaires de la sous-direction ainsi que le renseignement criminel cyber.  Composition et effectifs du service  L'OFAC est compos√© d'environ 180 personnels, policiers, gendarmes,  administratifs, techniques et scientifiques, agents contractuels, apprentis.  Le plateau technique est actuellement compos√© d'un officier et de 4 ing√©nieurs. L'objectif est d'obtenir un plateau compos√© d'un officier et de 14 ing√©nieurs.  Liaisons hi√©rarchiques  chef du plateau  cheffe du p√¥le de l'appui op√©rationnel cyber, et son adjointe  chefs de l'OFAC"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Nanterre", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": ["postgresql,", "postgresql)."], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableau", "tableau,", "tableaux"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef", "chef", "chefs"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["statistiques"], "raw_description": "Descriptif du poste      Vos missions en quelques mots    Groupe RIFSEEP : 2  Vos activit√©s principales :  Au sein de la section des statistiques et de l'informatique d√©cisionnel (SSID) renforce ses effectifs en vue de poursuivre le virage de la data.  Autonome et force de proposition, vous piloterez la mise en ≈ìuvre de projets d√©cisionnels pour la Police Nationale et la Gendarmerie Nationale. La t√¢che principale est de mettre √† disposition des donn√©es et des indicateurs issus d'applications sources ou de l'open data et de permettre leurs restitutions via des requ√™tes ou des documents graphiques type tableau de bord.  Les technologies utilis√©es sont vari√©es (SAP Webi, Tableau, Talend, PostgreSQL, SAP HANA) et r√©guli√®rement actualis√©es.  Vous serez int√©gr√© dans une √©quipe dynamique et votre activit√© sera rythm√©e par des sujets vari√©s (statistique de la d√©linquance, de l'activit√© des services, de la logistique, des finances, des ressources humaines ou encore de l'organisation) et souvent li√©s √† l'actualit√© (quantit√©s de stup√©fiants saisis, violences intra familliales, indicateurs de pr√©sence externe des forces de l'ordre,...).  Elle consistera notamment √† :  - initier les maitrises d'ouvrages aux principes de la BI et les assister dans l'expression de leur besoin ;  - sp√©cifier et concevoir les puits de donn√©es (indicateurs, dimensions,...) ;  - concevoir le processus d'extraction, de transformation et de chargement (ETL) des donn√©es dans les puits ;  - contr√¥ler la qualit√© des donn√©es ;  - piloter une √©quipe de d√©veloppement des puits de donn√©es ;  - g√©rer les incidents techniques en lien avec le service d'exploitation ;  - assister, au besoin, les ma√Ætrises d'ouvrage dans la mise en ≈ìuvre du reporting (cr√©ation des documents, tableaux de bord).  Profil recherch√© :  Le chef de projet devra avoir une exp√©rience dans le domaine de l'informatique d√©cisionnelle et ses principes. Il devra avoir des connaissances dans les technologies utilis√©es afin de pouvoir piloter des d√©veloppeurs sur la base des sp√©cifications produites (SAP BO, Talend, Hana, PostGreSQL).  Une exp√©rience d'AMOA serait un plus lors du recueil des besoins.  Votre environnement professionnel :  Activit√©s du service  L'Agence du Num√©rique des Forces de la S√©curit√© Int√©rieure (ANFSI) est charg√©e de concevoir, de piloter et de conduire les projet se syst√®mes d'information, de communication, de commandement et des moyens technologiques connexes d√©di√©s principalement aux utilisateurs et acteurs de la s√©curit√© int√©rieure.  Composition et effectifs du service  Vous serez int√©gr√© au sein d'une section √† l'effectif de 19 personnels dont 6 statuts militaire et 7 statuts civil.  Liaisons hi√©rarchiques  Chef de Section  Liaisons fonctionnelles  Vous serez √† la fois en contact avec les diverses directions de la Gendarmerie et de la Police (Police Judiciaire, S√©curit√© Publique,...) qui sont les MOA mais √©galement avec les chefs de projets techniques des applications sources de donn√©es. Vous pourrez √©galement √™tre"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "java,"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["git,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste      Vos missions en quelques mots    Groupe RIFSEEP : 3  Vous participerez √† l'int√©gration de donn√©es h√©t√©rog√®nes dans l'entrep√¥t de donn√©es DGSI, dans le respect des besoins m√©tiers et des contraintes de qualit√© et de s√©curit√©. Vous serez √©galement amen√© √† d√©velopper des utilitaires  Analyser les besoins m√©tier, identifier les meilleures solutions techniques et estimer les temps de d√©veloppement  D√©velopper, co-construire et faire √©voluer les solutions et applications m√©tiers  R√©aliser la recette et la mise en production  Assurer la maintenance √©volutive, adaptative et corrective  Respecter les m√©thodologies, bonnes pratiques et conventions en vigueur  R√©diger et maintenir la documentation technique  Respecter les plannings et les d√©lais  √ätre force de propositions  Assurer une veille technologique  Disposer d'un bon sens relationnel  Garantir une bonne communication  Connaissances techniques : Java, Python, Git, Symfony, ElasticSearch, MongoDB, Oracle  Votre environnement professionnel :  Ne peut √™tre communiqu√© en raison de la confidentialit√© des missions du service."}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Rennes", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["(python", "javascript)"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef", "cheffe", "chefs"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["html,", "(statistiques,"], "raw_description": "Descriptif du poste      Vos missions en quelques mots    GROUPE RIFSEEP : 2  Vos activit√©s principales  Cette fiche de poste n'est pas contractuelle et peut √™tre soumise √† √©volution en fonction des r√©organisations internes et des besoins d√©finis par la hi√©rarchie.  Au sein d'une √©quipe intervenant dans le domaine de la lutte contre la cybercriminalit√©, vous aurez pour missions principales de :  g√©rer, maintenir et documenter plusieurs bases de donn√©es (via l'importation de donn√©es externes en open data ou de donn√©es internes)  apporter votre expertise pour l'exploration et l'analyse complexe de donn√©es au moyen de techniques vari√©s (statistiques, analyse de texte, analyse comportementale, g√©olocalisation)  caract√©riser des donn√©es (qualit√©, richesse, contenu) en vue de leur int√©gration dans le syst√®me d'information cible du m√©tier  concevoir l'architecture de base de donn√©es par le codage (python appr√©ci√©, html, javascript) et les technologies (ElasticSearch, SQL, no SQL)  s'assurer de la qualit√© des donn√©es  mettre en place une data warehouse (entrep√¥t de donn√©es)  industrialiser le proc√©d√© pour les donn√©es les plus int√©ressantes  produire des rapports et des repr√©sentations graphiques  synth√©tiser et traduire des informations pour faciliter la prise de d√©cision  √©crire la documentation relative aux bases de donn√©es (r√®gles de gestion, dictionnaire des variables...)  Votre environnement professionnel  Activit√©s du service  L'OFAC est charg√© du d√©veloppement de la politique globale de lutte contre la cybercriminalit√© ainsi que de la d√©finition des strat√©gies √† mettre en ≈ìuvre dans les enqu√™tes et dans le domaine de la pr√©vention.  Le plateau technique d√©pend du p√¥le de l'appui op√©rationnel cyber situ√© √† Nanterre, en charge d'appuyer les investigations num√©riques de la police nationale. Ce p√¥le d√©veloppe une expertise de haut niveau dans les domaines de la recherche forensique, de l'OSINT, des investigations en crypto-monnaie, des enqu√™tes sous pseudonyme, du traitement des donn√©es de masse.  Le plateau technique de Rennes a pour objectif de d√©velopper l'activit√© de traitement de la donn√©e op√©rationnelle qui provient de multiples sources (proc√©dures judiciaires, CSIRT-PJ, flux commerciaux de CTI, OSINT, analyse de cryptomonnaie). Elle a vocation √† √™tre analys√©e afin d'alimenter les enqu√™tes judiciaires ainsi que le renseignement criminel cyber.  Composition et effectifs du service  L'OFAC est compos√© d'environ 180 personnels, policiers, gendarmes, administratifs, techniques et scientifiques, agents contractuels, apprentis.  Le plateau technique est actuellement compos√© d'un officier et de 4 ing√©nieurs. L'objectif est d'obtenir un plateau compos√© d'un officier et de 14 ing√©nieurs.  Liaisons hi√©rarchiques  chef du plateau  cheffe du p√¥le de l'appui op√©rationnel cyber, et son adjointe  chefs de l'OFAC  Liaisons fonctionnelles  services de l'OFAC  DNPJ, ANSSI, partenaires institutionnels, universit√©s, entreprises de logiciels, de cybers√©curit√©, CERTs, EUROPOL, INTERPOL, services de police √©trangers"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste      Vos missions en quelques mots    Groupe RIFSEEP : 3  Vos activit√©s principales :  Vous participerez √† l'int√©gration de donn√©es h√©t√©rog√®nes dans l'entrep√¥t de donn√©es DGSI, dans le respect des besoins m√©tiers et des contraintes de qualit√© et de s√©curit√©. Vous serez √©galement amen√© √† d√©velopper des utilitaires ;  Analyser les besoins m√©tier, identifier les meilleures solutions techniques et estimer les temps de d√©veloppement ;  D√©velopper, co-construire et faire √©voluer les solutions et applications m√©tiers ;  R√©aliser la recette et la mise en production ;  Assurer la maintenance √©volutive, adaptative et corrective ;  Respecter les m√©thodologies, bonnes pratiques et conventions en vigueur ;  R√©diger et maintenir la documentation technique ;  Respecter les plannings et les d√©lais ;  √ätre force de propositions ;  Assurer une veille technologique ;  Disposer d'un bon sens relationnel ;  Garantir une bonne communication.  Votre environnement professionnel :  Ne peut √™tre communiqu√© en raison de la confidentialit√© des missions du service."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail total", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Strat√©gie, Transformation, FinTech / InsurTech", "company_size": "65", "creation_date": "2018", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null, "programming_languages": ["python:", "python/nodejs,"], "databases": ["postgresql,"], "data_analyze": ["pandas", "pandas,", "numpydata"], "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "aws", "aws", "aws", "(awswrangler),", "aws"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": ["terraformles"], "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["terraformles"], "raw_description": "Descriptif du posteESG Connect a pour vocation de faciliter la validation, l‚Äôexploitation et l‚Äôenrichissement des donn√©es fournisseurs dans le contexte particulier de chacun de nos clients. Cela conduit notre √©quipe de d√©veloppeurs √† mettre en place des pipelines data, une librairie de calculs configurables par les utilisateurs et des features permettant d‚Äôencadrer les processus ESG.Les enjeux du posteLes missions de notre √©quipe :Concevoir les mod√®les de donn√©es des futures fonctionnalit√©s, pour assurer un stockage et une interrogation efficacesGarantir le bon fonctionnement des pipelines dataCr√©er des outils √† destination des autres √©quipes pour naviguer dans les donn√©esLes challenges de notre √©quipe :Travailler avec des volumes de donn√©es importants en limitant les temps de calculsOrganiser et rendre configurable des processus de calculs complexesComprendre les m√©thodologies ESG pour √™tre capable de les impl√©menterLes missionsAu sein du p√¥le Data de l‚Äô√©quipe Tech, et rattach√©.e directement au Data Lead, le.la futur.e Senior Data Software Engineer aura les missions suivantes :1. Participer √† la conception et √† l‚Äôarchitecture de la pipeline data en collaboration avec les diff√©rentes √©quipesD√©velopper et maintenir les pipelines data, avec AWS Lambda et AWS StepFunctionConcevoir l‚Äôarchitecture des pipelines et du stockage des donn√©esDiffuser la connaissance des technologies et les bonnes pratiques de code au sein de l‚Äô√©quipe Tech2. Participer √† la cr√©ation ou l‚Äôam√©lioration d‚Äôoutils internesD√©velopper des outils pour parcourir et v√©rifier les donn√©es√ätre √† l‚Äô√©coute des autres √©quipes sur leur usage des data3. Assurer la qualit√© de la plateformeTraiter les probl√©matiques de testabilit√© (grande variabilit√© dans les configurations utilisateurs, jeux de donn√©es hors production, etc)Participer aux revues de codeDiscuter des best practices avec les autres membres de l‚Äô√©quipeOverview de la stack technique :Pipeline Data: AWS Step Function, Lambda, ECSFrameworks python: AWS SDK for pandas (awswrangler), pandas, numpyData Base: S3 (parquet), PostgreSQL, DynamoDBBackend: Lambda Python/NodeJS, AWS API GatewayAuthentification: CognitoInfra as Code: TerraformLes + de l‚Äô√©quipeUne √©quipe d√©centralis√©e en full remoteUne forte expertise techniqueUne roadmap bas√©e sur des OKR"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Rennes", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Administration publique", "company_size": "30300", "creation_date": null, "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["(python", "javascript)"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef", "cheffe", "chefs"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["html,", "(statistiques,"], "raw_description": "Descriptif du poste      Vos missions en quelques mots    GROUPE RIFSEEP : 2  Vos activit√©s principales  Cette fiche de poste n'est pas contractuelle et peut √™tre soumise √† √©volution en fonction des r√©organisations internes et des besoins d√©finis par la hi√©rarchie.  Au sein d'une √©quipe intervenant dans le domaine de la lutte contre la cybercriminalit√©, vous aurez pour missions principales de :  ‚Ä¢  g√©rer, maintenir et documenter plusieurs bases de donn√©es (via l'importation de donn√©es externes en open data ou de donn√©es internes par exemple)  ‚Ä¢  apporter votre expertise pour l'exploration et l'analyse complexe de donn√©es au moyen de techniques vari√©es (statistiques, analyse de texte, analyse comportementale, g√©olocalisation)  ‚Ä¢  caract√©riser des donn√©es (qualit√©, richesse, contenu) en vue de leur int√©gration dans le syst√®me d'information cible du m√©tier  ‚Ä¢  concevoir l'architecture de base de donn√©es par le codage (python appr√©ci√©, html, javascript) et les technologies (ElasticSearch, SQL, no SQL)  ‚Ä¢  s'assurer de la qualit√© des donn√©es  ‚Ä¢  mettre en place une data warehouse (entrep√¥t de donn√©es)  ‚Ä¢  industrialiser le proc√©d√© pour les donn√©es les plus int√©ressantes  ‚Ä¢  produire des rapports et des repr√©sentations graphiques √† partir des donn√©es pertinentes  ‚Ä¢  synth√©tiser et traduire des informations pour faciliter la prise de d√©cision  ‚Ä¢  √©crire la documentation relative aux bases de donn√©es (r√®gles de gestion, dictionnaire des variables...)  Votre environnement professionnel  Activit√©s du service  L'Office anti-cybercriminalit√© est charg√© du d√©veloppement de la politique globale de lutte contre la cybercriminalit√© ainsi que de la d√©finition des strat√©gies √† mettre en ≈ìuvre dans les enqu√™tes et dans le domaine de la pr√©vention.  Le plateau technique d√©pend du p√¥le de l'appui op√©rationnel cyber situ√© √† Nanterre, en charge d'appuyer les investigations num√©riques de la police nationale. Ce p√¥le d√©veloppe une expertise de haut niveau dans les domaines de la recherche forensique, de l'OSINT, des investigations en crypto-monnaie, des enqu√™tes sous pseudonyme, du traitement des donn√©es de masse.  Le plateau technique de Rennes a pour objectif de d√©velopper l'activit√© de traitement de la donn√©e op√©rationnelle qui provient de multiples sources (proc√©dures judiciaires, CSIRT-PJ, flux commerciaux de CTI, OSINT, analyse de cryptomonnaie) et se pr√©sente sous de multiples formats. Elle a vocation √† √™tre analys√©e afin d'alimenter les enqu√™tes judiciaires de la sous-direction ainsi que le renseignement criminel cyber.  Composition et effectifs du service  L'OFAC est compos√© d'environ 180 personnels, policiers, gendarmes,  administratifs, techniques et scientifiques, agents contractuels, apprentis.  Le plateau technique est actuellement compos√© d'un officier et de 4 ing√©nieurs. L'objectif est d'obtenir un plateau compos√© d'un officier et de 14 ing√©nieurs.  Liaisons hi√©rarchiques  chef du plateau  cheffe du p√¥le de l'appui op√©rationnel cyber, et son adjointe  chefs de l'OFAC"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Boulogne-Billancourt", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-03", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "267", "creation_date": "2017", "address": null, "average_age_of_employees": "38", "turnover_in_millions": null, "proportion_female": "25", "proportion_male": null, "programming_languages": ["python,", "scala,"], "databases": ["(bigquery,"], "data_analyze": null, "big_data_tools": ["spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["gcp),", "gcp"], "dev_tools": ["digital", "git"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes,", "airflow,"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["kubernetes,"], "collaboration": null, "skills": ["ia/ml", "mlops", "cloud", "cloud", "cloud"], "raw_description": "Descriptif du posteContexte¬†:Fort de partenariats strat√©giques sign√©s avec Google Cloud (stack data full GCP), Renault Digital est √† la recherche d‚Äôun(e) Data Engineer au sein du P√¥le Architecture et Data pour mettre en place les fondations de la plateforme IA r√©pondant √† de nouveaux besoins m√©tiers.Vous collaborerez au jour le jour avec les √©quipes m√©tiers ainsi qu‚Äôavec les autres fonctions du P√¥le Architecture & Data (Data Analysts et Scientists, architectes, ‚Ä¶), exploitant des t√©raoctets de donn√©es (√©v√©nements en mode streaming, traitements en batch et temps r√©els et les appels aux APIs) afin entre autres d‚Äôalimenter des mod√®les de machine learning (segmentation clients, d√©tection automatique des pannes des v√©hicules, ‚Ä¶).Responsabilit√©s principales :Vous participez aux phases de framing, MVP et release des produits, services et APIs orient√©s IA ;Vous argumentez les choix d‚Äôarchitecture des projets et de la plateforme IA sur GCP ;Vous contribuez √† la valeur m√©tier des produits orient√©s IA s‚Äôappuyant sur le Datalake, en mettant en place des cha√Ænes bout en bout de traitement de la data, de l‚Äôingestion √† l‚Äôexposition d‚ÄôAPIs et √† la visualisation des donn√©es et des solutions IA/ML ;Vous √™tes garant(e) de la qualit√© des donn√©es transform√©es dans le Datalake, du bon fonctionnement des cha√Ænes de traitement et de l‚Äôoptimisation de l‚Äôutilisation des ressources cloud ;Vous d√©finissez et d√©veloppez les composants n√©cessaires pour orchestrer un syst√®me de machine learning en production suivant les best practice MLOPS (validation de donn√©es, preprocessing, apprentissage, analyse de mod√®le, d√©ploiement, monitoring, etc.)Vous proposez des standards d‚Äôarchitecture et de d√©veloppement ;Vous √™tes force de proposition, innovant(e) et bienveillant(e).¬†Environnement Technique :Google Cloud Platform (BigQuery, PubSub, Dataflow, Vertex AI), Airflow, Terraform, Spark, Scala, Python, Looker, Dataiku, Kubernetes, SQL, Git"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Application mobile, SaaS / Cloud Services, Ressources humaines", "company_size": "300", "creation_date": "2016", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null, "programming_languages": ["python,", "(python,", "python", "java,", "scala)tu"], "databases": ["snowflake"], "data_analyze": null, "big_data_tools": ["sparkdata"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["awsl'automatisation", "awsdatawarehouse", "aws", "(aws,", "gcp)une"], "dev_tools": ["github,", "docker,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes,", "airflowdata", "airflow"], "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": ["docker,", "kubernetes,"], "collaboration": null, "skills": [":cloud", "cloud", "airbyteci/cd:", "ci/cd)exp√©rience"], "raw_description": "Descriptif du posteMission :En rejoignant l‚Äô√©quipe data, tu auras pour mission principale de mettre en place les solutions techniques pour exploiter la donn√©e au sein de Skello.Cette donn√©e peut √™tre issue de plusieurs sources et √™tre destin√©e √† tous les m√©tiers de Skello que ce soit en termes d‚Äôanalyse BI, reporting ou de base √† nos features intelligentes.Plus concr√®tement tu seras responsable deLa collecte multi-source des donn√©es dans un data lake sur AWSL'automatisation et le traitement des flux de donn√©esGarantir l'int√©grit√© et la qualit√© des donn√©es du data lake et de la data warehouseMaintenir et am√©liorer l‚Äôarchitecture data  existanteParticiper & collaborer avec les data analysts et data scientists pour d√©finir des architectures simples et √©volutives en fonction des besoins.L'accessibilit√© des donn√©es pour qu‚Äôelles soient facilement exploitables par les data analysts et les data scientistsLa collaboration et la communication avec les √©quipes internes/externesNotre Modern Data Stack :Cloud provider: AWSDatawarehouse / Datalake: Snowflake / S3Orchestrateur: AirflowData Transformation: Python, DBT, SparkData Ingestion: Stitch, AirbyteCI/CD: Terraform, Github, AWS CodepipelineData Viz: LookerD√©p√™che toi de postuler siTu as un minimum de 4 ans d‚Äôexp√©rience en data engineeringTu ma√Ætrises le SQL ainsi qu‚Äôun langage de programmation (Python, Java, Scala)Tu as des comp√©tences en ing√©nierie (conception et qualit√© de code, tests, CI/CD)Exp√©rience dans la construction et la maintenance de pipelines de traitement donn√©esExp√©rience dans le d√©ploiement d‚Äôapplications dans un environnement cloud (AWS, GCP)Une exp√©rience avec Docker, Kubernetes, Python et Airflow est un plusD√©roulement des entretiens1er call de d√©couverte RH1er entretien m√©tier avec Edgar, lead data Un √©change technique avec un de nos data engineer Un dernier √©change avec Olivier, notre CTO"}
{"job_title": null, "contract_type": "CDD / Temporaire", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "Strat√©gie, Cybers√©curit√©, Administration publique", "company_size": "7200", "creation_date": "1982", "address": null, "average_age_of_employees": "43", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["ml", "ml"], "raw_description": "Descriptif du posteLa Direction G√©n√©rale de la S√©curit√© Ext√©rieure, DGSE, recrute un Data engineer (H/F).Le poste est situ√© √† Paris. La nationalit√© fran√ßaise est obligatoire.Domaine m√©tierSciences et TechnologiesVotre environnement de travailInt√©gr√© au sein d‚Äôune √©quipe pluridisciplinaire, vous participez √† la mise en place d‚Äôapplications bas√©es sur de l‚ÄôIA g√©n√©rative pour r√©pondre aux besoins des analystes en renseignement et de la direction technique et de l‚Äôinnovation. Vous d√©ployez des pipelines de traitement et des solutions de stockage en collaboration avec les autres Data Scientist, Data Engineer, ML Engineer, ML Ops et DevOps de l‚Äô√©quipe.Les applications d√©ploy√©es permettront aux analystes en renseignement d‚Äôexploiter plus rapidement de grandes quantit√©s de donn√©es et d‚Äôen extraire des informations pertinentes pour le renseignement op√©rationnel. Leurs m√©tiers ainsi que ceux de la direction technique et de l‚Äôinnovation s‚Äôen verront transform√©s. L‚Äô√©quipe dispose d‚Äôun excellent environnement pour adapter ces mod√®les aux besoins de la DGSE¬†: acc√®s √† d‚Äôimportants volumes de donn√©es pour l‚Äôapprentissage et mise √† disposition d‚Äôinfrastructures informatiques d√©di√©es (clusters GPU d‚Äôentrainement et d‚Äôinf√©rence), partenariats avec des laboratoires de recherche et startups.L‚Äô√©quipe m√®ne aussi des activit√©s de recherche afin de maintenir une connaissance de l‚Äô√©tat de l‚Äôart sur les th√©matiques d‚Äôint√©r√™t, ainsi que sur les technologies, approches et outils et propose de nouveaux cas d‚Äôusage pouvant avoir un fort impact sur le m√©tier.Vos missionsVous serez en charge de plusieurs activit√©s parmi les suivantes :prendre part √† la sp√©cification, √† l‚Äôimpl√©mentation et au maintien en condition op√©rationnelle des produits, services ou proc√©d√©s que l‚Äô√©quipe d√©veloppe et maintient,intervenir sur les phases de mise en production des outils et des pipelines de traitements de la donn√©e ainsi que des solutions de stockage (VectorDB, suite ELK, ‚Ä¶),d√©velopper le socle des applications (monitoring, t√©l√©m√©trie, ‚Ä¶),s‚Äôinformer des avanc√©es technologiques dans le domaine d‚Äôint√©r√™t de l‚Äô√©quipe, mais aussi et surtout¬†proposer des approches novatrices permettant de r√©pondre aux besoins du Service.Les plus de l‚ÄôoffreTechnologies √† la pointe ¬†¬†¬†¬†Missions uniques ¬†¬†¬†¬†Absence de routine  L‚ÄôIA g√©n√©rative transforme nos m√©tiers, nos usages, nos pratiques. Nos adversaires adoptent et tirent parti de ces nouveaux outils. Rejoignez-nous et participez √† cette r√©volution d‚Äôampleur en donnant un sens √† votre m√©tier¬†!"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-05-03", "sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, AdTech  / MarTech", "company_size": "43", "creation_date": "2014", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "54", "proportion_male": null, "programming_languages": ["#python", "scalabilit√©"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteConcevoir et impl√©menter de nouvelles fonctionnalit√©s #Python #micro-servicesOptimiser les cha√Ænes de traitement de donn√©es #batch et #tempsr√©el #dbt sur de grands volumes de data liveAccompagner nos data analysts pour la mise en place de dashboard #grafana sur de (tr√®s) grands volumes de donn√©es liveAssurer la disponibilit√©, la s√©curit√©, la maintenabilit√© et la scalabilit√© des diff√©rents services de la plateforme #sentry #prometheus√ätre garant des bonnes pratiques #unit-testing#great_expectations√ätre force de proposition (stack et projet) afin que notre solution ait le maximum d‚Äôimpact possible"}
{"job_title": null, "contract_type": "CDI", "salary": "55K √† 70K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail total", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Application mobile, SaaS / Cloud Services, Sant√©, Recrutement", "company_size": "200", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "22 lev√©s", "proportion_female": "45", "proportion_male": null, "programming_languages": ["reliability.scalability:"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams"], "skills": ["gymlibü§∏üèºüèãüèª"], "raw_description": "Descriptif du posteYou are joining the squad in charge of the Interoperability & Product Data subjects.¬†This squad has two main focuses:Create solution in view to provide¬†better interface between Hublo and¬†other tools & services used by our customers, in order¬†to improve their user experience and make their life easier.¬†Deliver data products and insight to leverage all the data we have in order to help our customers better understand and operate their replacement & hiring strategy.Your role:¬†As a seasoned Data Engineer, you bring your knowledge of data processing to help the squad build the relevant data stack in order to reach its goals with the right service level.You often communicate with our partners, in view to facilitate integrations. For this purpose, you are good at documenting your work and navigating technical documentation.How you‚Äôll make an impactArchitect and optimize: Craft robust data pipelines that ensure the timely and accurate availability of crucial data.Data quality: Implement rigorous data quality checks to reduce data discrepancies and enhance decision-making reliability.Scalability: Scale our data infrastructure to handle our growth as we expand our presence to 5,000+ healthcare facilities.Innovative solutions: Collaborate with cross-functional teams to introduce cutting-edge data technologies that have a real-world impact for our users.Team player: Foster a culture of collaboration, knowledge sharing, and mentorship within the interoperability squad and throughout Hublo.The experience we offerüéØ Impact-first mission: our focus on the healthcare sector offers a purpose-driven career.üí∂ Competitive compensation: a salary package ranging from 55K‚Ç¨ to 70K‚Ç¨ per year based on your experience.üë£ Professional growth: a dynamic, human-scale structure that values initiative and dedication.üå± Responsible work environment:¬†we are B-Corp certified, acknowledging our commitment to continuously grow and improve as an environmentally and socially responsible company.üóº Dynamic locations: our vibrant office on Rue de Paradis provides an inspiring setting. You‚Äôll also have a unique opportunity to work in our Cologne office in Germany.üè° Hybrid work policy: flexible work arrangement‚Äîup to 10 remote days a month, or full remote.ü§≤ Strong onboarding: a comprehensive program, guiding you through your initial weeks at Hublo.üí™ Team cohesion: build strong connections with colleagues through regular team events and an annual seminar, ensuring a connected and collaborative work environment.We also care about your well-being with tangible perks:‚õëÔ∏è Alan healthcare insurance: online insurance, 50% of it paid by Hubloü•ó A Swile Card: Providing you with access to ‚Ç¨11/day in meal vouchers, 50% covered by the company üç±üèãÔ∏è‚Äç‚ôÇÔ∏è Access to a variety of sports activities through our partner Gymlibü§∏üèºüèãüèª"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-03", "sector": "Application mobile, SaaS / Cloud Services", "company_size": "100", "creation_date": "2019", "address": null, "average_age_of_employees": "25", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null, "programming_languages": ["scalability,", "scalability"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud"], "raw_description": "Descriptif du posteJob DescriptionWe are seeking a talented and experienced Full Stack Data Engineer to join our dynamic tech team based in Paris. As a Full Stack Data Engineer, you will play a crucial role in enhancing our data platform and driving innovation through data engineering solutions.The primary focus of this position is data engineering, encompassing tasks such as building, optimizing, and maintaining our data platform. You will be responsible for making continuous improvements to our data infrastructure to ensure its reliability, scalability, and performance. As an integral part of the data team, you will collaborate closely with team members to address various data-related challenges and opportunities. This may involve tasks ranging from designing and implementing data pipelines to conducting in-depth data analysis to extract actionable insights.The role will focus on:Build and maintain bsport‚Äôs data architectureEnsure the sustainability and scalability of the diverse components by leveraging bsport‚Äôs cloud provider services and adhering to all DevOps best practices"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": "> 3", "education_level": null, "publication_date": "2024-05-03", "sector": "Application mobile, Banque", "company_size": "220", "creation_date": "2013", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams"], "skills": ["cloud"], "raw_description": "Descriptif du posteCreated in 2013, Lydia quickly became the reference for payment between friends. The French fintech has gained great notoriety for this feature and now has more than 7 million users.In recent years, Lydia has developed other services - pot, current account, common account, savings, credit, investment... to become the daily and complete payment application for millions of French people.With 250 employees based in Paris, Nantes, Bordeaux and Lyon, Lydia has set itself the task of changing the codes of the bank by offering all the essential services to manage your money on a daily basis through a simple, accessible and enjoyable customer experience.We are looking for an Analytics Engineer to join the Customer Knowledge and Access team. This team is in charge of making access to Lydia as frictionless as possible thanks to a good customer knowledge.In this team, you will be the data referent, responsible for everything from data ingestion to data analysis, all while improving and maintaining the Data Warehouse.In your daily work, you will be working closely with a diverse team of talents: back-end, Front-end and mobile developers, backend, product owner, operation managers, etc.You will also have the opportunity to contribute to the Data Engineering story : A transverse team of 3 data engineers dedicated to improve our tooling, improve processes, etc. All to enable you to meet your goals.What you will do:Deep dive into the data model of our Data warehouse, help your team answer various operational and product questions;Proactively improve the Data warehouse's data model to build and centralize customer knowledge insights in one place;Serve those insights to various data clients in offline and production contexts.Examples:Push information to the other verticals to offer a personalized and humanized experience to our customers;Improve our customer segmentation to better target our commercial actions;Improve user data remediation;Be in charge of the regulatory reportings in line with Customer Knowledge;Collaborate with backend and mobile teams to ensure that new projects integrate well within our data ecosystem.You are in the right place if:You have a MSc in computer science or related fields from an engineering school;You have had an experience (internship or full-time) in an analytical position (data engineer, data analyst, software engineer);You are willing to help end-users in their analytical journey;You are willing to code in python and SQL with high quality coding standards;You have between 0 and 3 years experience;You are curious and autonomous;You are fluent in English, both orally and in writing.Nice to have:Knowledge of dbt;Knowledge of Google Cloud Platform;A previous experience in a customer knowledge related field.Recruitment Process:- Initial interview by phone with the Recruitment Team;- Technical Case Study;- First round of interviews at Lydia with the Vertical Lead;- Second round of interviews with members of our Data team.At Lydia, we believe that diversity is a strength. Diversity is part of our culture and identity. We want to create an inclusive culture where all forms of diversity are seen as a real value to the company. Lydia is therefore proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, colour, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, physical characteristics (size, weight ... ), age, status as an individual with a disability, genetic information, or other applicable legally protected characteristics."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-02", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travail :Sous la supervision d'un Chef de Projet, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l'occasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.Votre r√¥le et vos missions :Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es¬†;Vous vous assurez¬†que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles¬†;Vous d√©finissez¬†le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez¬†une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins¬†;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.¬†Informations suppl√©mentairesCe que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy..La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": "> 5", "education_level": null, "publication_date": "2024-05-02", "sector": "IT / Digital, Organisation / Management, Transformation", "company_size": null, "creation_date": "1998", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["mlops"], "raw_description": "Descriptif du posteVous faites partie de celles et ceux qui pensent que m√™me avec plusieurs ann√©es d‚Äôexp√©rience, on continue √† apprendre‚ÄØ? Alors, nous sommes sur la m√™me longueur d'onde ! Et si on en parlait ?Au sein de l‚ÄôAtelier Data&AI, on retrouve des communaut√©s de pratique organis√©es par tribus. L‚Äôid√©e, c‚Äôest de se retrouver et de partager des expertises communes, de d√©velopper ses comp√©tences en √©quipes √† taille humaine. Vous aurez donc pour missions de faire du conseil, du delivery et de la R&D.√ätre MLOps Engineer Senior chez OCTO, c‚Äôest :¬†1- Faire du conseil autant que du delivery : accompagner nos clients dans la mise en ≈ìuvre de solutions autour de la gestion et transformation de leur Data. Participer au d√©veloppement agile et √† l‚Äôimpl√©mentation d‚Äôapplications dans le respect des bonnes pratiques. Et bien s√ªr, qui dit conseil, dit convictions : proposer la solution la plus adapt√©e, c‚Äôest aussi savoir et oser challenger nos clients (et c‚Äôest dans notre ADN !)¬†2- Participer activement √† la R&D ‚ÄúData & IA‚Äù : au programme, veille technologique & bonnes pratiques. Quelques sujets ‚Äúchauds‚Äù du moment ?¬† LLMOps, TOIL, d√©ploiement,¬† monitoring & observabilit√© des mod√®les.¬†3- Participer aux r√©ponses aux appels d‚Äôoffres et avant-ventes4- Former & mentorer : le partage de connaissances et la mont√©e en comp√©tences des collaborateurs vous importent ? Nous sommes convaincus et pr√¥nons haut et fort la valeur de transmission. Mentoring et gestion de votre carri√®re seront donc √† l‚Äôhonneur. Et oui, chez OCTO le savoir n‚Äôest pas chasse gard√©e !¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-02", "sector": "FinTech / InsurTech, SaaS / Cloud Services", "company_size": "1400", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "44", "proportion_male": null, "programming_languages": ["python,"], "databases": ["postgresql,", "snowflake,"], "data_analyze": null, "big_data_tools": ["spark,", "flink.ü§î"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,"], "dev_tools": ["digitale"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes,", "airflow", "(airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["kubernetes,"], "collaboration": ["teams:", "teams,", "teams.", "teams.‚Ä¢"], "skills": ["seamlessly"], "raw_description": "Descriptif du posteOur mission? Making day-to-day banking easier for SMEs and freelancers thanks to an online business account that's combined with invoicing, bookkeeping and spend management tools. Thanks to its innovative product, highly reactive 24/7 customer support and clear pricing, Qonto has become the leader in its market.Our journey: Founded by Alexandre¬†and¬†Steve in July 2017, Qonto has rapidly gained trust, serving over 450,000 customers. Thanks to our wonderful team of 1,400+ Qontoers, we also made it to the LinkedIn Top Companies French ranking!Our values:Customer focus | Prioritize customers in everything you doOwnership | Own your part, get things doneTeamwork | Make (team)work easyMastery | Continuously raise the barIntegrity | Always do what‚Äôs right, and respect peopleOur beliefs: At Qonto, we're committed to fostering a welcoming environment where everyone can thrive. We prioritize evaluating applicants based solely on skills and potential, ensuring diversity with 50% international team members, 44% women, and 20% parents. Join us in building a workplace that celebrates diversity and individuality.Discover the steps we took to create a discrimination-free hiring process.Qonto has grown a 60+ data team with Data Engineers, BI, and Data Scientists working together to deliver great dashboards, reports, and data products.The data platform covers three key functions:¬†governance, ingestion, and data modeling, providing high-quality and available data to all Qontoers and to all data teams: BI, DS-Analytics, and Data Products.There are 16 engineers in the data platform team divided into data engineers and analytics engineers.üë©‚Äçüíªüßë‚Äçüíª As a Lead Data Engineer at Qonto, you will:‚Ä¢ Coach and grow your team of 5 data engineers, fostering a culture of technical excellence and growth.‚Ä¢ Lead the data engineering roadmap, ensuring project deliverables align with business objectives and timelines.‚Ä¢ Assume a people leadership role and bring technical vision to your team, map and set up data governance, ensure all data pipelines provide high-quality and fresh data to all Qontoers, and maintain a performant data model.‚Ä¢ Scale our Airflow monolith by splitting it into a module approach‚Ä¢ Create real-time data products, crafting a streaming platform that leverages innovative technical solutions.‚Ä¢ Simplify and automate Data ingestion for Qonto.‚Ä¢ Decrease data ingestion incidents by collaborating with cross-functional teams, increasing data documentation and discoverability.üõ† Tech StackThe team uses Python, SQL, and state-of-the-art infrastructure, encompassing Kubernetes, AWS, PostgreSQL, Snowflake, Kafka, Apache, Flink.ü§î What you can expect‚Ä¢ Join Qonto who is¬†winning SME banking in Europe. Qonto is on track to power one million SMEs in 2025.‚Ä¢ Technological Investment: Qonto invests a lot in technology, to stay ahead in this field and in constant innovation.‚Ä¢ Growth and Leadership Development: grow as a manager, improving your management gestures and methods.‚Ä¢ Impactful Work: have a direct impact in building a centralized and self-service real-time data platform at scale to be used by hundreds of users daily.‚Ä¢ Empower to seamlessly channel daily terabytes of data throughout the organization with resilience.ü§ù About your future manager:Your future manager, David (Head of Data Platform), brings a wealth of experience in data analytics and a proven track record of leading high-performing teams. David is deeply committed to nurturing talent and fostering an environment where initiative and innovation thrive. He has a strong international career with multiple software and data engineering experiences. Before joining Qonto in January 2022, he was the CTO of several startups in the sports & video game industries.üèÖAbout You‚Ä¢ People Management: You have strong leadership experience, managing data engineers, software engineers, or Analytics Engineers.‚Ä¢ Mastery:¬†You are familiar with data pipeline tools (airflow, dbt, etc.), stream-processing platforms (Kafka, Spark, Flow) modern data architectures, and data governance processes.‚Ä¢ Leadership: You are a natural leader with the ability to influence and drive initiatives across teams.‚Ä¢ Simplicity and quality: You prefer simple solutions and are obsessed with quality‚Ä¢ Languages:¬†You are fluent in English. French is a plus.At Qonto we understand that true diversity isn't just about ticking boxes on a hiring checklist. Apply regardless of the boxes you tick! Who knows? You may have the missing piece of the puzzle we've been searching for all along.üéÅ PerksA tailor-made and dynamic career track. An inclusive work environment. And so much more to help you succeed.- Offices in Paris, Berlin, Milan, Barcelona, and Belgrade;- Tailor-made remote work policy depending on the job you apply for and where you live;- Competitive salary package;- A¬†meal voucher;- Public transportation reimbursement (part or global);- A great health insurance (depending on the country);- Employee well-being initiatives: access to Moka Care¬†to take care of your mental health and great offers for sports and wellness activities;- A progressive disability, and parenthood policy as part of our commitment to the¬†Parental Act¬†(1 in 6 of Qonto employees is a parent!) and childcare benefits with selected partners;- Monthly team events.üí™ Our hiring process:- Interviews with your Talent Acquisition Manager and future managers- A remote exercise to demonstrate your skills and give you a taste of what working at Qonto could be likeWe will send you an interview guide so you can best prepare yourself.On average, our process lasts 20 working days and offers usually follow within 48 hours ü§ûTo learn more about us:Qonto's Blog¬†|¬†Les √âchos I L'Usine Digitale |¬†Courrier CadresTo know how your personal data will be processed during your application process or to request its deletion, please¬†click here."}
{"job_title": null, "contract_type": "Stage(4 √† 6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Cr√©teil", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +3", "publication_date": "2024-05-02", "sector": "Pharmaceutique / Biotechnologique, Sant√©, Fondation, ONG", "company_size": "27", "creation_date": "2007", "address": null, "average_age_of_employees": "35", "turnover_in_millions": " 9M Euros ", "proportion_female": "55", "proportion_male": null, "programming_languages": ["scalabilit√©"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteLe poste de Stagiaire Data Engineer se concentre sur la conception, la construction et la maintenance des syst√®mes de traitement de donn√©es. Il offre une exp√©rience pratique dans la gestion de bases de donn√©es, le d√©veloppement de pipelines de donn√©es et l‚Äôoptimisation des performances des syst√®mes de donn√©es, contribuant ainsi √† garantir la disponibilit√© et la fiabilit√© des donn√©es pour l‚Äôentreprise.ACTIVITES PRINCIPALESConception et d√©veloppement de syst√®mes de traitement de donn√©esGestion de bases de donn√©es et d√©veloppement de pipelines de donn√©esOptimisation des performances des syst√®mes de donn√©esAssurance de la qualit√©, de la s√©curit√© et de la scalabilit√© des syst√®mes de donn√©esCollaboration avec les √©quipes de data science et d‚Äôanalyse de donn√©es pour r√©pondre √† leurs besoins en mati√®re de donn√©esD√©bogage et r√©solution de probl√®mes li√©s aux syst√®mes de donn√©esParticipation √† des projets de data engineering et contribution √† leur r√©alisation dans les d√©lais impartis."}
{"job_title": null, "contract_type": "CDI", "salary": "60K √† 70K¬†‚Ç¨", "company": null, "location": "Lyon", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "FinTech / InsurTech", "company_size": "266", "creation_date": "2016", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null, "programming_languages": ["python,", "scalable.nous"], "databases": ["postgresql,"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["ia/ml", "ml"], "raw_description": "Descriptif du posteEn raison de notre forte croissance, nous avons la volont√© de mettre en place une stack robuste, performante et scalable.Nous avons besoin de mieux utiliser les donn√©es en pr√©sence, et c‚Äôest une super opportunit√© pour toi : cela te permettra de cr√©er de la valeur pour l‚Äôentreprise !Aujourd‚Äôhui, l‚Äô√©quipe Data est compos√©e de 4 personnes, dans une √©quipe Tech globale de 45 personnes. Notre objectif √† terme est d‚ÄôavoirUn p√¥le IA avec 2 AI EngineersUn p√¥le BI avec un Lead Data Engineer et 3 Data EngineersTu rejoindras :Benoit, Lead Data EngineerElo√Øse, Data EngineerMaud, Data EngineerMaxime, Data ScientistLes missions de l‚Äô√©quipeFournir des donn√©es up-to-date, utiles et fiables aux √©quipes Business de Indy pour leur permettre d‚Äôanalyser et piloter leur activit√©.Am√©liorer notre syst√®me de cat√©gorisation automatique des transactions bancaires.L‚Äôobjectif actuel pour le p√¥le IA est d‚Äôam√©liorer la qualit√© de notre service de cat√©gorisation de transactions bancaires, en particulier pour les nouveaux r√©gimes fiscaux ouverts recemment. Nous souhaitons √©galement √©tudier d‚Äôautres opportunit√©s de cr√©ation de valeur pour l‚Äôentreprise en utilisant des techniques IA.Notre stack actuelle se compose de: PostgreSQL, Airbyte, DBT, Metabase, Dagster, Census, Python, Heroku, AWS ECS, DataDog.Tu auras pour missions de :Am√©liorer la qualit√© et la pr√©cision de notre service de cat√©gorisation de transactions bancaires.√âtudier des opportunit√©s de cr√©ation de valeur √† partir des donn√©es de l‚Äôentreprise en utilisant des techniques IA.Intervenir du POC jusqu‚Äô√† la mise en production.√ätre le garant de la m√©thodologie et de l‚Äô√©valuation des projets IA.Mettre en ≈ìuvre les projets IA/ML d‚ÄôIndy, que ce soit pour le produit utilis√© par nos client, ou pour les besoins internes.Assurer une veille permanente sur les sujets IA / ML et proposer des innovations √† Indy."}
{"job_title": null, "contract_type": "CDI", "salary": "45K √† 75K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 1 an", "education_level": null, "publication_date": "2024-05-02", "sector": "Logiciels, IT / Digital", "company_size": "28", "creation_date": "2018", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "3,6 M", "proportion_female": "20", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteCodeWorks regroupe une communaut√© de passionn√©s qui partagent une vision d‚Äôun code fiable, durable et r√©siliant.Nous appliquons cette vision depuis la conception d‚Äôapplications web jusqu‚Äôaux plateformes de traitement de donn√©es massives en passant par la mise en place de pipelines de d√©ploiement automatis√©s (NoOps).Nous cherchons avant tout des personnalit√©s qui ont la volont√© :d‚Äôadopter une posture adapt√©e, ancr√©e dans la r√©alit√© des probl√©matiques terrain pour r√©pondre au mieux aux besoins de nos clients en renfor√ßant leur √©quipe Datade partager leurs connaissances pour faciliter la mont√©e en comp√©tences r√©ciproquede rejoindre une communaut√© solidaire qui focalise son attention sur la qualit√© du code produit et l‚Äôentraide"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Brignais", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "Logiciels, SaaS / Cloud Services", "company_size": "245", "creation_date": "1999", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "27", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["azurepolitique"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud,"], "raw_description": "Descriptif du posteDans le cadre d‚Äôune cr√©ation de poste et rattach√© au Responsable Infra Cloud, vos missions sont les suivantes :‚Äî> Le d√©veloppement de la BI interne et client :D√©velopper les extractions et chargement de l‚Äôentrep√¥t de donn√©eD√©velopper les entrep√¥tsD√©velopper le Data LakeD√©velopper les rapports Power BI‚Äî> Le Maintien en condition op√©rationnel des bases de donn√©es :Optimisation des bases de donn√©es dans AzurePolitique de gestion des bases de donn√©es (sauvegarde , r√©tention, acc√®s‚Ä¶)Gestion des co√ªts FinOpsEgalement :Travailler en √©troite collaboration avec les 7 Squads pour r√©percuter les modifications dans la base de donn√©es produit.Suivi des nouvelles fonctionnalit√©s d√©velopp√©es par les √©quipes.Travailler avec les autres services d‚ÄôElcia pour d√©ployer les rapports aupr√®s des clients industriels (gestion des bugs, fonctionnement, rapports‚Ä¶).Administration de PowerBI (g√©rer des dataflow, cr√©ation des mod√®les, cr√©ation des KPI en DAX, cr√©ation des rapports, Relevel Security)D√©ploiement continue DevSecOps"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "< 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "Logiciels, Big Data, Energie", "company_size": "300", "creation_date": "2020", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": ["databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "aws", "azure.animes", "azure,"], "dev_tools": ["digital", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRejoins-nous en plein c≈ìur de Paris en tant que Data Architect, tu seras int√©gr√©(e) dans la Tech Authority qui r√©unit environ une vingtaine de personnes (Assurance Qualit√©, S√©curit√©, Architecte Software et Technique...). L'√©quipe √©volue dans un contexte agile √† tous les niveaux de l'organisation, en mode it√©ratif et co-constructif, en s'appuyant sur l'intelligence collective. Au sein de la Tech Authority, tu participes √† d√©terminer la gouvernance technique des projets. Tu es √©galement un soutien et un accompagnateur pour les Squads durant les diff√©rentes phases de leur projet. Nous attendons techniquement de toi que tu :D√©finisses l'architecture en phase de framing.Co-construises cette architecture avec les Squads en phase build. Tu seras principalement en lien avec les Data Engineers et les Tech Leads. Tu valides √©galement l'architecture lorsque le besoin √©volue. Tu es amen√©(e) √† prendre des d√©cisions d'architecture tout au long de la phase de build.Valides les mod√©lisationsEffectues des revues p√©riodiques avec la Squad pour √©tudier le code et sa qualit√©.Revois l'architecture de la solution avant le transfert au m√©tier.Tu devras √©galement faire de la veille et de l'accompagnement. Ainsi, nous attendons de toi que tu :D√©finisses les bonnes pratiques en mati√®re d'architecture data et que tu t'assures qu'elles sont bien respect√©es par l'ensemble des Squads.Te tiennes inform√©(e) des tendances, des √©volutions technologiques et des innovations en vigueur dans ton domaine d'intervention.Coaches les Squads dans les diff√©rentes phases de r√©alisation de leur projet avec les Chapter Lead.D√©bloques les Squads si n√©cessaire lorsqu'elles rencontrent un souci avec les architectures data dans les plateformes AWS et Azure.Animes les communaut√©s Tech sur l'architecture au travers des Communities of Practices pr√©sentes √† la Digital Factory de TotalEnergies.Ce que nous t'offrons:Le d√©veloppement de tes comp√©tences avec le support de la Digital Academy et une enveloppe √©quivalente √† environ 10 jours de formations par an que tu peux choisir en toute autonomie (formations externes et internes). La possibilit√© de te certifier sur les plateformes AWS et Azure, DataBricks, ‚Ä¶Un programme de mentorat pour t'accompagner.Un √©quilibre vie professionnelle et vie personnelle avec le recours possible aux horaires flexibles et au t√©l√©travail √† domicile.Un environnement de travail international et interculturel en plein c≈ìur de Paris, engag√© dans la diversit√© et l'inclusion"}
{"job_title": null, "contract_type": "Stage(6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-02", "sector": "Intelligence artificielle / Machine Learning, FinTech / InsurTech, Big Data", "company_size": "55", "creation_date": "2013", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null, "programming_languages": ["python", "python,", "python.", "python,"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams,"], "skills": null, "raw_description": "Descriptif du posteWe are looking for a rigorous Machine Learning Engineer with advanced expertise in Python programming from September 2024. Within the Macroeconomics team, you will participate in the development and improvement of our nowcasting pipelines for the main economic aggregates (such as GDP, Household consumption, Jobs Openings, etc.). As part of this team, you will seek to design robust models that measure the pulse of the economy in real time using a maximum of alternative data.Your mission will include :Create conceptual diagrams for data pipelinesCreate robust modeling to approach the economic measure of interest using advanced Statistical Learning techniques, Time Series Analysis, Machine Learning technologies and AI.Develop advanced modeling pipelines in Python, applying software development approaches, from data collection to productionUnderstand the economic measure of interest, its methodology, and the factors affecting it.Develop procedures for collecting and processing Big Data, using massive data engineering skills.Explore and assess the quality of available data sources, think about new use cases.Implement quality tests on indices put into production.Collaborate with IT team including Data Architects and DevOps pipeline implementationIn summary, participate in the entire production chain of a nowcasting model using alternative data (structured and unstructured) to estimate an economic indicator.What we offer:You will have the opportunity to rapidly get more responsibilities, take part in challenging and valuable projects, to communicate directly with our IT, Investment Strategy and Data Science teams, at the forefront of AI for‚ÄØeconomics and finance. You will also join a dynamic team that likes to organize after-work events and activities.Nous recherchons un Machine Learning Engineer rigoureux avec une expertise avanc√©e en programmation Python. Au sein de l‚Äô√©quipe de macro√©conomie, vous participerez au d√©veloppement et √† l‚Äôam√©lioration de nos pipelines de pr√©vision instantan√©e pour les principaux indicateurs √©conomiques (tels que le PIB, la consommation des m√©nages, les offres d‚Äôemploi, etc.). Dans le cadre de cette √©quipe, vous chercherez √† concevoir des mod√®les qui mesurent l‚Äô√©conomie en temps r√©el en utilisant un maximum de donn√©es alternatives.Votre mission comprendra :Cr√©ation des diagrammes conceptuels pour les pipelines de donn√©esCr√©ation des mod√®les robustes pour aborder la mesure √©conomique d‚Äôint√©r√™t en utilisant des techniques avanc√©es d‚Äôapprentissage statistique, d‚Äôanalyse de s√©ries temporelles, de technologies d‚Äôapprentissage automatique et d‚ÄôIA.D√©velopper des pipelines de mod√©lisation avanc√©e en Python, en appliquant des approches de d√©veloppement logiciel, de la collecte de donn√©es √† la productionComprendre la mesure √©conomique d‚Äôint√©r√™t, sa m√©thodologie et les facteurs qui l‚Äôaffectent.D√©velopper des proc√©dures de collecte et de traitement de Big Data, en utilisant des comp√©tences en ing√©nierie des donn√©es massives.Explorer et √©valuer la qualit√© des sources de donn√©es disponibles, r√©fl√©chir √† de nouveaux cas d‚Äôutilisation.Mettre en ≈ìuvre des tests de qualit√© sur les indices mis en production.Collaborer avec l‚Äô√©quipe informatique, y compris les data architects et la mise en ≈ìuvre des pipelines DevOps.  En r√©sum√©, participer √† l‚Äôensemble de la cha√Æne de production d‚Äôun mod√®le de pr√©vision instantan√©e en utilisant des donn√©es alternatives (structur√©es et non structur√©es) pour estimer un indicateur √©conomique.Ce que nous offrons :Vous aurez l‚Äôopportunit√© d‚Äôassumer rapidement plus de responsabilit√©s, de participer √† des projets stimulants, de communiquer directement avec nos √©quipes informatiques, de strat√©gie d‚Äôinvestissement et de science des donn√©es, √† l‚Äôavant-garde de l‚ÄôIA pour l‚Äô√©conomie et la finance. Vous rejoindrez √©galement une √©quipe dynamique qui aime organiser des √©v√®nements et des afterworks."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "Logiciels, IT / Digital, Transformation", "company_size": "160", "creation_date": "2014", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "17", "proportion_female": "38", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale.", "digitale", "digitales,optimisation"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteMeltOne Advisory, c‚Äôest 10 ans d‚Äôaventure dans la transformation digitale. Nous sommes en pleine croissance et nous avons besoin de toi pour continuer √† relever de nouveaux challenges aux c√¥t√©s de nos 150 collaborateurs passionn√©s !Si tu veux rejoindre une aventure innovante √† l‚Äôesprit start-up (innovation, agilit√©, intimit√© client) avec la force d‚Äôun grand cabinet (engagement sur le r√©sultat, large spectre d‚Äôexpertise, m√©thodologie), tu es au bon endroit.¬†Ta mission si tu l‚Äôacceptes: accompagner nos clients sur des projets de transformation digitale vari√©s et dans tous types de¬† secteurs d‚Äôactivit√© (Luxe, retail, services, industrie, banque / assurance, √©nergie‚Ä¶).¬†Nos consultants poss√®dent une double expertise : technique et fonctionnelle (Finance, Supply, S&OP‚Ä¶). Tu interviendras donc sur des projets alliant cette double casquette et tu pourras √©voluer dans des environnements vari√©s¬† au fil des missions client.Tu travailleras en collaboration √©troite avec nos managers et sur diff√©rents types de projet :Transformations digitales,Optimisation des processus,Am√©lioration de la qualit√© de l‚Äôinformation,Mise en ≈ìuvre et √©volution de syst√®mes d‚Äôinformation,Assistance √† la gestion de projetTes missions seront :Concevoir des solutions pertinentes et innovantes en tenant compte de tous les enjeux du contexte clientImpl√©menter et optimiser ces solutions dans les r√®gles de l‚ÄôartConseiller les clients dans leurs choixTransmettre ton savoir-faire et participer √† la capitalisation de connaissance des utilisateursSur tes diff√©rentes missions tu auras l‚Äôopportunit√© d‚Äôintervenir √† la fois sur les diff√©rentes phases des projets : cadrage / conception et mise en ≈ìuvre / conduite de projet et encadrement d‚Äô√©quipe, mais √©galement sur des activit√©s √† dominante commerciale : conception d‚Äôoffres / r√©daction de proposition / soutenance en client√®le."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Toulouse", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteMP DATA recrute un(e)¬†Data Engineer (H/F).Dans le cadre de la transformation digitale industriel, l‚Äô√©quipe de data engineering en charge de l‚Äôexploitation du Cluster Big Data cherche √† se d√©velopper.En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des donn√©es, en veillant √† ce qu‚Äôelles soient pr√™tes pour l‚Äôanalyse. Votre expertise dans la conception de pipelines ETL et la s√©curisation des donn√©es sera essentielle pour soutenir les activit√©s d‚Äôanalyse et de prise de d√©cision de l‚Äôentreprise. Votre r√¥le contribuera √† cr√©er une base de donn√©es solide et s√©curis√©e pour des insights pertinents et en temps r√©el."}
{"job_title": null, "contract_type": "CDI", "salary": "43K √† 52K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-05-02", "sector": "Application mobile, Logiciels, IT / Digital, Digital", "company_size": "80", "creation_date": "2017", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "7", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,"], "databases": ["mysql/postgresql.ta", "mysql/postgresql.ta"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": ["pytorch,"], "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitalis√©s"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteEn tant qu‚ÄôIng√©nieur IA, tu d√©velopperas des solutions d‚Äôintelligence artificielle pour des clients, en m√©thode agile. Tu seras √©paul√© par un mentor technique qui sera responsable de ta progression et du bon d√©roul√© de ton projet.Tes r√¥les seront les suivants :Mettre en ≈ìuvre des mod√®les d‚ÄôIA avec une approche pragmatique et it√©rative, en s‚Äôappuyant au besoin sur des mod√®les pr√©-entra√Æn√©s ou sur des services d√©di√©s ;D√©velopper des fonctionnalit√©s en mode full-stack pour int√©grer l‚ÄôIA dans les produits et services du client, en privil√©giant l‚Äôam√©lioration continue ;Collecter, nettoyer et pr√©parer les donn√©es pour l‚Äôentra√Ænement des mod√®les, en adoptant une approche pragmatique pour maximiser l‚Äôefficacit√© ;√âvaluer et am√©liorer les performances des mod√®les d‚ÄôIA en utilisant des techniques d‚Äô√©valuation adapt√©es, dans le but d‚Äôobtenir des r√©sultats significatifs ;Contribuer aux choix structurants du projet du point de vue des mod√®les et de l‚Äôinfrastructure technique.Exemples de projetsTu seras impliqu√© dans une vari√©t√© de projets passionnants et diversifi√©s, couvrant de nombreux secteurs d‚Äôactivit√© :D√©veloppement d‚Äôassistants vocaux dans le secteur m√©dicalEntra√Ænement et d√©ploiement de mod√®les de vision sur syst√®mes embarqu√©sIndustrialisation et automatisation de retouches photographiquesUtilisation de LLM pour la g√©n√©ration automatique de fiches produitsMod√©lisation de la pr√©vision de la demande dans l‚ÄôindustrieNos technosNous explorons continuellement les nouvelles technologies et les derni√®res approches en IA (mod√®les de diffusion, LLM, etc.). Pour le d√©veloppement IA, nos technologies de pr√©dilection sont Python, Pytorch, Hugging Face et les API d‚ÄôOpenAI ou √©quivalent. Pour la programmation fullstack, nous utilisons Typescript, Node.js, React et les bases de donn√©e MySQL/PostgreSQL.Ta progressionTu seras suivi par un mentor technique qui r√©alisera avec toi des pair-programmings et des codes reviewsTu auras un acc√®s illimit√© √† des cours vid√©os d‚Äôexperts sur nos technosTu pourras participer √† des cours et des ateliers techniques chaque semaine, anim√©s par le CTO, le CEO ou un lead d√©veloppeur.L‚Äô√©quipeTu partageras ton quotidien avec les √©quipes de Galadrim, compos√©e de pr√®s de 80 collaborateurs. La moyenne d‚Äô√¢ge est de 27 ans et l‚Äôambiance est tr√®s amicale et d√©tendue. Nos activit√©s principales pendant les pauses sont les jeux de soci√©t√© et les balades, mais nous sommes ouverts √† toute proposition !Nos plusüíö Une mutuelle derni√®re g√©n√©ration avec notre partenaire AlanüçΩÔ∏è Des tickets restaurant digitalis√©s gr√¢ce √† notre partenaire Swileü§∏ Participation √† 70% des abonnements sportifs jusqu‚Äô√† 49 ‚Ç¨ par mois, trois s√©ances offertes avec une nutritionniste, s√©ances organis√©es avec un coach sportifüéπ Des si√®ges ergonomiques Herman Miller Aeron, des bureaux assis-debout Autonomous, un piano, un babyfoot et une Switchü•≥ Une soir√©e chaque jeudi et plusieurs team building par mois (laser game, escape game, stand-up, cin√©ma, sport‚Ä¶)"}
{"job_title": null, "contract_type": "Stage(4 √† 6 mois)", "salary": "1,6K √† 2,1K¬†‚Ç¨ par mois", "company": null, "location": "Paris", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-05-02", "sector": "Application mobile, Logiciels, IT / Digital, Digital", "company_size": "80", "creation_date": "2017", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "7", "proportion_female": null, "proportion_male": null, "programming_languages": ["python,"], "databases": ["mysql/postgresql.ta", "mysql/postgresql.ta"], "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": ["pytorch,"], "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitalis√©s"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteEn tant qu‚ÄôIng√©nieur IA, tu d√©velopperas des solutions d‚Äôintelligence artificielle pour des clients, en m√©thode agile. Tu seras √©paul√© par un mentor technique qui sera responsable de ta progression et du bon d√©roul√© de ton projet.Tes r√¥les seront les suivants :Mettre en ≈ìuvre des mod√®les d‚ÄôIA avec une approche pragmatique et it√©rative, en s‚Äôappuyant au besoin sur des mod√®les pr√©-entra√Æn√©s ou sur des services d√©di√©s ;D√©velopper des fonctionnalit√©s en mode full-stack pour int√©grer l‚ÄôIA dans les produits et services du client, en privil√©giant l‚Äôam√©lioration continue ;Collecter, nettoyer et pr√©parer les donn√©es pour l‚Äôentra√Ænement des mod√®les, en adoptant une approche pragmatique pour maximiser l‚Äôefficacit√© ;√âvaluer et am√©liorer les performances des mod√®les d‚ÄôIA en utilisant des techniques d‚Äô√©valuation adapt√©es, dans le but d‚Äôobtenir des r√©sultats significatifs ;Contribuer aux choix structurants du projet du point de vue des mod√®les et de l‚Äôinfrastructure technique.Exemples de projetsTu seras impliqu√© dans une vari√©t√© de projets passionnants et diversifi√©s, couvrant de nombreux secteurs d‚Äôactivit√© :D√©veloppement d‚Äôassistants vocaux dans le secteur m√©dicalEntra√Ænement et d√©ploiement de mod√®les de vision sur syst√®mes embarqu√©sIndustrialisation et automatisation de retouches photographiquesUtilisation de LLM pour la g√©n√©ration automatique de fiches produitsMod√©lisation de la pr√©vision de la demande dans l‚ÄôindustrieNos technosNous explorons continuellement les nouvelles technologies et les derni√®res approches en IA (mod√®les de diffusion, LLM, etc.). Pour le d√©veloppement IA, nos technologies de pr√©dilection sont Python, Pytorch, Hugging Face et les API d‚ÄôOpenAI ou √©quivalent. Pour la programmation fullstack, nous utilisons Typescript, Node.js, React et les bases de donn√©e MySQL/PostgreSQL.Ta progressionTu seras suivi par un mentor technique qui r√©alisera avec toi des pair-programmings et des codes reviewsTu auras un acc√®s illimit√© √† des cours vid√©os d‚Äôexperts sur nos technosTu pourras participer √† des cours et des ateliers techniques chaque semaine, anim√©s par le CTO, le CEO ou un lead d√©veloppeur.L‚Äô√©quipeTu partageras ton quotidien avec les √©quipes de Galadrim, compos√©e de pr√®s de 80 collaborateurs. La moyenne d‚Äô√¢ge est de 27 ans et l‚Äôambiance est tr√®s amicale et d√©tendue. Nos activit√©s principales pendant les pauses sont les jeux de soci√©t√© et les balades, mais nous sommes ouverts √† toute proposition !Nos plusüíö Une mutuelle derni√®re g√©n√©ration avec notre partenaire AlanüçΩÔ∏è Des tickets restaurant digitalis√©s gr√¢ce √† notre partenaire Swileü§∏ Participation √† 70% des abonnements sportifs jusqu‚Äô√† 49 ‚Ç¨ par mois, trois s√©ances offertes avec une nutritionniste, s√©ances organis√©es avec un coach sportifüéπ Des si√®ges ergonomiques Herman Miller Aeron, des bureaux assis-debout Autonomous, un piano, un babyfoot et une Switchü•≥ Une soir√©e chaque jeudi et plusieurs team building par mois (laser game, escape game, stand-up, cin√©ma, sport‚Ä¶)"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2024-05-02", "sector": "Digital Marketing / Data Marketing, IT / Digital, Audit", "company_size": "65", "creation_date": "2021", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "6", "proportion_female": "30", "proportion_male": null, "programming_languages": ["python", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadooptu", "spark"], "ML_and_data_mining": null, "data_viz": ["tableau"], "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste√ätre Data Engineer chez R√¶dy, √ßa consiste √† quoi ?D√©velopper des solutions techniques de stockagesConcevoir l‚Äôarchitecture technique n√©cessaire pour la valorisation des donn√©esPrioriser les besoins m√©tiers Mod√©liser, d√©velopper et effectuer la maintenance du DatawarehouseAssurer la clart√© et la s√©curit√© des donn√©esD√©celer les dysfonctionnements √©ventuelsConsolider les donn√©es √† des fins analytiques ou de Datascience Explorer et effecteur la fouille des donn√©es R√©aliser des tests unitaires et d‚Äôint√©grationSuivre le RUNParticiper √† des POCMettre √† jour les technologies et langages utilis√©sAssurer le suivi de production et la maintenance Comp√©tences requises Tu fais de la veille informatique et technologique pour compl√©ter ton expertise L‚Äôesprit d‚Äô√©quipe est essentiel pour toi Tu ma√Ætrises les langages Scala, Spark et Python Tu as des connaissances dans la gestion volume de donn√©e et d‚Äôapplications Big Data sur HadoopTu as des connaissances sur les nouvelles techniques analytiques Big Data : Apache Kylin, Atscale, Hive, Presto DBTu utilises les techniques de visualisation de donn√©es : Tableau Software Tu ma√Ætrise la m√©thode agilePetit + : tu as des connaissances en mod√©lisation datalake "}
{"job_title": null, "contract_type": "CDI", "salary": "85K¬†$", "company": null, "location": "New York", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-02", "sector": "IT / Digital, Strat√©gie, Audit, Big Data", "company_size": "400", "creation_date": "2006", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null, "programming_languages": ["(python,", "scalable", "scalable"], "databases": ["snowflake-"], "data_analyze": null, "big_data_tools": ["spark)-", "databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "azure,"], "dev_tools": ["digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams,"], "skills": ["mlops-", "cloud", "cloud", "cloud.-", "(ci/cd),"], "raw_description": "Descriptif du posteEkimetrics is a leader in data science and AI-powered solutions. For over 16 years, we‚Äôve pioneered the use of AI and advanced data science applied to unified marketing measurement, holistic business optimization and broad-ranging sustainability goals.Our goal: combine high impact with long-term business purpose.Ekimetrics is one of the world‚Äôs largest independent analytics firms with offices on 3 continents, and with more than 400 data experts. Since 2006, we have led more than a thousand data science projects in over 50 countries, generating more than $1bn in profit for our customers.We help companies rethink the way they operate, so they can reconcile financial KPIs with non-financial goals. We are uniquely specialized in creating scalable data and analytics solutions that drive high-impact optimizations in alignment with overarching brand strategy and sustainability goals.At Ekimetrics, we believe our best assets are our people. They are what set us apart and drive our success with entrepreneurial spirit and innovation. We encourage entrepreneurial spirit and innovation. We share what we know with others, and, above all, we love what we do. These sentiments are supported by our company values which serve as pillars in our work and attitude: curiosity, creativity, excellence, transmission, and pleasure.In our New York office, we focus particularly in Marketing Science and the deployment of our ‚ÄòMMO‚Äô offer (Marketing Mix Optimization), either through analytics as a service or building industrialized solutions. About the RoleThis role is perfect for data engineers early in their career journey with 1 - 2 year experience.As a Consultant you will work with international blue-chip clients across diverse industries. In this role you will use and develop advanced data engineering and consulting skills on your projects.As a Data Engineer, you will be involved in challenging projects with leading international clients in diverse industries, building tailor-made analytical solutions to meet our clients' challenges. You will work in a team, with other Ekimetrics consultants (data engineers, data scientists, domain specialists) on 1 or 2 projects simultaneously. You will benefit from our technological partnerships and a training offer to support you in your skills development.As a data engineer you will support our clients in their Data Transformation so that they can carry out ambitious data-driven initiatives. We advise our clients in the choice of the most appropriate technology as well as in the implementation of robust and scalable Data Architectures. Our close-knit team will guide your growth to build expertise on best-practice methodologies and industry knowledge, working directly with Ekimetrics partners. Each member of our team takes a vested interest in the development of your technical skills and business acumen. Our team members continuously learn and grow through 70+ proprietary training sessions and collaboration with colleagues as coaches and mentors.Finally, the opportunity to work for a growing, international pioneer in data science, will empower you to have an immediate impact by contributing to our passionate team.Responsibilities:Data Engineering- Design and develop complex chains and solutions to collect and prepare data- Develop tools to facilitate access to, implementation, industrialization, and deployment of data pipelines in cloud environments- Deepen your knowledge of Machine Learning, Generative AI, and Marketing Mix OptimizationPartnerships with Clients- Liaise daily with clients to develop a deep understanding of their business context and experience- Deliver findings and battle plans with excellence and confidence- Provide ad-hoc analyses that further develop projects and client relationships by parameterizing the business questionsLife- Support our fast growth by contributing to local and global initiatives such as Knowledge Management, Recruitment, Culture, Gender Balance and Diversity teams, Pioneering Machine Learning/AI techniques for the office, etc.About you:We are looking for a talented, dual profile consultant.Data Skills:- BA or MA degree (or equivalent) in Data Science, Computer Science, Engineering or other related field/bootcamp- 1 ‚Äì 2 years data engineering experience- Advanced knowledge of coding languages, databases, and development tools (Python, SQL, Spark)- Passion for data, statistics, or applied mathematics with familiarity with modeling/optimization techniques- Experience with cloud environments such as Azure, AWS, Databricks, Snowflake- Knowledge of data architecture, data lakes, ETL/ELT and setting up data/data science solutions on cloud.- Experience in using business intelligence platforms for data visualization, creating and automating dashboards, reports and data sources.- Familiarity with Continuous Integration and continuous delivery (CI/CD), DevOps, MLOps- Advanced knowledge of data acquisitionConsulting skills:- Consulting experience or interest in working as a consultant- Strong interest in marketing & business issues- Exceptional written and oral communication skills- Ability to work collaboratively in a team setting- Self-driven and motivated to thrive in a fast-paced environment- Continuous striving for high performance- Spanish-speaking is a plusWhat we offer:At Ekimetrics, final base salary is determined by a multitude of factors and vary from candidate to candidate. Determining factors for base compensation include, but are not limited to, professional background, years of experience, and skillset. A reasonable estimate of the base salary for our NYC office is $85,000. In addition to this base salary, we have a comprehensive benefits package, generous bonus package, and a dynamic promotions and salary raise structure.- An emphasis on work-life-balance and 20 PTO days per year and holidays- Dynamic environment with a strong culture and great offices- Close-knit team with friendly environment, bi-monthly team events and more- Creative and entrepreneurial start-up environment with vertical and lateral mobility- Best-in-class methodologies and cutting-edge technologies- Unique internal training package with 70+ sessions in our Eki.Academy digital platform- Growth to develop a double profile in data science and strategic consulting- Client exposure up to the executive level- Opportunities for international mobility across our three other offices in Paris, London, and Hong Kong"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Toulouse", "remote": "T√©l√©travail occasionnel", "experience": "> 3", "education_level": null, "publication_date": "2024-05-01", "sector": "Application mobile, Logiciels, E-commerce", "company_size": "50", "creation_date": "2009", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "14M$", "proportion_female": "50", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteMission and challenges üéØSi tu es enthousiaste √† embarquer dans la nouvelle √©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c‚Äôest l‚Äôaventure qu‚Äôil te faut!¬†üèîÔ∏èAvec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les √©quipes de Pictarine ne sont jamais √† court d‚Äôid√©es pour explorer de nouveaux horizons. üöÄEn tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta cr√©ativit√© pour garantir la qualit√© de la data, accompagner et challenger les besoins data.Tu √©volueras au sein de l‚Äô√©quipe Engineering, compos√©e des p√¥les dev & data. Tu rejoindras une √©quipe data d√©j√† compos√©e d‚Äôune data analyste, Romane, et de la data manager, Marie¬†!Ton r√¥le comprendra les aspects suivants üëáüèªTu es garant de la qualit√© de la data !En simplifiant la structure de la data et r√©duisant le nombre de tablesEn transformant les donn√©es pour les rendre facilement utilisablesEn orchestrant le flux des donn√©es de mani√®re continue et automatiqueTu accompagnes et challenges les √©quipes de Pictarine !En co-construisant des solutions data appropri√©esEn √©levant le niveau de jeu des m√©thodes data existantesEn faisant rayonner la data autour de bonnes pratiques et d‚Äôoutillages ad√©quates"}
{"job_title": null, "contract_type": "CDI", "salary": "40K √† 50K¬†‚Ç¨", "company": null, "location": "Le Mans", "remote": "T√©l√©travail non autoris√©", "experience": "> 3", "education_level": null, "publication_date": "2024-05-01", "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital", "company_size": "16000", "creation_date": "1979", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "1 022.5 ", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteAfin d'accompagner notre croissance et les activit√©s du groupe, nous recherchons un¬†Tech Lead Data¬†H/FRattach√© √† notre cellule d‚Äôexpertise, vous serez int√©gr√© au sein de l‚Äô√©quipe structure mancelle.En tant qu‚Äôinterlocuteur privil√©gi√© sur la r√©gion du Mans, vous aurez en charge l‚Äôaccompagnement du d√©veloppement de notre Delivery Center Data, une participation active au suivi technique des projets ainsi qu‚Äôun acteur √† la veille technologique et au d√©ploiement de m√©thodes ou d‚Äôenvironnements innovants autour de la data.Vous interviendrez sur les activit√©s suivantes :  Participation de l‚Äôanimation technique des √©quipes¬†;   Intervention sur des sujets √† fortes valeurs ajout√©es ou en situation de blocage¬†; D√©livrer des missions d‚Äôexpertise et de conseil aupr√®s de nos clients¬†;    Support au d√©veloppement des comp√©tences internes (consolidation des plans de formation, animation technique et suivi mont√©e en comp√©tences)¬†; Capitaliser des savoirs faire sur nos projets et compl√©ter les r√©f√©rences pour le Groupe¬†; En liaison avec l‚Äô√©quipe commerciale et la Direction du D√©veloppement du Groupe, contribution aux r√©ponses √† des appels d‚Äôoffres¬†; Communication et mise en avant de notre offre data (Events / R√©seaux sociaux / Blog / Speak-up / Club-client / ‚Ä¶)¬†;    Veille technologique¬†; Animation de la communaut√© Big Data locale.De formation sup√©rieure (Bac +4/5) en informatique, vous avez une exp√©rience technique confirm√©e (minimum 3 ans) en contexte projets Big Data.Vous connaissez pr√©cis√©ment l‚Äô√©cosyst√®me existant (opensource/buy), D√©termin√©, √† l'√©coute et autonome, devenez un expert reconnu sur votre territoire et pour le Groupe SII!Rejoindre SII Ouest, c‚Äôest aussi :  Un service formation au top (formations techniques, d√©veloppement personnel, gestion d‚Äô√©quipe, management, ‚Ä¶)  Des possibilit√©s d‚Äô√©volution pour votre carri√®re (devenir Lead Dev, Chef de Projet, passerelles entre les m√©tiers techniques et fonctionnels, ‚Ä¶)   Une vraie communaut√© de passionn√©s (participation aux √©v√©nements techniques tels que le Breizh Camp, l‚ÄôAgile Tour ; possibilit√© de partager ses connaissances √† travers les D√©jeuners Techniques, ‚Ä¶)   Une ambiance conviviale (Petit d√©jeuner √† l‚Äôagence, Afterworks, Soir√©es d‚ÄôAgence, ‚Ä¶)   Jusqu‚Äô√† 50% de t√©l√©travail (on privil√©gie l‚Äô√©quilibre vie pro/vie perso tout en gardant le lien avec nos collaborateurs !) Une QVT reconnue (pour la 7√®me ann√©e cons√©cutive, nous sommes certifi√©s Great Place to Work)Le Groupe SII est au c≈ìur de l‚Äôinnovation au service de grands comptes dans des secteurs d‚Äôing√©nierie vari√©s.Pour la 7√®me ann√©e cons√©cutive, SII France a obtenu le label Great Place To Work¬Æ. En 2023 nous avons √©t√© reconnus 3√®me entreprise de ¬´ +de 2500 salari√©s ¬ª o√π il fait bon vivre. Nous en sommes tr√®s fiers car nous sommes la seule ESN de cette dimension √† obtenir cette reconnaissance par ses salari√©s ! Ce succ√®s est le reflet de notre culture bas√©e sur notre volont√© de proposer √† tous nos salari√©s un cadre de travail √©panouissant pour le d√©veloppement de leurs comp√©tences et carri√®res. Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la cr√©ativit√©, la proximit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur. Le Groupe SII est une soci√©t√© handi-accueillante, signataire de la Charte de la diversit√© en entreprise.Alors si ces valeurs vous parlent, rejoignez-nous !#LI-CM8"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Tours", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-01", "sector": "IT / Digital, Transformation, Big Data", "company_size": "14500", "creation_date": "1976", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "12 Mds ‚Ç¨ en 2022", "proportion_female": "35", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste Vos missions sont :- Recueillir les besoins m√©tiers et des √©quipes data- Concevoir et mettre en place les traitements de donn√©es- R√©aliser les tests de validation- Assurer l‚Äôalimentation du dataware- R√©aliser les ordonnancements des traitements- √ätre garant de la mise en place, du suivi et de l‚Äôexploitation des outils d√©ploy√©s- Assurer une veille technologique r√©guli√®reEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,‚Ä¶). "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Tours", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-05-01", "sector": "IT / Digital, Transformation, Big Data", "company_size": "14500", "creation_date": "1976", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "12 Mds ‚Ç¨ en 2022", "proportion_female": "35", "proportion_male": null, "programming_languages": ["python.", "java,", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["(hadoop,", "spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["git,"], "OS": null, "big_data_and_processing": ["cassandra‚Ä¶),"], "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["ci/cd‚Ä¶)-"], "raw_description": "Descriptif du poste Vous √™tes passionn√©(e) par le domaine de la Data et avez d√©j√† une exp√©rience significative sur des probl√©matiques de data engineering : construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es, ‚Ä¶Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi‚Ä¶) et/ou NoSQL (MongoDB, Neo4j, Cassandra‚Ä¶), vous maitrisez un des trois langages suivants : Java, Scala, Python. Connaissances de Talend.En tant que Data Engineer, vous serez int√©gr√©(e) √† un p√¥le de consultant(e)s sp√©cialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions mises en place- Travailler en collaboration avec les ing√©nieurs techniques et autres experts afin de rechercher et fournir des r√©ponses aux probl√©matiques techniques- R√©aliser les travaux d‚Äôimpl√©mentation des solutions (pr√©paration des donn√©es, industrialisation des mod√®les, communications entre les diff√©rentes technologies,‚Ä¶)- Produire les projets en mode agile avec des processus et outils de d√©veloppement de derni√®re g√©n√©ration (DevOps, Git, CI/CD‚Ä¶)- Participer √† l'√©laboration et la r√©vision de normes / documentation technique- Animer des formations internes. Accompagner la mont√©e en comp√©tences des √©quipes- Assurer un support technique Big Data aux √©quipes et aux clients au quotidienAccompagn√©(e) et entour√©(e) par une communaut√© Data passionn√©e, l‚Äô√©change, le partage et les formations vous offriront un v√©ritable espace pour vous √©panouir. La proximit√© et le suivi personnalis√© de votre manager, puis un bon nombre d‚Äô√©v√©nements tout au long de l'ann√©e, renforceront encore la convivialit√© et l‚Äôesprit d'√©quipe !Fort(e) d‚Äôune int√©gration r√©ussie, de nombreuses possibilit√©s d‚Äô√©volutions de carri√®re s‚Äôoffriront rapidement √† vous, dans l‚Äôanimation de la fili√®re technique ou dans le consulting de solutions Data.En rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,‚Ä¶).¬† "}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Croix", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "Application mobile, Logiciels, Cybers√©curit√©, Sport, E-commerce, Grande distribution", "company_size": "4000", "creation_date": "2018", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python,", "python", "scaladata"], "databases": null, "data_analyze": null, "big_data_tools": ["pyspark,", "databricks,", "databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale", "digitales", "digitalet", "digital,", "git,", "github,", "git", "digital", "digital"], "OS": ["windows)√©quipe"], "big_data_and_processing": null, "automation_and_orchestration": ["airflowdata", "airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["ml", "cloud", "cloud"], "raw_description": "Descriptif du posteIntroductionDecathlon acc√©l√®re sa transformation digitale avec pour mission de devenir LA plateforme num√©rique sportive qui permettra aux clients de d√©couvrir notre univers √† travers de nombreuses exp√©riences locales centr√©es sur le sport.Notre but est de cr√©er un √©cosyst√®me ouvert afin de connecter de nombreux acteurs et services tiers, de mani√®re s√ªre et performante.Nos √©quipes digitales bas√©es √† Lille, Paris et Amsterdam regroupent plus de 1500 collaborateurs qui sont unis pour construire et faire grandir des produits num√©riques dans le but de toujours offrir la meilleure valeur √† nos utilisateurs.Decathlon DigitalEt si la Tech nous permettait de r√©inventer le sport de demain et de devenir la plus grande plateforme num√©rique sportive ? c‚Äôest l‚Äôobjectif que nous nous fixons chez Decathlon.‚ÄúRendre durablement les plaisirs et les bienfaits du sport accessibles au plus grand nombre‚Äù est notre mission depuis toujours. Une vocation qui atteint aujourd‚Äôhui son paroxysme en augmentant l‚Äôexp√©rience du sport par les technologies et r√©pondant aux besoins de nos 500 millions d‚Äôutilisateurs √† travers le monde.Nous cr√©ons ainsi de nouvelles exp√©riences pour les sportives et sportifs ‚Äì coaching virtuel, programmes de fid√©lit√©, exp√©riences intelligentes en magasin, offres de produits neufs et d'occasion, mais aussi services de location d'une large gamme de produits Decathlon et de partenaires.Decathlon Digital, c‚Äôest aujourd‚Äôhui plus de 5000 profils techniques : software engineers, product managers, expert¬∑e¬∑s de la data, du Cloud et de la cybers√©curit√©, en France et √† l‚Äô√©tranger, implant√©es √† Paris, Lille, Nantes, Lyon, et Amsterdam.Notre √©quipe Data Wonder Offer cherche sa.son Analytics Engineer stagiaire / Alternant.e bas√©.e √† LilleL'√©quipe Data Wonder Offer a la responsabilit√© de plusieurs produits Analytics & IA contribuant au maintien de l‚Äôefficience de l‚Äôoffre de Decathlon (d√©tection de produits similaires, optimisation d‚Äôassortiment, monitoring de la performance produit‚Ä¶).Avec des produits en cours de build qui devront √™tre industrialis√©s mais √©galement des cas d‚Äôusage qui doivent encore √™tre cadr√©s. Tu seras impliqu√©.e dans l‚Äôindustrialisation de l‚Äôensemble de ces produits.Sur le plan humain, l‚Äô√©quipe Data Wonder Offer est aujourd‚Äôhui constitu√©e de 9 personnes :1 Data PM, 1 Analytics Engineer, 2 BI Engineers, 1 Data Analyst, 2 Data Scientists, 2 ML Engineers√Ä venir : 1 Data Scientist, 1 Analytics Engineer Vos responsabilit√©sEn tant que Analytics Engineer stagiaire/alternant.e, vous aurez l‚Äôoccasion de :Automatiser et industrialiser les pipelines de transformation de donn√©es qui servent aux dashboards, mod√®les IA et data analysesConstruire et mod√©liser la semantic layer de domaine m√©tier (commerce, supply, sports, etc.) ;D√©finir la strat√©gie de nos stacks techniques et garantir la qualit√© des donn√©es expos√©es ;Maintenir et repenser les datasets et pipelines existants pour servir une plus large vari√©t√© de use cases ;Permettre de l'analytique intelligente en construisant des datasets robustes, fiables et pertinents ;Contribuer activement √† notre communaut√© d'analytics engineers et de data engineers ;Le p√©rim√®tre techniqueData-platform : Amazon Web Services, Databricks, Glue, S3Code Programming : SQL, Python, ScalaData orchestration : AirflowData modeling : dbtData quality : great_expectationsSoftware Delivery : Git, Github, MakeSkillsConnaissance de Python et SQL comme langage de programmationConnaissances en mod√©lisation dimensionnelleConnaissances et exp√©rience avec Databricks, dbt, Airflow, pyspark, git est un plusCuriosit√© et proactivit√© pour comprendre le besoin m√©tierRigueur pour d√©livrer de la donn√©e de qualit√©Une volont√© d‚Äôapprendre et d‚Äôapporter de la valeurUne forte app√©tence pour la d√©couverte et la r√©solution de probl√®mesCe que nous offronsFlexibilit√© dans l'organisation du travail (lieu, rythme)Libert√© de choix de l'outil de travail (Mac, Windows)√âquipe de projet locale et partage avec le r√©seau mondial (parcours international)Mont√©e en comp√©tences (diversit√© des projets, des langues et des technologies)Formations internes et externesActionnariat salari√©sPrimes mensuelles et trimestriellesDECATHLON DIGITAL Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Limonest", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["scalables"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": [";digitaliser"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud,", "cloud,", "cloud", "cloud"], "raw_description": "Descriptif du posteRattach√©/e √† la communaut√© technique, vous √©voluez parmi nos experts au sein de communaut√©s de practices¬†: DATA, IA, Cloud, Frontend, Backend, Architecture, Num√©rique Responsable.Vous aurez pour responsabilit√©, de participer au succ√®s des projets de modernisation, de d√©veloppements, en apportant votre savoir-faire technique aux √©quipes, en promouvant la qualit√©, la s√©curit√© et l‚Äôinnovation pour r√©pondre aux d√©fis technologiques de demain.Si vous avez un talent exceptionnel pour faire parler les donn√©es et que vous aimez les d√©fis, alors vous √™tes au bon endroit !En rejoignant Sopra Steria Lyon, vous prendrez part √†¬†:Travailler √† la modernisation technologique de nos clients industriels avec des sujets tels que la data, le cloud, l‚ÄôIoT pour l‚Äôindustrie 4.0, mais aussi prendre part √† construire une industrie plus durable¬†;Digitaliser les services pour am√©liorer l‚Äôexp√©rience et l‚Äôint√©gration entre les entreprises, les citoyens et les administrations¬†;Am√©liorer l‚Äôexp√©rience utilisateur des clients du retail ax√© sur l‚Äôomnicanalit√©, le cloud et la data¬†;Transformer les assurances, face √† des concurrents disruptifs tels que les n√©o-assurances, pour am√©liorer les services aux clients en adoptant les principes de d√©mat√©rialisation des services avec le cloud et l‚Äôanalytics pour l‚Äôoptimisation des offres.Votre r√¥le et vos missions :Plongez au c≈ìur de l'excellence de notre agence Lyonnaise, et prenez part √† la transformation du march√© de l‚Äôindustrie automobile. Vous int√©grez une √©quipe projet de la taille d‚Äôune pizza team compos√©e de profils pluridisciplinaires (d√©veloppement frontend, backend, data analyst, data engineer, architect, IaC, s√©curit√© applicative, op√©rations) qui a √† c≈ìur d‚Äôapporter la qualit√©, la s√©curit√©, l‚Äôexp√©rience utilisateur dans la construction de ses solutions.Dans ce cadre vous remplissez les missions suivantes :Vous mettez en place et maintenez des plateformes data performantes et scalables ;Vous partagez votre √©nergie contagieuse et votre passion de l‚Äôexcellence technique aux √©quipes¬†;Vous √™tes force de proposition et apportez une vision nouvelle¬†et innovante ;Vous collaborez avec des esprits brillants pour transformer les id√©es en produits concrets¬†;Vous brisez les barri√®res et repoussez les limites de ce qui est possible dans le monde de la data.Informations suppl√©mentairesLes avantages √† nous rejoindre :¬†‚Ä¢ Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions ;‚Ä¢ Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation ;‚Ä¢ Un accompagnement individualis√© avec un mentor ;‚Ä¢ Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble ;‚Ä¢ Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy ;‚Ä¢ La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire \"Vendredi\" ;‚Ä¢ L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements>¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Clermont-Ferrand", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": [";digitaliser"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud,", "cloud,", "cloud", "cloud"], "raw_description": "Descriptif du posteRattach√©/e √† la communaut√© technique, vous √©voluez parmi nos experts au sein de communaut√©s de practices¬†: DATA, IA, Cloud, Frontend, Backend, Architecture, Num√©rique Responsable.Vous aurez pour responsabilit√©, de participer au succ√®s des projets de modernisation, de d√©veloppements, en apportant votre savoir-faire technique aux √©quipes, en promouvant la qualit√©, la s√©curit√© et l‚Äôinnovation pour r√©pondre aux d√©fis technologiques de demain.En rejoignant Sopra Steria Lyon, vous prendrez part √†¬†:Travailler √† la modernisation technologique de nos clients industriels avec des sujets tels que la data, le cloud, l‚ÄôIoT pour l‚Äôindustrie 4.0, mais aussi prendre part √† construire une industrie plus durable¬†;Digitaliser les services pour am√©liorer l‚Äôexp√©rience et l‚Äôint√©gration entre les entreprises, les citoyens et les administrations¬†;Am√©liorer l‚Äôexp√©rience utilisateur des clients du retail ax√© sur l‚Äôomnicanalit√©, le cloud et la data¬†;Transformer les assurances, face √† des concurrents disruptifs tels que les n√©o-assurances, pour am√©liorer les services aux clients en adoptant les principes de d√©mat√©rialisation des services avec le cloud et l‚Äôanalytics pour l‚Äôoptimisation des offres.Votre r√¥le et vos missions :Plongez au c≈ìur de l'excellence de notre agence Clermontoise, et prenez part √† la transformation du march√© de l‚Äôindustrie automobile. Vous int√©grez une √©quipe projet de la taille d‚Äôune pizza team compos√©e de profils pluridisciplinaires (d√©veloppement frontend, backend, data analyst, data engineer, architect, IaC, s√©curit√© applicative, op√©rations) qui a √† c≈ìur d‚Äôapporter la qualit√©, la s√©curit√©, l‚Äôexp√©rience utilisateur dans la construction de ses solutions.Si vous avez un talent exceptionnel pour d√©coder et faire la parler la data et que vous aimez les d√©fis, alors vous √™tes au bon endroit !Dans ce cadre vous remplissez les missions suivantes :Vous √™tes participez au d√©veloppement et √† la maintenance de plateformes data ;Vous partagez votre √©nergie contagieuse et votre passion de l‚Äôexcellence technique aux √©quipes¬†;Vous √™tes force de proposition et apportez une vision nouvelle¬†et innovante ;Vous collaborez avec des esprits brillants pour transformer les id√©es en produits concrets¬†;Vous brisez les barri√®res et repoussez les limites de ce qui est possible dans le monde de la data.Informations suppl√©mentairesLes avantages √† nous rejoindre :¬†‚Ä¢ Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions ;‚Ä¢ Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation ;‚Ä¢ Un accompagnement individualis√© avec un mentor ;‚Ä¢ Des opportunit√©s de carri√®res multiples : plus de 30 familles de m√©tiers, autant de passerelles √† imaginer ensemble ;‚Ä¢ Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy ;‚Ä¢ La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire \"Vendredi\" ;‚Ä¢ L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements>¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Nantes", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["java,", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop,", "spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["docker),", "(jenkins"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["ansible"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker),"], "collaboration": null, "skills": ["ci/cd"], "raw_description": "Descriptif du posteVotre futur environnement de travail :Le march√© de l‚Äô√©nergie vit un boom de l‚Äôutilisation de la Data : Optimisation des pr√©visions de production, suivi intelligent des consommations √©lectriques, fiabilit√© et intelligence pr√©dictible‚Ä¶.Dans ce contexte, Sopra Steria accompagne ses grands clients du secteur pour d√©velopper des solutions de structuration, de transformation, d‚Äôanalyse et de diffusion de la donn√©e : compteur Linky, √©quilibrage de la production et de la consommation √©lectrique, impact des √©nergies renouvelables et des nouveaux modes de consommation (autoconsommation, v√©hicules √©lectriques, d√©tection de fraude √† la consommation‚Ä¶)Vous int√©grez une √©quipe Agile au sein d‚Äôune organisation √† l‚Äô√©chelle (SAFE) notamment pour des projets qui sont en charge :D‚Äôidentifier et de suivre les pertes non techniques (probl√®me de raccordement ou fraude) au sein du r√©seau de distribution √©lectrique fran√ßais.D‚Äôindustrialiser le DataLake client (supervision, optimisation, transformation)Accompagner le d√©ploiement applicatif dans une d√©marche DEVOPS.Votre r√¥le et vos missions :En tant qu‚Äô√©quipier(√®re)¬†Agile int√©gr√©(e) au sein d‚Äôune √©quipe d‚Äôenviron 8 √† 10 personnes, vous participez √† l‚Äôanalyse, au d√©veloppement et au d√©ploiement (DEVOPS) de l‚Äôapplication. Accompagn√©(e) par un tuteur et gr√¢ce √† un plan de formation adapt√©, vous participez aux activit√©s suivantes :Analyse des besoins m√©tiers et mise en place de solution de data ing√©nierie et/ou data analysis ;Exploration des donn√©es afin d‚Äôoptimiser et d‚Äô√©tudier la faisabilit√© des sc√©narios¬†d‚Äôalgorithmes ;Mise en place d‚Äôalgorithmes de traitement des donn√©es (batch ou streaming) ;Structurer un DataLake, et s√©curisation des donn√©es ;Int√©gration dans une chaine¬†CI/CD et participation aux pratiques DEVOPS ;Contribution au grooming et MVP afin d‚Äôaffiner le backlog des besoins m√©tiers;Participation active au Poker Planning ;Conception et d√©veloppement des nouvelles User Stories ;R√©alisation des tests techniques des solutions d√©velopp√©es ;R√©daction de la documentation ;D√©monstration et r√©trospective du sprint.Les apports de l'alternance :Approfondir vos comp√©tences techniques dans un √©cosyst√®me Data innovant.D√©velopper une approche m√©thodologique et industrialis√©e de votre travail.Renforcer votre app√©tence pour le travail collaboratif avec les rituels Agile (Scrum/SAFE).D√©couvrir le domaine de l‚Äô√©nergie avec des enjeux m√©tiers majeurs (transition √©nerg√©tique).Innover dans un contexte Big Data en permanente √©volution au sein d‚Äôun des leaders de la tech.Technos utilis√©es : Hive, Spark, Scala, SQL, HDFS, Hadoop, DEVOPS (Jenkins / Ansible / Docker), PowerBI, Java, PGAAS, Teradata.Informations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, et des primes vacances.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.De tr√®s nombreuses opportunit√©s en CDI peuvent vous attendre √† l‚Äôissue de l'alternance.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Nantes", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["python,", "javaoutillage"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["gitlab,", "gitlab", "docker,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chefs", "airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker,", "openshift,"], "collaboration": null, "skills": ["cnamla", "ci/cdd√©veloppement"], "raw_description": "Descriptif du posteVotre futur environnement de travail :Participez √† la construction de la Plateforme Big Data du SI de l‚ÄôAssurance Maladie et contribuez au d√©veloppement de cas d‚Äôusage m√©tier autour du Data Engineering.Int√©gr√©(e) au sein d‚Äôun projet d‚Äôune √©quipe d‚Äôenviron 5 collaborateurs, int√©gr√© lui-m√™me au sein d‚Äôun plateau de 80 personnes, vous contribuez au d√©veloppement de la plateforme Big Data du SI de la CNAM. Cette plateforme Big Data a pour objectif de fournir aux Data Scientists / Data Analysts de la CNAM de nouveaux usages autour de la donn√©e.Votre r√¥le et vos missions :La mission se d√©roule en plusieurs phases¬†:Appropriation du contexte projet (enjeux, objectifs‚Ä¶)Appropriation du contexte technique (Data Engineering, Conteneurisation,‚Ä¶)Conception de la solution technique du traitement qui vous sera confi√© ;Pr√©paration des conditions de tests du traitement √† mettre en ≈ìuvre ;R√©alisation du module ;Recette du module ;Transfert de comp√©tences vers l‚Äô√©quipe en fin de stage.Les interlocuteurs seront les chefs de projets, les architectes techniques et les r√©f√©rents techniques du projet qui ont la charge d‚Äôassurer la bonne mise en ≈ìuvre fonctionnelle et technique de la solution.L'environnement technologique/fonctionnel :Environnement fonctionnel¬†:D√©couverte et mise en place du socle technique de Data Engineering √† la CNAMLa plateforme se destine aux Data Scientists de la CNAM leur permettant de valoriser leurs donn√©es, les explorer, les transformer, les restituer pour l‚Äôensemble de leurs cas d‚Äôusage m√©tier (donn√©es de sant√©, donn√©es de relation usager, donn√©es RH‚Ä¶)Environnement technique¬†:D√©ploiement¬†: Docker, OpenShift, HelmPIC : Gitlab, Gitlab CI/CDD√©veloppement¬†: Python, JavaOutillage Big Data¬†: Apache Spark, Apache Airflow, JupyterLes apports de l'alternance :D√©couvrir un m√©tier passionnant au sein du leader europ√©en de la transformation num√©rique.Comprendre les enjeux d'un projet et respecter ses engagements vis-√†-vis d'un client.Approfondir vos connaissances sur des technologies innovantes.√ätre form√©(e) aux technologies ainsi qu'aux m√©thodologies mises en ≈ìuvre par le Groupe.C√¥toyer des experts dans leurs domaines √† m√™me de vous guider dans vos premiers pas.Informations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, et des primes vacances.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.De tr√®s nombreuses opportunit√©s en CDI peuvent vous attendre √† l‚Äôissue de l'alternance.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Nantes", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop,", "technologiquespark,"], "ML_and_data_mining": null, "data_viz": ["tableau"], "statistics": null, "cloud_computing": null, "dev_tools": ["git/jenkins,", "git/jenkins,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["oozie/airflow,"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud,"], "raw_description": "Descriptif du posteVotre futur environnement de travailDans le cadre de la transformation du SI Post-Op√©rationnel vers l‚Äôoffre Big Data d‚Äôun acteur majeur du transport public, vous intervenez sur les phases de r√©alisation des solutions d√©livr√©es et sur les phases amont d‚Äô√©tudes :Etudes fonctionnelles et techniques ;Ingestion des flux de donn√©es ;Mod√©lisation et traitements des donn√©es ;Restitution et valorisation des donn√©es au sein de solution de data visualisation.Vous int√©grez donc le Centre de comp√©tences BI & Big Data qui accompagne notre client sur les technologies de traitement et de valorisation des donn√©es.Nos √©quipes √† taille humaine y m√®nent des projets Agiles, entour√©es de leaders techniques apportant leur expertise, au quotidien et lors de formations d√©di√©es. Ils vous encadreront sur vos missions, avec votre Project manager et tuteur d‚Äôalternance.Votre r√¥le et vos missionsVous serez compl√®tement int√©gr√©(e) √† l'√©quipe et participez aux activit√©s suivantes dans un contexte Agile :Prendre connaissance du contexte fonctionnel du projet ;Contribuer √† l'alimentation du tableau des fonctionnalit√©s (product backlog) ;R√©diger des documents de conception technique ;D√©veloppements et tests unitaires des traitements d'alimentation et de calcul ;Participer √† la validation de la livraison ;Participer aux instances Agiles.Les apports de l'alternanceD√©couvrir le framework Scrum.Approfondir votre connaissance des environnements Big Data.Concevoir des solutions industrielles √† forte plus-value m√©tier.Imaginer des usages de la donn√©e et d√©velopper sa force de proposition.Disposer d‚Äôun environnement de travail pr√©sentant une solide expertise technologique.Interagir au sein d‚Äô√©quipes multidisciplinaires.Environnement technologiqueSpark, Scala, Cloud, K8s, Oozie/Airflow, Power BI, Git/Jenkins, Suite Hadoop, Hive, ELK, AngularJS, Qlik SenseInformations suppl√©mentairesLes avantages √† nous rejoindre :Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, et des primes vacances.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.De tr√®s nombreuses opportunit√©s en CDI peuvent vous attendre √† l‚Äôissue de l'alternance.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Nantes", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["python,", "java,", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop,", "spark,", "spark", "databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["azure"], "dev_tools": ["digitaux", "digitale", "github", "gitlab,", "jenkins,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud.si", "cloudera,"], "raw_description": "Descriptif du posteVotre futur environnement de travail :Les Services Financiers Banque et Assurance sont au c≈ìur de la vie quotidienne de chacun. Sur ce secteur, Sopra Steria est un partenaire privil√©gi√© des grands acteurs du domaine afin de r√©pondre aux enjeux d‚Äôinnovations, d‚Äôadaptation des parcours digitaux et de transformation des Syst√®mes d‚ÄôInformations. Nous participons √† la r√©volution digitale gr√¢ce √† notre expertise en automatisation des processus, (Big) Data, IA, Cloud.Si vous √™tes passionn√©(e) par la valorisation de la donn√©e, rejoignez notre Agence Data localis√©e √† Nantes et les quelques 100 Data Ing√©nieurs qui la composent. En tant qu‚ÄôAlternant(e), vous int√©grez une √©quipe de 8/10 personnes au sein d‚Äôun plateau multi clients de projets¬†(Big)¬†Data. Vous √™tes accompagn√©(e) au quotidien par un tuteur de stage. Vous participez activement √† la vie quotidienne de l‚Äô√©quipe. Vous √™tes √©galement en liens √©troits avec le responsable de l‚Äô√©quipe et le leader technique de l‚Äô√©quipe.Votre r√¥le et vos missions :Int√©gr√©(e) dans les √©quipes projets, les principales activit√©s suivantes vous sont confi√©es :Comprendre les expressions de besoins techniques et fonctionnelles ;Contribuer √† la conception technique avec le support de votre tuteur(trice) et du r√©f√©rent technique de votre projet ;R√©aliser des traitements de collecte, transformation et stockage de la donn√©e ;R√©aliser des traitements de d‚Äôanalyse et de calcul sur les donn√©es ;R√©aliser des traitements de visualisation des donn√©es ;R√©aliser et automatisez les tests : unitaires et d'int√©gration (JUnit, ‚Ä¶)V√©rifier la coh√©rence du travail en √©quipe en suivant activement les Merge Requests de vos d√©veloppements ;Documenter vos travaux, capitaliser vos connaissances dans le Wiki de l‚Äô√©quipe ;R√©aliser les livraisons client en garantissant leur coh√©rence et leur compl√©tudes techniques et documentaires ;Respecter les bonnes pratiques de d√©veloppement et contr√¥ler la qualit√© du code produit des indicateurs de qualit√© ;Garantir la S√©curit√© Applicative en respectant les bonnes pratiques et en utilisant les contr√¥les Checkmarx ;Explorer les avantages de l‚ÄôIA Generative avec GitHub Copilot ;Contribuer √† l'am√©lioration des solutions, en lien avec toutes les personnes de l‚Äô√©quipe.Bien s√ªr, en fonction de vos souhaits d‚Äôapprentissage et en coh√©rence avec les besoins des projets, ces missions peuvent √©voluer au cours de votre alternance.Les apports de l'alternance :Tout au long de votre parcours, vous √™tes accompagn√©(e) par votre tuteur(trice) afin d‚Äôacc√©l√©rer le d√©veloppement de vos comp√©tences techniques et m√©thodologiques, de favoriser l‚Äôanticipation de la r√©daction de votre rapport et la pr√©paration de votre soutenance et finalement, de garantir le succ√®s de votre alternance.Vous √™tes form√©(e) √† nos process qualit√© et m√©thodes. Vous avez acc√®s aux Communaut√©s, √† tous types de certifications et √† nos plateformes de formation (e-learning, pr√©sentiel). Nous vous offrons la possibilit√© de capitaliser sur vos qualit√©s professionnelles et personnelles, d'√©voluer dans un environnement dynamique et convivial, sur des projets vari√©s.Technologies utilis√©es :¬†Spark, Spark UI, Kafka, Scala, hadoop, Hive/SQL, Oozie, Hue/HDFS, Ambari, GitLab, Jenkins, SonaQub, IntellJ, Eclipse, Nexus, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Python, RInformations suppl√©mentairesUn accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, et des primes vacances.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.De tr√®s nombreuses opportunit√©s en CDI peuvent vous attendre √† l‚Äôissue de l'alternance.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "La Defense", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "Banque, FinTech / InsurTech, Finance", "company_size": "117000", "creation_date": "1864", "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": "55", "proportion_male": null, "programming_languages": ["scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "aws", "aws"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud,", "cloud", "cloud."], "raw_description": "Descriptif du posteVous aimez suivre une innovation : de l'id√©e, √† sa maturation en passant par sa m√©thodologie d'impl√©mentation jusqu'√† sa livraison en production ? Vous avez un int√©r√™t pour le risque de cr√©dit ? Rejoignez-nous !Notre entit√© est le CSM (Centre de Solution M√©tier) en charge du syst√®me d'information permettant d'assurer la gestion des provisions,  ainsi que le d√©veloppement d'outils de mod√©lisation du risque de cr√©dit, de capacit√©s d'analyses avanc√©es et de stress test du risque de cr√©dit et de la solvabilit√© et d'une offre de d√©veloppement rapide pour accompagner les √©quipes risques.Dans le cadre du domaine Simulation Cr√©dit, nous sommes en cours de cr√©ation d'un nouvel √©cosyst√®me desservant les usages de simulation par la mise en place d'une plateforme de simulation de cr√©dit stress test qui : s'alimente des donn√©es Group Soci√©t√© G√©n√©rale (Datalakes), s'appuie sur le cloud AWS pour excuter les calculs de simulation de cr√©dit Groupe b√©n√©ficiant ainsi de la haute performance du Cloud, permet d'assurer des reportings Groupe r√©pondant √† diff√©rents usages (pilotage interne, reporting r√©glementaire, demandes adhoc ...).  Concr√®tement, et sous la supervision de votre tuteur(rice) et/ou manager, vous serez amen√©(e) √† : Participer √† la mise en place de cette plateforme  Proposer des solutions techniques  Travailler en √©troite collaboration avec les Data Ing√©nieurs et les Devops AWS pour industrialiser le proc√©d√© et produire des analyses op√©rationnelles Participer √† l'analyse complexe de donn√©es provenant de diff√©rentes sources Assurer une veille technologique permettant de tester de nouvelles fonctionnalit√©s et nouveaux outils Et si c‚Äô√©tait vous ?    Vous √™tes √©tudiant(e) de niveau Bac +4/5 en √©cole de Commerce, d'Ing√©nieur ou Universit√© avec une sp√©cialisation en Informatique, BigData. Vous √™tes int√©ress√©(e)s par les domaines autour du BigData dans un environnement innovant. Vous avez de bonnes connaissances en SCALA, SPARK, SQL. Id√©alement, vous avez des connaissances en Cloud AWS ou souhaitez monter en comp√©tence en Cloud.  Une curiosit√© technologique sera un plus pour s'adapter et pouvoir participer aux √©volutions possibles de la plateforme. Autonome, rigoureux(se), vous avez le sens du travail en √©quipe. Rejoignez notre √©quipe innovante !  You're fluent in english ! Vous √™tes notre candidat(e) id√©al(e) !   Pensez √† accompagner votre CV de votre planning de formation !  Plus qu'un poste, un tremplinD√®s votre arriv√©e, vous serez int√©gr√© dans nos √©quipes et apprendrez chaque jour aux c√¥t√©s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette exp√©rience un vrai acc√©l√©rateur de carri√®re. Vous d√©couvrirez √©galement toute la diversit√© de nos m√©tiers, dans un secteur qui √©volue et innove en permanence.A la fin de vos √©tudes, diverses opportunit√©s pourront s'offrir √† vous, en France et √† l'international.  Pourquoi nous choisir ?Attentif √† votre qualit√© de vie et conditions de travail, vous b√©n√©ficiez d'avantages : Prime* de participation et d'int√©ressement Jours de t√©l√©travail (selon le rythme de votre service et celui de votre alternance)  Prise en charge de 50% de votre titre de transport Billetterie √† prix r√©duits de notre Comit√© d'Entreprise (concerts, cin√©ma, sport...). Offre vari√©e de restaurants d'entreprise et de caf√©t√©rias √† tarifs comp√©titifs ainsi que des titres restaurants d√©mat√©rialis√©s quand vous √™tes en t√©l√©travail  *Si vous avez 3 mois d'anciennet√© sur l'exercice de r√©f√©rence Cr√©er, oser, innover, entreprendre font partie de notre ADN. Si vous aussi vous souhaitez √™tre dans l'action, √©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et d√©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !Vous h√©sitez encore ?Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidarit√© sur leur temps de travail : parrainer des personnes en difficult√© dans leur orientation ou leur insertion professionnelle, participer √† l'√©ducation financi√®re de jeunes en apprentissage ou encore partager leurs comp√©tences avec une association. Les formats d'engagement sont multiples.Nous sommes un employeur garantissant l'√©galit√© des chances et nous sommes fiers de faire de la diversit√© une force pour notre entreprise. Le groupe s'engage √† reconna√Ætre et √† promouvoir tous les talents, quels que soient leurs croyances, √¢ge, handicap, parentalit√©, origine ethnique, nationalit√©, identit√© de genre, orientation sexuelle, appartenance √† une organisation politique, religieuse, syndicale ou √† une minorit√©, ou toute autre caract√©ristique qui pourrait faire l'objet d'une discrimination.R√©f√©rence: 24000C7C  Entit√©: Fonctions centrales groupes  Date de d√©but: 02/09/2024   Date de publication: 30/04/2024"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-04-30", "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services", "company_size": "58", "creation_date": "2011", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de d√©veloppement √† l‚Äôinternational nous am√®nent √† renforcer notre √©quipe data en recrutant un Data Engineer (H/F).¬†Rattach√©(e) au Lead Dataflow, vos travaux d‚Äôinnovation et de recherche en data engineering permettront de faire √©voluer les produits de Lucky Cart, d‚Äô√©valuer au mieux leur performance et d‚Äô√©largir la palette de services connexes.Vos recherches pourront faire l‚Äôobjet de publications, de pr√©sentation dans des s√©minaires ou des meetups et de d√©p√¥ts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie int√©grante de la forte expansion de Lucky Cart en France et en Europe.Au c≈ìur de la soci√©t√©, vous collaborerez au quotidien avec toutes les √©quipes impliqu√©es (marketing, R&D, data et juridique) pour mener √† bien vos missions.MISSIONSSous la responsabilit√© du Lead Dataflow, vous aurez pour missions :D√©finir, d√©velopper et mettre en place et maintenir les outils et infrastructures ad√©quats √† la conception d‚Äôalgorithmes de data science et de recherche op√©rationnelle, int√©grant les contraintes li√©es √† des volumes de donn√©es tr√®s importants, √† des mod√®les de grande dimension, au temps r√©el, ainsi qu‚Äô√† la s√©curit√©, la disponibilit√© et la performance,D√©ployer des pipelines de donn√©es et les mod√®les ci-dessus en production notamment¬† en concevant et en d√©veloppant une architecture en micro-services,Assurer la fiabilit√© des pipelines de donn√©es, des processus ETL et de la transformation des donn√©es en r√©alisant et en mettant en ≈ìuvre des tests manuels et automatis√©s,√ätre force de proposition sur tous les sujets d‚Äôarchitecture et de mod√©lisation,Participer √† l‚Äôam√©lioration des √©tapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribu√©s, d√©veloppement d‚Äôoutils, mise en production, et tests, data lineage,√ätre force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la soci√©t√© (marketing, R&D, Sales, Produit),Assurer un reporting r√©gulier de l‚Äôactivit√©."}
{"job_title": null, "contract_type": "Stage", "salary": "1,2K √† 1,8K¬†‚Ç¨ par mois", "company": null, "location": "Boulogne-Billancourt", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "Digital Marketing / Data Marketing, Publicit√©, Digital", "company_size": "200", "creation_date": "2015", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "31", "proportion_female": "45", "proportion_male": null, "programming_languages": ["python", "python", "python,"], "databases": ["bigquery", "bigquery.collaborer"], "data_analyze": ["pandas,"], "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["(gcp)"], "dev_tools": ["github"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["afterworks/teams"], "skills": ["cloud", "cloud", "cloud", "cloud", "cloud", "cloud", "cloudnotre"], "raw_description": "Descriptif du posteInt√©gr√© √† l‚Äô√©quipe Data, tu seras responsable de la cr√©ation des connecteurs de donn√©es et de la collecte de donn√©es sur BigQuery en utilisant des outils tels que GitHub Actions, Google Cloud Platform (Artifact Registry, Cloud Run, Cloud Scheduler).Tu travailleras en √©troite collaboration avec l‚Äô√©quipe de d√©veloppement et les autres membres de l‚Äô√©quipe pour d√©velopper, tester et d√©ployer des solutions de collecte de donn√©es efficaces et fiables Ce r√¥le t‚Äôoffrira une opportunit√© unique de contribuer √† des projets de donn√©es d‚Äôenvergure et de d√©velopper des comp√©tences en ing√©nierie de donn√©es et en d√©veloppement Python dans un environnement professionnel.Concr√®tement, tes missions seront les suivantes :Cr√©er et maintenir les connecteurs de donn√©es n√©cessaires pour collecter les donn√©es √† partir de diff√©rentes sources vers BigQuery.Collaborer avec l‚Äô√©quipe de d√©veloppement pour concevoir, d√©velopper, tester et d√©ployer des solutions de collecte de donn√©es bas√©es sur Python et les meilleures pratiques d‚Äôing√©nierie de donn√©es.Utiliser les outils de Google Cloud Platform (GCP) tels que Artifact Registry, Cloud Run et Cloud Scheduler pour d√©ployer et automatiser les flux de travail de collecte de donn√©es.Collaborer avec les autres membres de l‚Äô√©quipe pour comprendre les besoins en donn√©es et garantir la qualit√©, la fiabilit√© et la s√©curit√© des donn√©es collect√©es.R√©soudre les probl√®mes et les d√©fis techniques li√©s √† la collecte de donn√©es et aux connecteurs de donn√©es, en proposant des solutions et en effectuant des tests pour valider les performances et la qualit√© des donn√©es collect√©es.Documenter les processus de collecte de donn√©es, les connecteurs de donn√©es et les flux de travail automatis√©s pour faciliter la maintenance et la compr√©hension des solutions de collecte de donn√©es.Les +Exp√©rience pr√©alable dans le d√©veloppement de connecteurs de donn√©es ou de flux ETL.Connaissance des meilleures pratiques de d√©veloppement Python, des biblioth√®ques de traitement de donn√©es telles que Pandas, et des outils de d√©veloppement comme PyCharm ou Visual studio code.Exp√©rience avec l‚Äôutilisation des services de Google CloudNotre offre :Type de contrat : contrat d‚ÄôalternanceR√©mun√©ration : 1200 √† 1800 euros selon profilAvantages : carte Swile pour les repas, remboursement des frais de transports √† hauteur de 50%, t√©l√©travail partiel possibleDate de d√©marrage : septembre 2024Pourquoi nous rejoindre ? Tu travailleras dans une ambiance bienveillante avec de l‚ÄôautonomieTu rejoindras une entreprise en forte croissance qui ambitionne de devenir un leader europ√©enTu travailleras dans un environnement multiculturelTu b√©n√©ficieras de supers avantages : set up pour travailler dans les meilleures conditions, afterworks/teams buildings r√©guliers, corbeille de fruits et snacks hebdomadaires, cantine Frichti"}
{"job_title": null, "contract_type": "CDI", "salary": "50K √† 70K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "20", "creation_date": "2019", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "1 500 000", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNous souhaitons accueillir un¬∑e Senior Data Engineer pour intervenir chez nos clients et contribuer au d√©veloppement de Modeo.Tu rejoindras une √©quipe en pleine croissance pour intervenir sur des projets offrant l‚Äôopportunit√© de monter en comp√©tences et en responsabilit√©s. En tant que Senior Data Engineer, tu pourras travailler avec l‚Äôensemble des outils de la Modern Data Stack, sur une grande vari√©t√© de projets comprenant la mise en place de Data Platforms, le d√©veloppement d‚Äôapplications data avanc√©es et la cr√©ation de pipelines de donn√©es. Au cours de ces projets, tu seras r√©guli√®rement amen√©¬∑e √† travailler avec des √©quipes m√©tier et √† pr√©senter et vulgariser ton travail.Tes responsabilit√©s seront les suivantes :Mettre en place des infrastructures de donn√©es pour des clients ou des projets de Modeo, en collaboration avec d‚Äôautres membres de l‚Äô√©quipeEncadrer des projets internes et accompagner nos Data Engineers dans leur mont√©e en comp√©tencesD√©velopper et optimiser les flux de donn√©es depuis l‚Äôextraction de donn√©es brutes jusqu‚Äô√† leur activationD√©ployer des solutions dataTravailler avec des √©quipes m√©tier pour comprendre et d√©finir leurs besoins puis leur mettre √† disposition des solutions adapt√©esMettre en place les bonnes pratiques de DataOps, Data Management et DevOps au sein des entreprisesParticiper au recrutement, √† la veille technique, √† la strat√©gie de Modeo et √† la mise en place de nouvelles offres"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Puteaux", "remote": "T√©l√©travail occasionnel", "experience": "> 10", "education_level": null, "publication_date": "2024-04-30", "sector": "Logiciels, IT / Digital, Big Data", "company_size": "601000", "creation_date": "1968", "address": null, "average_age_of_employees": null, "turnover_in_millions": "$ 29 milliards", "proportion_female": "36", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteSommaire du poste :En tant que Data Integration Architect & Bid Manager, vous jouerez un r√¥le central en combinant une expertise approfondie en int√©gration de donn√©es avec des comp√©tences strat√©giques en gestion des offres commerciales. Vous serez responsable de la conception, du d√©veloppement et de la mise en ≈ìuvre d‚Äôarchitectures d‚Äôint√©gration de donn√©es robustes, tout en prenant en charge la gestion compl√®te des propositions commerciales strat√©giques, du concept initial au d√©ploiement final. Cette position exige une solide exp√©rience technique dans les technologies d‚Äôint√©gration de donn√©es ainsi qu‚Äôune capacit√© √©prouv√©e √† conseiller nos clients sur les meilleures pratiques, tout en dirigeant des initiatives de proposition commerciale avec une approche consultative."}
{"job_title": null, "contract_type": "Stage(4 √† 6 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-30", "sector": "Intelligence artificielle / Machine Learning, Strat√©gie, Big Data", "company_size": "40", "creation_date": "2017", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["statistiques"], "raw_description": "Descriptif du posteLors de ce stage, vous serez impliqu√©(e) dans un ou plusieurs projets, avec des missions vari√©es et stimulantes :Analyse de besoins clients complexes et r√©alisation d‚Äôanalyses quantitatives avec un focus sur la gestion des donn√©es.Cr√©ation de pipelines de donn√©es efficaces pour l‚Äôint√©gration et le traitement des donn√©es.D√©veloppement de dashboards interactifs et visuellement impactants en datavisualisation.Participation √† la conception et √† l‚Äôimpl√©mentation de mod√®les statistiques et de machine learning.Gestion et manipulation de diverses bases de donn√©es pour soutenir le processus de data engineering.√âlaboration de supports de restitution des r√©sultats, mettant en valeur vos comp√©tences en datavisualisation.Pr√©sentation du fruit de votre travail de fa√ßon didactique √† votre client avec les autres membres de l‚Äô√©quipe projetContribuer au d√©veloppement du cabinet"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Montpellier", "remote": "T√©l√©travail non autoris√©", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2024-04-30", "sector": "IT / Digital", "company_size": "49000", "creation_date": "1997", "address": null, "average_age_of_employees": null, "turnover_in_millions": "5,6 milliards ‚Ç¨", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteAu sein de l‚Äô√©quipe du P√¥le data de Montpellier, vous participer aux activit√©s d‚Äôint√©gration et de traitement de la donn√©e sur nos projets IA et Big Data.Vous participerez aux travaux pour nos clients sur la mise en place d‚Äôoutil allant du prototype √† la solution industrialis√© sur des sujets comme :¬† La conception et d√©veloppement des briques logicielles d‚Äôimpl√©mentation des briques IA et de gestion de flux de donn√©. Participez aux diff√©rents rituels de gestion de projet (Agile, ou cycle en V). R√©digez les documentations techniques¬† Assurez une veille technologique autours de la donn√©e et de son traitement. ¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Saint-Herblain", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-04-30", "sector": "IT / Digital, Supply Chain, SaaS / Cloud Services", "company_size": "1500", "creation_date": "1984", "address": null, "average_age_of_employees": "38", "turnover_in_millions": "156 millions d'euros en 2022", "proportion_female": "30", "proportion_male": null, "programming_languages": ["(python,", "java,", "javascript)vous"], "databases": null, "data_analyze": null, "big_data_tools": ["(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["awsvous", "gcp"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "cloudvous"], "raw_description": "Descriptif du posteAu sein de notre entit√© Business Applications nantaise et int√©gr√© au sein d‚Äôune √©quipe projet, vous contribuez √† l‚Äô√©laboration et l‚Äô√©volution des couches m√©tiers des applications que nous r√©alisons pour nos clients.En tant que Cloud Data Engineer, vous participez √† des projets innovants √† forte valeur ajout√©e pour nos clients, √† la fois technologique et m√©tier. Entour√© de d√©veloppeurs, lead d√©veloppeur, architecte et Scrummaster, vous travaillez en m√©thode agile (Scrum). Notre vision du Cloud Data Engineer  :Vous √™tes capable d‚Äôappr√©hender un contexte client et d‚Äôimpl√©menter une plateforme pour valoriser sa donn√©eVous avez d√©j√† une exp√©rience sur GCP ou AWSVous √™tes √† l‚Äôaise sur l‚Äôun des langages suivants (Python, Java, JavaScript)Vous avez d√©j√† utilis√© un framework de calculs distribu√© (Spark, Beam, ‚Ä¶)Vous connaissez et utilisez les diff√©rentes solutions de stockage (SQL, NoSQL, Search Engine‚Ä¶)Vous maitrisez les principes du d√©veloppement CloudVous avez des connaissances en machine learning"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services", "company_size": "67", "creation_date": "2019", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["slack,", "teams", "teams", "teams", "teams", "teams"], "skills": ["ml", "ml", "ci/cd-"], "raw_description": "Descriptif du posteModjo:Modjo is the leader European AI Revenue Platform whose mission is to drive revenue teams productivity & performance with AI-extracted knowledge from customers interactions.While AI is challenging how companies work across the world and all industries, Modjo brings these new capabilities to sales teams thanks to a platform that analyzes all interactions sales people have with their customers to improve sales teams productivity, drive strategy, and increase revenue. We are a growing team of over 65 people, helping over 400 clients like BouyguesTelecom, Doctolib, Spendesk and Payfit in France and abroad. üåéJust like Slack, Zoom or Hubspot, Modjo is a product company. This means that our product is the core of what we are doing and how we are creating value to customers. Therefore, the success of the company relies on the capacity of its Tech & Product teams to deliver together the best product to its users.Team organization :¬†The overall tech department is composed of 10 Software Engineers (2 squads), 2 ML Engineers, a Data Team (1 team lead + 1 analyst) and the CTO. You will be part of the Data Science team alongside the other ML Engineers.Mission:Modjo's core capabilities include capturing conversations between sales teams and their customers (video & audio recordings, emails..) and leveraging this data thanks to speech-to-text and various LLM-based processings to extract and structure data out of it. As part of this, your main missions will be: - Collaborating with Product and Engineering to build features that require machine-learning expertise- Build, maintain and optimize our infrastructure for doing production machine learning including our speech-to-text stack (processing thousands of hours of audio every day) and our infrastructure for using LLMs- Design and implement processes, tools and pipelines in order to work efficiently with LLMs for our multiple use cases- Stay up to date with latest speech-to-text and LLM technologies in order to include them in the product and build the relevant technological asset for Modjo to differentiate from basic competition. This includes exploring model-finetuning models and RAGs. Your profile :We think you would be a great fit if :- You have 3y+ experience in Machine Learning and Engineering- You have experience working with and knowledge about NLP, LLM and speech-to-text- You have experience with putting models in production, including monitoring and CI/CD- You are interested in solving real world use cases with LLMs and building the proper technology around it- You are eager to learn a lot in an autonomous way, both in Science and Engineering fields- You are willing to work in English (language of the team)- You want to join a company where the product you will be building is core to our strategy- You are looking for a challenging job, but also an environment where you can thrive and have fun on a day-to-day basis :)We are looking for someone who will thrive and share our values:üòÉ¬†Pleasure‚ÄúIf you Smile, things will work out‚Äù - Serena Williams‚úÖ¬†Action‚ÄúDone is better than perfect‚Äù - Sheryl Sandbergüìö Continuous Learning‚ÄúAmateurs call it Genius, masters call it practice‚Äù - Thierry Henryü§≤ Team Spirit‚ÄúGreat things in business are never done by one person; they‚Äôre done by a team of people‚Äù - Steve Jobs"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Bordeaux", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Application mobile", "company_size": "1050", "creation_date": "2005", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "835", "proportion_female": null, "proportion_male": null, "programming_languages": ["environmentpython", "python,", "java,", "scalabilit√©", "scalabilit√©vous", "scala,"], "databases": ["flinksnowflake"], "data_analyze": null, "big_data_tools": ["flinksnowflake"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["serverlessawsairflow,"], "dev_tools": ["github", "dockerjira", "sql</li><li>docker,", "dbtjenkins"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["serverlessawsairflow,"], "IaC": ["terraform"], "security_and_network": null, "virtualization": null, "containers": ["dockerjira", "sql</li><li>docker,"], "collaboration": ["dockerjira", "confluencewho"], "skills": ["ml", "mlops)", "cloud", "<ol><li>cloud"], "raw_description": "Descriptif du posteWE ARE BETCLICEntreprise fran√ßaise leader en Europe sur les paris sportifs et les jeux en ligne, Betclic c'est :‚Ä¢ ‚Äç‚Äç 11 millions de joueurs vibrants au rythme des comp√©titions sportives ‚Ä¢ ‚≠ê Une offre tr√®s large de paris sportifs, de poker, de jeux de casino et de paris hippiques en ligne‚Ä¢    ‚öΩ Plus de 50 sports ouverts aux paris ‚Ä¢   300 000 √©v√®nements sportifs disponibles aux paris chaque ann√©e ‚Ä¢     60 000 √©v√®nements sportifs diffus√©s en live chaque mois ‚Ä¢    Plus de 3 000 jeux de casino √† exp√©rimenter‚Ä¢     Plus de 2 millions de parties de poker jou√©es chaque mois‚Ä¢   De nombreux partenariats officiels en France tels que la FFF, Ligue 1 Uber Eats, la Coupe de France, le Top 14 de Rugby (LNR), la Betclic Elite en basket-ball (LNB), l'UBB, les Boxers de Bordeaux‚Ä¶Depuis sa cr√©ation en 2005, Betclic est une soci√©t√© de technologie \"mobile-only\", anim√©e par une passion in√©branlable pour le sport. Guid√© par l'√©motion et le plaisir du jeu, Betclic d√©veloppe des applications de divertissement mobile et place ses clients au c≈ìur d'une exp√©rience de jeu unique en innovant avec agilit√© et rapidit√© pour offrir toujours plus de jeux et plus de fun √† ses joueurs. Notre ambition ? Proposer √† nos clients l'exp√©rience de jeu la plus divertissante gr√¢ce √† des applications simples, immersives et innovantes.Betclic, dont le si√®ge est √† Bordeaux, est une entreprise multiculturelle et internationale qui compte plus de 38 nationalit√©s parmi ses 800 collaborateurs r√©partis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal. Les profils recherch√©s sont ceux qui ont l'ambition de construire en √©quipe, qui sont pr√™ts √† relever des challenges tous plus passionnants les uns que les autres, et qui ont cette volont√© de cr√©er des solutions offrant une exp√©rience client in√©dite. L'univers du sport et du jeu vous fait vibrer ? Vous aimez les d√©fis et participer √† l'effort collectif ? Betclic vous propose de rejoindre l'aventure !#JoinBetclic #WeAreBetclicENTER THE GAMELes √©quipes Tech Betclic sont organis√©es autour des principes de d√©veloppement agiles et s'organisent en squad et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique. Gr√¢ce √† cette organisation vous b√©n√©ficierez de la responsabilit√© de A √† Z de vos projets : d√©veloppement, livraison, suivi de production. You build it, you run it ! Dans ce contexte nous recherchons un Data Engineering Manager, qui prendra en charge l'√©quipe Data Platform compos√©e de DataOps / Data Engineer, ML Ops dont le r√¥le est de garantir la disponibilit√© de la plateforme data et mettre en place les outils et bonnes pratiques autour de la data.YOUR ROLE WITHIN BETCLIC√Ä ce titre, tes missions sont les suivantes‚ÄØ:Manager une √©quipe data (DataOps, Data Engineer, MLOps) - en charge des entretiens de recrutement, des entretiens de performance, one&one avec l'√©quipe etc.. Animer l'√©quipe Data Platform et les c√©r√©monies agile, alimenter le backlog et d√©finir les sprint planningAnalyser les besoins et √©tudier la faisabilit√© technique¬†Arbitrer les priorit√©s selon les objectifs fix√©s par le Head of Engineering¬†Valider les cahiers des charges techniquesEtablir le planning et d√©finir les ressources n√©cessaires √† la r√©alisation des t√¢chesGarantir la fiabilit√© des d√©veloppements, la r√©silience, la scalabilit√© des services op√©r√©sContr√¥ler et garantir l'atteinte des objectifs des projets√ätre garant du respect des bonnes pratiques, de la s√©curit√© et de la gouvernanceTravailler en √©troite collaboration avec les Leader Techniques et les diff√©rentes √©quipesTECHNICAL ENVIRONMENTPython / Terraform / ServerlessAWSAirflow, FlinkSnowflake / dbtJenkins / Github / Datadog / DockerJira / ConfluenceWHO WE ARE LOOKING FOR?Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, [un amour pour la technique], un peu de z√®le et une r√©elle passion pour leur m√©tier !Ce job est fait pour vous si :Vous √™tes dipl√¥m√©(e) d'une √©cole d'ing√©nieur, √©cole informatique, MIAGEVous disposez d'une exp√©rience professionnelle dans des projets data engineering de type Data Lake, Data Streaming, Pipelines data dans un environnement Cloud PublicVous avez une exp√©rience en tant que lead technique et avez ou souhaitez manager tout en conservant une maitrise technique des services d√©velopp√©s et op√©r√©sVous √™tes sensible √† la performance, la fiabilit√©, la maintenabilit√© et la scalabilit√©Vous ma√Ætrisez ou avez de l'exp√©rience dans les technologies suivantes :            <ol><li>Cloud public et serverless</li><li>Pipeline Data et Data Streaming</li><li>Language : Python, Scala, Java, SQL</li><li>Docker, CICD</li></ol>            <p>Et enfin, vous parlez anglais couramment</p><p></p><p><strong>WHAT CAN YOU EXPECT?</strong></p><ul><li>Un package de r√©mun√©ration attractif</li><li>25 jours de cong√©s pay√©s et 10 jours de repos compensateurs</li><li>Une carte Ticket Restaurant¬Æ financ√©e √† hauteur de 50% (10‚Ç¨/ jour)</li><li>Une mutuelle d&#39;entreprise prise en charge √† 100% pour vous et vos enfants </li><li>Un abonnement de transport pris en charge √† hauteur de 50% ou une prime annuelle de mobilit√© durable (200‚Ç¨ pour les trajets domicile ‚Äì travail en transport durable)</li><li>Un pack mobilit√© (aide au d√©m√©nagement) </li><li>Une flexibilit√© de travail encadr√©e par un accord sur le t√©l√©travail</li><li>Un souci constant de d√©veloppement des comp√©tences avec un programme de formation annuel personnalis√©</li><li>Des √©volutions de carri√®re dans un environnement international</li><li>Des locaux hors du commun avec un rooftop am√©nag√© pour profiter d&#39;animations r√©guli√®res, de pauses et de d√©jeuners au soleil face √† la Cit√© du Vin</li><li>Des cours de sports 2 fois par semaine</li></ul><p>*Et l&#39;opportunit√© de travailler dans une atmosph√®re conviviale, jeune et fun !</p><p>Poste en CDI √† pourvoir d√®s que possible √† Bordeaux</p><p>Betclic Group - 117 quai de Bacalan 33300 BORDEAUX </p><p>Tous nos postes sont ouverts aux personnes en situation de handicap.</p>"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 5", "education_level": null, "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travail : Chez notre client, grande banque commerciale fran√ßaise, vous int√©grez nos squads¬†pour intervenir sur des projets de grande envergure, des projets transformants et structurants de la banque de demain. Vous interviendrez sur la gestion d‚Äôapplications sur des domaines tels que¬†: la conformit√©, la fraude, la lutte anti-blanchiment, les risques de cr√©dit, la tr√©sorerie, les paiements, les financements structur√©s ou encore le r√©glementaire bancaire.Au sein de notre Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l'occasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.¬†Votre r√¥le et vos missions : Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es;Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles;Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.Additional InformationCe que nous vous proposons : Un accord t√©l√©travail pour t√©l√©travailler jusqu'√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'int√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy..La possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L'opportunit√© de rejoindre le collectif Tech'Me UP (formations, conf√©rences, veille, et bien plus encore).¬†¬†Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Prague", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": "Sans dipl√¥me", "publication_date": "2024-04-29", "sector": "Digital", "company_size": "532", "creation_date": "1994", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "4.685.583 tis CZK", "proportion_female": "55", "proportion_male": null, "programming_languages": ["pythonu"], "databases": null, "data_analyze": null, "big_data_tools": ["databricks"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["azure"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du postePopisJsme datovƒõ-analytick√© oddƒõlen√≠ v‚ÄØmedi√°ln√≠ divizi Publicis Groupe. Na≈°i kolegov√© vyu≈æ√≠vaj√≠ n√°mi zpracovan√° data pro pokroƒçil√© pl√°novan√≠ a vyhodnocov√°n√≠ medi√°ln√≠ch kampan√≠ i pro pr√°ci s‚ÄØna≈°imi datov√Ωmi produkty.  Hled√°me ƒçlovƒõka na post team leadera datov√Ωch engineer≈Ø. V‚ÄØtomto t√Ωmu budujeme firemn√≠ datovou infrastrukturu, vytv√°≈ô√≠me automatizaƒçn√≠ miniaplikace a mak√°me na projektech, kter√© zjednodu≈°uj√≠ ≈æivot v≈°ech na≈°ich koleg≈Ø i klient≈Ø.‚ÄØ Hled√°me kolegu, kter√Ω n√°m pom≈Ø≈æe posunout na≈°i infrastrukturu na vy≈°≈°√≠ √∫rove≈à ‚Äì od vƒõt≈°√≠ integrace DevOps, monitorov√°n√≠ kvality dat, a≈æ po optimalizaci datov√Ωch pipeline.‚ÄØ¬†Co tƒõ u n√°s ƒçek√°? Veden√≠ t√Ωmu cca 4 datov√Ωch engineer≈Ø (senior/junior), √∫zk√° spolupr√°ce s‚ÄØdal≈°√≠mi datov√Ωmi i byznys t√Ωmy Rozvoj a √∫dr≈æba na≈°e datov√© infrastruktury, vytv√°≈ôen√≠ ETL/ELT pipeline v‚ÄØprost≈ôed√≠ Kebooly, Azure Databricks a Data Factory s‚ÄØvyu≈æit√≠m Pythonu a SQL‚ÄØ Pr√°ce na datov√Ωch produktech ‚Äì spolupr√°ce s‚ÄØdatov√Ωmi analytiky, data science t√Ωmem a uv√°dƒõn√≠ nov√Ωch produkt≈Ø do produkce‚ÄØ Vytv√°≈ôen√≠ automatizaƒçn√≠ch miniaplikac√≠ v‚ÄØDashi, Djangu a jin√Ωch frameworc√≠ch, jejich≈æ dopad do firmy uvid√≠≈° okam≈æitƒõ‚ÄØ Nauƒç√≠≈° se z√°kladn√≠ principy online & offline marketingu a z√°kladn√≠ orientaci v‚ÄØn√°stroj√≠ch, na kter√Ωch stoj√≠ n√°≈° automatick√Ω reporting ‚Äì Adform, Google Ads, Meta, Sklik, GMP a dal≈°√≠¬†Po≈æadujemeCo m≈Ø≈æeme nab√≠dnout? Propracovan√Ω onboarding a brut√°lnƒõ efektivn√≠ on-the-job‚ÄØ Mo≈ænost osobn√≠ho a‚ÄØprofesn√≠ho rozvoje prost≈ôednictv√≠m ≈°kolen√≠, a≈• u≈æ na t√©ma dat a‚ÄØanalytiky nebo m√©di√≠, prezentov√°n√≠ a vyjedn√°van√≠‚ÄØ Rozv√≠jen√≠ kompetenc√≠ pro veden√≠ lid√≠ / t√Ωmu skrze form√°ln√≠ i neform√°ln√≠ ≈°kolen√≠ ƒçi kouƒçink Pr√°ce v office pln√©m skvƒõl√Ωch lid√≠, p√°r ps≈Ø a hlavnƒõ skvƒõl√Ωch projekt≈Ø‚ÄØ Kolektiv s neform√°ln√≠ kulturou, pozn√°≈° spoustu zaj√≠mav√Ωch lid√≠ nap≈ô√≠ƒç obory ‚Äì kreativce, developery ƒçi projek≈•√°ky a m≈Ø≈æe≈° se zapojit do v≈°eho, co se ve firmƒõ dƒõje‚ÄØ Pr√°ce v modern√≠ch prostorech, kde si m≈Ø≈æe≈° oddechnout u fotb√°lku, ≈°ipek nebo PS, s venkovn√≠ terasou‚ÄØ¬†Nab√≠z√≠me‚ÄØBenefity‚ÄØ:3 dny My days a tak√© organizujeme in-house dny zdrav√≠. Pokud onemocn√≠≈°, doplat√≠me ti nemocenskou do sta procent (21 dn√≠/rok)‚ÄØ Benefitn√≠ bal√≠ƒçek, ze kter√©ho si s√°m vybere≈°, co ti vyhovuje (po zku≈°ebce, v hodnotƒõ 15tis. Kƒç/rok). ‚ÄØ Firemn√≠ chata ‚Äì t√Ωmovƒõ i samostatnƒõ m≈Ø≈æe≈° odjet pracovat nebo relaxovat na na≈°i firemn√≠ chatu‚ÄØ R√°di pom√°h√°me, a tak m√° ka≈æd√Ω mo≈ænost vyu≈æ√≠t dobrovolnick√Ω den‚ÄØ Mobil s‚ÄØfiremn√≠m tarifem a cokoliv co pot≈ôebuje≈° k‚ÄØpr√°ci‚ÄØ Dve≈ôe do analytick√©ho nebe jsou otev≈ôeny!‚ÄØ Prvn√≠ krok je na tobƒõ‚ÄØ ¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Theix-Noyalo", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Grande distribution, Agroalimentaire / Nutrition animale", "company_size": "8500", "creation_date": "2020", "address": null, "average_age_of_employees": "42", "turnover_in_millions": "3,1 milliards d'euros", "proportion_female": "40", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteRattach√© au Manager Equipe BI de la DSI du Groupe, vos missions sont orient√©es vers la mise en place et la maintenance des syst√®mes et outils utilis√©s pour la collecte, l'analyse et la visualisation des donn√©es dans le but d'aider les m√©tiers du Groupe √† prendre des d√©cisions pertinentes.Vous travaillez en √©troite collaboration avec les utilisateurs de la donn√©e, pour comprendre leurs besoins en mati√®re de reporting d√©cisionnel et vous apportez les solutions techniques pour y r√©pondre.Vous √™tes charg√© de concevoir et de d√©ployer des architectures de stockage de donn√©es optimis√©es pour l'analyse et le reporting, allant de la mise en ≈ìuvre de datawarehouse d'entreprise (type datalake) √† celle de datamarts structur√©s et sp√©cialis√©s par domaine d'activit√© de l'entreprise.Vous √™tes responsable de l'int√©gration de donn√©es provenant des diff√©rentes applications m√©tiers, permettant de fournir une vue consolid√©e et coh√©rente des donn√©es √† des fins d'analyse. Votre responsabilit√© va de l'extraction de donn√©es √† leur chargement dans les entrep√¥ts, en garantissant la mise √† disposition, dans un d√©lai convenu, d'une donn√©e conforme √† la donn√©e des outils sources.Afin de garantir un service performant dans la dur√©e, vous √™tes charg√© de contr√¥ler l'usage des outils d'ingestion et de datavisualisation, la performance des requ√™tes et des rapports utilis√©s, et l'ad√©quation continue du dimensionnement des infrastructures qui les h√©bergent. "}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Levallois-Perret", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "160", "creation_date": "1992", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "23 millions ‚Ç¨", "proportion_female": null, "proportion_male": null, "programming_languages": ["python", "java,", "scala"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams"], "skills": ["cloud,", "cloud,"], "raw_description": "Descriptif du posteNous recrutons un Consultant Data / Data Engineer qui √©voluera au sein d‚Äôun environnement Data & Analytics, d‚Äôune culture DevOps et des contextes fonctionnant en mode Agile.En tant que Consultant Data, vous intervenez sur des probl√©matiques m√©tiers autour de la gestion des donn√©es. En collaboration avec les architectes data, les data analysts, les teams DevSecOps, infra et cloud, vous serez amen√© √† mettre en place des solutions et des plateformes data (datahub, datalake, streaming platform, event-driven pipeline, ‚Ä¶), d√©velopper, d√©ployer et maintenir des chaines de transformations data.La r√®gle d‚Äôor : collecte et int√©gration, stockage, traitement et stockage, mise √† disposition pour analyse et reporting.Vous maitrisez java, python et/ou scala et avez une exp√©rience significative sur un projet data. V√©ritable adepte des pratiques devops et cloud, la maitrise de kafka serait un atout."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Courbevoie", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["python,", "java),", "scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop)", "(spark,", "pyspark"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "ci/cd"], "raw_description": "Descriptif du posteCompany Description Sopra Steria, l‚Äôun des leaders europ√©ens de la Tech reconnu pour ses activit√©s de conseil, de services num√©riques et d‚Äô√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d‚Äôactivit√© et des technologies innovantes √† une approche r√©solument collaborative.Sopra Steria place l‚Äôhumain au centre de son action et s‚Äôengage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif.Fort de 50 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d‚Äôaffaires de 5,8 milliards d‚Äôeuros en 2023.The world is how we shape it.Job Description Notre Data FactoryVous √™tes passionn√©(e) par la valorisation de la donn√©e, rejoignez notre Data Factory localis√©e √† Paris ! Vous y rencontrerez des experts de la mise en ≈ìuvre de Plateforme de Donn√©es, des Data Architectes ou autres experts solution autour des probl√©matiques de valorisation de la donn√©e.Vous √™tes accompagn√©(e) au d√©veloppement de vos connaissances aux travers de diff√©rents parcours Data que ce soit pour l‚Äôingestion, la construction de datahub, la transformation et valorisation de la donn√©e, la mod√©lisation et mise √† disposition.Rejoindre notre Data Factory Sopra Steria, c‚Äôest rejoindre une communaut√© de Data Ing√©nieurs fiers de partager leur savoir et ouverts aux nouvelles exp√©riences et exp√©rimentations de la donn√©e.Votre r√¥le et mission :Dans le cadre de la mise en place du centre Data pour un grand acteur financier de l‚Äô√©tat et selon votre app√©tence, vous participerez √† plusieurs √©tapes de la cha√Æne :- La compr√©hension des besoins m√©tiers et la traduction solution de data ing√©nierie- La mise en ≈ìuvre de solution d‚Äôingestion des donn√©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;- La structuration du DataLake, la mise en place des processus de gouvernance et de s√©curisation des donn√©es ;- Le traitement de la donn√©e jusqu‚Äô√† l‚Äôexposition au m√©tier ;- La mise en place de la chaine CI/CD et de sa supervision ;- La veille technologie avec nos partenaires √©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d‚Äôid√©ation pour nos clients.Qualifications Dipl√¥m√©(e) d‚Äôune Ecole d‚Äôing√©nieur ou formation √©quivalente, vous avez d√©j√† particip√© √† un projet Data (Big Data, BI) et vous avez une exp√©rience de minimum 3 ans.Vous maitrisez un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (SQL, Scala, R, Python, Java), le traitement distribu√© de donn√©es (Spark, Pyspark , Hadoop) et un Framework de streaming de donn√©es (Kafka, RabbitMQ, etc.)Vous √™tes attir√©(e) par le monde du num√©rique, le Cloud et des technologies innovantes.Vous avez un bon esprit d‚Äôanalyse, √™tes curieux(se) et passionn√©(e) et vous avez le sens du travail en √©quipe dans une organisation Agile type Srcum ou SAFEVous accordez une importance particuli√®re au d√©veloppement de vos comp√©tences sur plusieurs technologies. Vous souhaitez une √©volution r√©elle de carri√®re √† travers l‚Äôexp√©rience projet. Vous √™tes soucieux de l‚Äôapport de valeur pour vos clients. Et vous voulez transmettre votre savoir aupr√®s de collaborateurs moins exp√©riment√©s. Alors, n‚Äôattendez-plus, ce poste est fait pour vous !Additional Information Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s‚Äôengager aupr√®s de notre fondation ou de notre partenaire ¬´ vendredi ¬ª.L‚Äôopportunit√© de rejoindre le collectif Tech‚ÄôMe UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Courbevoie", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": ["hadoop)ma√Ætrise", "(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "(azure,"], "dev_tools": ["digitale", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "ci/cd"], "raw_description": "Descriptif du posteDescription de l‚Äôentreprise Sopra Steria, acteur majeur de la Tech en Europe, reconnu pour ses activit√©s de conseil, de services num√©riques et d‚Äô√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d‚Äôactivit√© et des technologies innovantes √† une approche r√©solument collaborative.Sopra Steria place l‚Äôhumain au centre de son action et s‚Äôengage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif.Fort de 50 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d‚Äôaffaires de 5,8 milliards d‚Äôeuros en 2024.The world is how we shape itDescription du poste Votre futur environnement de travail :Au sein de notre Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l‚Äôoccasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.Votre r√¥le et vos missions :Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es ;Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles ;Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins ;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.Qualifications Votre profil :De formation Master 2 Ecole d‚ÄôIng√©nieurs ou Informatique, ou √©quivalent, vous justifiez d‚Äôune exp√©rience technique de 3 ans minimum et souhaitez √©voluer rapidement dans un contexte motivant.Vous avez au moins l‚Äôune de ces comp√©tences requises :Ma√Ætrise des technologies de bases de donn√©es Relationnelles et NoSQLMa√Ætrise d‚Äôau moins un outil d‚ÄôETL/ELT (Informatica, datastage, etc.)Ma√Ætrise des technologies de traitement distribu√© de donn√©es (spark, Hadoop)Ma√Ætrise d‚Äôau moins un framework de streaming de donn√©es (Kafka, RabbitMQ, etc.)Ma√Ætrise de chaines CI/CD et de des bonnes pratiques de DataOpsMa√Ætrise de solution de Virutualisation de donn√©es (Denodo, Dremio, etc.)Ma√Ætrise d‚Äôau moins un environnement cloud public ou priv√© (Azure, AWS, Outscale, etc.)Vous √™tes attir√©(e) par le monde du num√©rique, le Cloud et des technologies innovantes.Vous avez un bon esprit d‚Äôanalyse, √™tes curieux(se) et passionn√©(e) et vous avez le sens du travail en √©quipe.Informations suppl√©mentaires Ce que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy.La possibilit√© de s‚Äôengager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L‚Äôopportunit√© de rejoindre le collectif Tech‚ÄôMe UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Limonest, Strasbourg, Lyon‚Ä¶+1", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "72", "creation_date": "2007", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "8 millions ‚Ç¨", "proportion_female": "35", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVous serez amen√©(e) √† vous impliquer sur l‚Äôensemble de la chaine de valorisation des donn√©es depuis leur collecte en mode batch ou via une speed layer, leur stockage dans des datalakes leur transformation et leur structuration dans des environnements d√©cisionnels ou leur mise √† disposition en vue d‚Äôanalyses propres √† la data science. Vous interviendrez dans diff√©rents types d‚Äôenvironnements¬†: Modern Data Platforms, OnPremise ou hybride. Vos savoir-faire et savoir-√™tre feront la diff√©rence.Vos missions seront de diff√©rentes natures¬†: audit, conseil, expertise ponctuelle, avant-vente, projet de mise en ≈ìuvre.Vous pourrez intervenir dans toutes les phases des projets, r√©aliser des chiffrages, animer des ateliers avec les utilisateurs, d√©finir des architectures, mod√©liser, concevoir des environnements (Datalake, Datalakehouse et Datamart), sp√©cifier et mettre en place des flux ETL/ELT, r√©aliser des pipelines.Pour d√©velopper et partager vos comp√©tences, vous serez amen√©(e) √† suivre des formations puis √† passer des certifications qualifiantes prises en charge par l‚Äôentreprise. Vous contribuerez activement au centre d‚Äôexpertise qui vous permettra de d√©velopper votre c≈ìur de comp√©tences, mais √©galement de vous ouvrir sur d‚Äôautres domaines.Vous pourrez aussi coacher et encadrer des consultants plus juniors."}
{"job_title": null, "contract_type": "Alternance(12 √† 24 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Meudon", "remote": "T√©l√©travail non autoris√©", "experience": "< 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "IT / Digital, Objets connect√©s, Electronique / T√©l√©communications", "company_size": "10000", "creation_date": "1996", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "7 Mds", "proportion_female": "40", "proportion_male": null, "programming_languages": ["java"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": ["(vmware)"], "containers": null, "collaboration": null, "skills": ["cloud"], "raw_description": "Descriptif du posteAu sein de la Direction des Op√©rations R√©seau, vous int√©grerez l'√©quipe d'ing√©nieurs responsable des plates-formes de services (PFS) d√©livrant une grande vari√©t√© de services utilis√©s au quotidien par nos clients : la TV (sur d√©codeur, mobile ou SmartTV..), les SMS+ (dons par SMS, paiement de transport, jeux TV‚Ä¶), le paiement de service sur facture Bouygues‚Ä¶Vous √©voluerez dans un environnement technique vari√©, au carrefour entre le monde des telecoms et de l'IT, en constante √©volutions et avec de multiples projets.Une majorit√© des applicatifs sont d√©velopp√©s en Java et tournent dans des serveurs virtuels (VMware) ou des containers, avec des fournisseurs externes et des fournisseurs internes, certains organis√©s en devops.Votre mission consistera √† d√©finir et √† mettre en place les indicateurs n√©cessaires au pilotage de la qualit√© de service sur l'ensemble du domaine, conform√©ment aux contrats de service, et qui seront fournis √† nos clients et partenaires internes et externes.Pour cela, vous pourrez vous appuyer sur une √©quipe jeune et dynamique, experte dans ses domaines et qui saura vous accompagner pour connaitre le fonctionnement des services.Des experts DATA de nos √©quipes IT et de la communaut√© des Data Analysts et Data Scientists qui collaborent au quotidien.Un environnement bigdata performant sur le cloud mis √† disposition par nos √©quipes IT."}
{"job_title": null, "contract_type": "Alternance(12 mois)", "salary": "Non sp√©cifi√©", "company": null, "location": "Toulouse", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Logiciels, Mobilit√©, Robotique", "company_size": "250", "creation_date": "2014", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": "25", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams,"], "skills": ["mlopsinternship", "mlops"], "raw_description": "Descriptif du posteInternship detailsContract: ApprenticeshipLocation: ToulouseTeam: MLOpsInternship Tutor: Nathan LabbeApprentice salary, ‚Äútickets restaurant‚Äù Swile, ‚ÄúCSE‚ÄùMissionEasyMile has new projects and the R&D team is growing! Therefore we are looking for our future colleague to help us increase our features. You will join a team of >80 R&D engineers at the cutting edge of autonomous navigation technology, and work in a modern & open source environment.  You will join our amazing MLOps team and work on machine learning infrastructure and pipelines to scale our current data workflow and make our autonomous vehicles safer and smarter than ever.  Your future responsibilities In collaboration with our Machine Learning Ops and our Data teams, you will participate to put into production DL based autonomous feature (New localization modality). To do so, you will :Define and implement pipelines / workflows for:Training, validation, and optimization of machine learning based algorithmsData gathering, versioning, preparationModel Versioning, deployment, monitoring¬†Develop, construct and optimize machine learning based infrastructure(s) (e.g. databases, clusterGPU training server(s))Shape EasyMile‚Äôs data platform by ingesting, manipulating, and visualising data across data platforms"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Issy-les-Moulineaux", "remote": "T√©l√©travail non autoris√©", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management, Strat√©gie, Transformation", "company_size": "360000", "creation_date": "1967", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "18 Mds ‚Ç¨", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du poste¬†     Les objectifs de Group IT Global Applications sont de soutenir les entreprises et de travailler en partenariat avec elles pour leur permettre d'√™tre √† la fois efficaces et rentables. ¬†Nous mettons en ≈ìuvre des normes mondiales et int√©grons toutes les unit√©s op√©rationnelles dans un mod√®le de services informatiques unifi√©s. La fonction qualifie, par le biais de chartes de projet, les exigences de l'entreprise et la d√©fend dans ses relations avec les fonctions informatiques du groupe mondial.   Vous serez responsable de la conception, de la construction et de la maintenance de notre infrastructure de donn√©es, de la garantie de la qualit√© des donn√©es et de la prise de d√©cisions fond√©es sur les donn√©es dans l'ensemble de l'organisation. Le candidat id√©al poss√®de une solide exp√©rience en ing√©nierie des donn√©es, d'excellentes comp√©tences en r√©solution de probl√®mes et une passion pour le travail avec les donn√©es. Responsabilit√©s : - Concevoir, construire et maintenir notre infrastructure de donn√©es, y compris les pipelines de donn√©es, les entrep√¥ts et les bases de donn√©es.- Assurer la qualit√© et l'int√©grit√© des donn√©es en mettant en ≈ìuvre des processus de validation, de test et de contr√¥le des donn√©es.- Collaborer avec des √©quipes interfonctionnelles pour comprendre les besoins en mati√®re de donn√©es et les traduire en exigences techniques.- √©laborer et mettre en ≈ìuvre des politiques et des proc√©dures en mati√®re de s√©curit√© et de confidentialit√© des donn√©es- Optimiser les performances en mati√®re de traitement et de stockage des donn√©es, en veillant √† l'√©volutivit√© et √† la fiabilit√©.- Se tenir au courant des derni√®res tendances et technologies en mati√®re d'ing√©nierie des donn√©es.- Fournir un encadrement et des conseils aux ing√©nieurs et analystes de donn√©es d√©butants.- Contribuer au d√©veloppement de solutions et de produits ax√©s sur les donn√©es.      ¬†        ¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Courbevoie", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["scala,"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop)ma√Ætrise", "(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digitale", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "ci/cd"], "raw_description": "Descriptif du posteCompany Description Sopra Steria, acteur majeur de la Tech en Europe, reconnu pour ses activit√©s de conseil, de services num√©riques et d‚Äô√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d‚Äôactivit√© et des technologies innovantes √† une approche r√©solument collaborative.Sopra Steria place l‚Äôhumain au centre de son action et s‚Äôengage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif.Fort de 56 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d‚Äôaffaires de 5,8 milliards d‚Äôeuros en 2023.The world is how we shape itJob Description Votre futur environnement de travail :Chez notre client, grande banque commerciale fran√ßaise, vous int√©grez nos squads pour intervenir sur des projets de grande envergure, des projets transformants et structurants de la banque de demain. Vous interviendrez sur la gestion d‚Äôapplications sur des domaines tels que : la conformit√©, la fraude, la lutte anti-blanchiment, les risques de cr√©dit, la tr√©sorerie, les paiements, les financements structur√©s ou encore le r√©glementaire bancaire.Au sein de notre Data Factory, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l‚Äôoccasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.Votre r√¥le et vos missions :Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es;Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles;Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.Qualifications Votre profil :De formation Master 2 Ecole d‚ÄôIng√©nieurs ou Informatique, ou √©quivalent, vous justifiez d‚Äôune exp√©rience technique de 3 ans minimum et souhaitez √©voluer rapidement dans un contexte motivant. Vous avez ces comp√©tences requises :Ma√Ætrise des technologies de bases de donn√©es Relationnelles et NoSQLMa√Ætrise d‚Äôau moins un outil d‚ÄôETL/ELT (Informatica, datastage, etc.)Ma√Ætrise des technologies de traitement distribu√© de donn√©es (spark, scala, Hadoop)Ma√Ætrise d‚Äôau moins un framework de streaming de donn√©es (Kafka, RabbitMQ, etc.)Ma√Ætrise de chaines CI/CD et de des bonnes pratiques de DataOpsMa√Ætrise de solution de Vitrtualisation de donn√©es (Denodo, Dremio, etc.)M√©thodologie Agile ScrumAnglais professionnelVous √™tes attir√©(e) par le monde du num√©rique, le Cloud (maitrise d‚Äôun environnement public ou priv√© est un plus) et des technologies innovantes.Vous avez un bon esprit d‚Äôanalyse, √™tes curieux(se) et passionn√©(e) et vous avez le sens du travail en √©quipe.Additional Information Ce que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy..La possibilit√© de s‚Äôengager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L‚Äôopportunit√© de rejoindre le collectif Tech‚ÄôMe UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Digital Marketing / Data Marketing, IT / Digital, Strat√©gie", "company_size": "39", "creation_date": "2010", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null, "programming_languages": ["python,", "java,", "scalaune"], "databases": null, "data_analyze": null, "big_data_tools": ["(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["(aws", "azure", "gcp)une"], "dev_tools": ["digital", "docker/kubernetes"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["docker/kubernetes"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker/kubernetes", "docker/kubernetes"], "collaboration": null, "skills": ["cloud", "ci/cd"], "raw_description": "Descriptif du posteIODA Group, cabinet de conseil en plein essor en France et √† l‚Äôinternational, √† taille humaine et orient√© business, mixant la Data, le Marketing, le Digital & la Technologie, est √† la recherche de talents passionn√©s pour rejoindre son √©quipe.Si tu es un(e) Senior Data Engineer chevronn√©(e) avec au moins 4 ans d‚Äôexp√©rience, ce poste est fait pour toi !Ce poste est bas√© √† Paris mais nous avons √©galement des bureaux √† Bordeaux, l‚ÄôIle de la R√©union et Barcelone.Le Job üíªEn tant que Senior Data Engineer chez IODA Group, tu seras aux commandes des missions suivantes :D√©velopper de nouveaux mod√®les de donn√©es et des pipelinesTester les solutions les plus innovantes et prometteuses du march√© en vue de pouvoir am√©liorer nos capacit√©s en mati√®re de donn√©esComprendre les enjeux business et savoir les traduire dans un environnement techniqueAssister nos clients dans le cadrage des projets et contribuer au design fonctionnel et technique avec une vision avant-gardisteAssumer le r√¥le de r√©f√©rent, coacher les consultants juniors et faire √©voluer son √©quipeComp√©tences techniques requises üîßPour ce poste, nous recherchons une personne aux comp√©tences multiples avec :Une exp√©rience approfondie des technologies li√©es aux donn√©es, y compris les mod√®les d‚Äôarchitecture Big Data (Spark, Hive, Impala‚Ä¶)Une exp√©rience approfondie des services Cloud (AWS / Azure / GCP)Une expertise en langages de programmation : Python, Java, et si possible ScalaUne mise en production de cas d‚Äôusage Data, notamment en Machine LearningUne capacit√© √† mettre en place des mod√®les de donn√©es flexibles et √©volutifs (optimisation de stockage et traitement, regroupement, agr√©gation, partitionnement‚Ä¶)Une maitrise des bases de donn√©es SQL (conception, exploitation ‚Ä¶)Une connaissance en DevOps et en d√©veloppement de flux de donn√©es (data pipelines) avec une ma√Ætrise de Docker/Kubernetes et des cha√Ænes CI/CD seraient un plus"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Courbevoie", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": ["hadoop)ma√Ætrise", "(spark,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "(azure,"], "dev_tools": ["digitale", "digital"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["chef"], "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloud", "ci/cd"], "raw_description": "Descriptif du posteDescription de l‚Äôentreprise Sopra Steria, acteur majeur de la Tech en Europe, reconnu pour ses activit√©s de conseil, de services num√©riques et d‚Äô√©dition de logiciels, aide ses clients √† mener leur transformation digitale et √† obtenir des b√©n√©fices concrets et durables. Il apporte une r√©ponse globale aux enjeux de comp√©titivit√© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d‚Äôactivit√© et des technologies innovantes √† une approche r√©solument collaborative.Sopra Steria place l‚Äôhumain au centre de son action et s‚Äôengage aupr√®s de ses clients √† tirer le meilleur parti du digital pour construire un avenir positif.Fort de 56 000 collaborateurs dans pr√®s de 30 pays, le Groupe a r√©alis√© un chiffre d‚Äôaffaires de 5,8 milliards d‚Äôeuros en 2023.The world is how we shape itDescription du poste Votre futur environnement de travail :Sous la supervision d‚Äôun Chef de Projet, vous √™tes pleinement impliqu√©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi √† leur succ√®s. Vous avez l‚Äôoccasion de d√©velopper vos comp√©tences techniques et fonctionnelles de mani√®re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.Votre r√¥le et vos missions :Vous avez pour r√¥le la mise en place de pipelines de donn√©es fiables, s√©curis√©s et √† l‚Äô√©chelle pour soutenir la mise √† disposition des donn√©es aux cas d‚Äôusage m√©tier qui en ont besoin.Vos activit√©s principales sont les suivantes :Vous travaillez avec le client pour √©valuer, concevoir, d√©ployer, am√©liorer et maintenir les pipelines de donn√©es ;Vous vous assurez que les pipelines de donn√©es cr√©√©s sont r√©silients, s√©curis√©s et accessibles ;Vous d√©finissez le mod√®le op√©rationnel pour monitorer et supporter les pipelines de donn√©esVous fournissez une expertise √† nos clients sur leurs donn√©es pour assurer leur optimisation et leur s√©curit√© par rapport √† leurs besoins ;Vous apportez un savoir en gestion de la qualit√© et la gouvernance de la donn√©e pour assurer le suivi de la conformit√© √† la gouvernance de la donn√©eVous faites de la veille technologique dans le domaine afin d‚Äôenrichir les roadmaps technologiques et fournir des solutions modernes √† nos clients.Qualifications Votre profil :De formation Master 2 Ecole d‚ÄôIng√©nieurs ou Informatique, ou √©quivalent, vous justifiez d‚Äôune exp√©rience technique de 3 ans minimum et souhaitez √©voluer rapidement dans un contexte motivant.Vous avez au moins l‚Äôune de ces comp√©tences requises :Ma√Ætrise des technologies de bases de donn√©es Relationnelles et NoSQLMa√Ætrise d‚Äôau moins un outil d‚ÄôETL/ELT (Informatica, datastage, etc.)Ma√Ætrise des technologies de traitement distribu√© de donn√©es (spark, Hadoop)Ma√Ætrise d‚Äôau moins un framework de streaming de donn√©es (Kafka, RabbitMQ, etc.)Ma√Ætrise de chaines CI/CD et de des bonnes pratiques de DataOpsMa√Ætrise de solution de Virutualisation de donn√©es (Denodo, Dremio, etc.)Ma√Ætrise d‚Äôau moins un environnement cloud public ou priv√© (Azure, AWS, Outscale, etc.)Vous √™tes attir√©(e) par le monde du num√©rique, le Cloud et des technologies innovantes.Vous avez un bon esprit d‚Äôanalyse, √™tes curieux(se) et passionn√©(e) et vous avez le sens du travail en √©quipe.Informations suppl√©mentaires Ce que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressants : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, des primes vacances et cooptation.Un accompagnement individualis√© avec un mentor.Des opportunit√©s de carri√®res multiples : plus de 50 m√©tiers, autant de passerelles √† imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria Academy..La possibilit√© de s‚Äôengager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.L‚Äôopportunit√© de rejoindre le collectif Tech‚ÄôMe UP (formations, conf√©rences, veille, et bien plus encore).Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Meudon", "remote": "T√©l√©travail non autoris√©", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "IT / Digital, Objets connect√©s, Electronique / T√©l√©communications", "company_size": "10000", "creation_date": "1996", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "7 Mds", "proportion_female": "40", "proportion_male": null, "programming_languages": ["escalade"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteSi pour vous, ce qui vous pla√Æt dans votre m√©tier, c'est l'exploitation de syst√®mes d'informations et la r√©solutions de crise, alors on est fait pour √™tre ensemble!Ce que l'on vous propose :Rejoindre la Direction Production SI commercial r√©seau et l'√©quipe DWH/Fraude et Obligation l√©gale, au coeur des processus DATA, en tant qu'Ing√©nieur exploitation syst√®me d'information, compos√©e de 13 personnes et sous la responsabilit√© de Thomas. (manager).Ce que vous ferez au quotidien :Vous assurez le support de niveau 2 sur les applications m√©tiers de votre p√©rim√®tre et d√©veloppez une v√©ritable expertise fonctionnelle et technique du SI.Vous serez en charge de :- Analyser et r√©soudre des incidents ¬´ alarmes ¬ª et des incidents ¬´ m√©tiers ¬ª remont√©s par le support N1 afin de maintenir le niveau de service attendu par nos clients.- Si n√©cessaire, escalade au N3 (MOE)- Installation de batchs, cr√©ation et modification de scripts shell- Cr√©ation de jobs via l'ordonnanceur VTOM- Mise en place de Dashboard et syst√®me d'alerting √† venir, via la suite ELK- Accompagnement des projets de l'entreprise sur leur mise en service, depuis les phases d'√©tudes jusqu'au d√©ploiement : -- D√©finition des normes d'exploitation-- Participation √† la strat√©gie de tests d'exploitabilit√© avant la mise en production et optimisation de ces tests avec les MOE-- Mises en production et √©laboration de strat√©gies de MEP-- Anticipation proactive des incidents afin de contribue r √† l'am√©lioration la QOSCe poste est soumis aux astreintes (1 semaine sur 6)."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail total", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Strat√©gie, SaaS / Cloud Services, Big Data", "company_size": "115", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNous recherchons un Senior Data Engineer pour rejoindre l‚Äô√©quipe charg√©e des applications et des services internes. Tu seras responsables du cycle de vie complet de tes projets, du design √† la mise en production. Les projets r√©cents accomplis par l‚Äô√©quipe comprennent une plateforme d‚Äôenrichissement des donn√©es de g√©olocalisation capable de g√©rer des centaines de millions de data points par jour ainsi qu‚Äôun API de machine learning bas√©e sur ChatGPT capable de cat√©goriser automatiquement nos donn√©es.Tes responsabilit√©sDesign, d√©veloppement et maintenance de nos services internes d‚Äôenrichissement des donn√©es.Travailler en √©troite collaboration avec nos product managers, data analysts, et autre partie prenantes pour d√©finir les besoin techniques et les sp√©cifications.Coacher et guider nos profils junior.Diagnostiquer et r√©soudre les diff√©rents probl√®mes techniques qui peuvent survenir (pas d‚Äôastreinte)."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "Logiciels, IT / Digital", "company_size": "400", "creation_date": "2005", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "43M", "proportion_female": null, "proportion_male": null, "programming_languages": ["python/scala/java-", "python/scala/java-", "scala,", "python/scala/java-"], "databases": null, "data_analyze": null, "big_data_tools": ["spark/hadoop", "spark,", "spark/hadoop", "databricks.", "databricks.nos"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws/", "azure", "azure,", "azure/", "gcp"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud", "cloudops)-", "cloud:"], "raw_description": "Descriptif du posteMargo Analytics est l'entit√© experte de Margo Group des probl√©matiques Data, Cloud et DevOps cr√©√©e en 2020 par leurs fondateurs Rapha√´l et Mounir. Aujourd‚Äôhui 60 consultants ont int√©gr√© l'entit√© et nous avons commenc√© √† travailler avec 18 nouveaux clients (Banque, Industrie, Assurance, √ânergie, E commerce, Sant√©). A leurs c√¥t√©s, vous pourrez √©voluer rapidement et d√©velopper de nouvelles comp√©tences.¬†Deux ADN fondateurs forts et sp√©cifiques √† Margo Analytics √† l‚Äôorigine de l‚Äôentit√© :- Toujours se positionner sur les plus beaux sujets et sur les missions √† fortes valeurs ajout√©es- Recruter des consultants passionn√©s et curieux qui cherchent √† √™tre challeng√©s Aujourd‚Äôhui, Margo Analytics poss√®de 4 communaut√©s de comp√©tences :¬†- Data engineer¬† - Data Science/ IA¬†- Galaxy OPS (devOps, dataOps, cloudOps)- Architecte Big Data¬†Ainsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagn√© par les deux fondateurs ainsi que par le leader de votre communaut√©, dont les r√¥les sont de rechercher le projet qui correspondra le plus √† vos attentes et de vous accompagner dans votre carri√®re.üéØLes missions Margo Analytics¬†:¬†Au sein de la communaut√© Data Engineer vos missions¬†seront :¬†- D√©velopper en mode agile les cas d‚Äôusages m√©tier¬†- Mettre en place des processus de collecte, d‚Äôorganisation, de stockage et de mod√©lisation des donn√©es¬†- D√©velopper des traitements de transformation et de production de donn√©es - Assurer la mise en production des mod√®les de pr√©diction cr√©√©s par les Data Scientists - Participer √† l‚Äôam√©lioration continue et au refactoring de codeBesoin de projection ? Voici un exemple de mission :¬†Camille accompagne un grand compte dans le domaine de l‚Äôindustrie sur son projet de mise en place d‚Äôun nouveau datalake en Azure databricks. L‚Äôobjectif de cette mission est d‚Äôassurer la distribution de la donn√©e de mani√®re optimis√©e pour cr√©er une couche de distribution et permettre aux Data Scientists d‚Äôimpl√©menter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.Nos stack Technique :¬†- Langage : Python/Scala/Java- Framework : Spark/Hadoop - Cloud: Azure/ AWS/ GCP¬†üôå Les avantages¬†:¬†- Tickets restaurants Swile - Mutuelle Alan prise en charge √† 100%- Pass Navigo pris en charge √† 100%- T√©l√©travail- Formations illimit√©es- Locaux en plein coeur de Paris- Places en cr√®ches ü§ùNotre processus de recrutement :¬†Notre processus de recrutement se fait en 3 √©tapes, r√©parties sur 7 √† 15 jours maximum : - Premi√®re rencontre ! Vous √©changez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunit√©s que nous proposons-¬†Challengez-vous dans le cadre d‚Äôun entretien technique avec l‚Äôun de nos experts. C‚Äôest √©galement l‚Äôoccasion pour vous d‚Äôavoir son retour d‚Äôexp√©rience- Dernier entretien de motivation : pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final üîç Vous √™tes un(e) futur(e) Margo Analytics si :¬†Must-HaveVous √™tes issu(e) d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun cursus universitaire √©quivalent niveau Bac + 5 / MasterVous aimez coder et vous √™tes passionn√©(e) d‚Äôinformatique et de DataVous √™tes curieux(se) et vous vous int√©ressez aux derni√®res technologies du march√©Vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data EngineerNice to HaveVous √™tes ambitieux(se) et n‚Äôavez pas peur de travailler sur des projets challengeants dans des environnements √† fortes contraintes techniques . Vous parlez et comprenez l‚Äôanglais.¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Orly", "remote": "T√©l√©travail occasionnel", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "Restauration, Boissons, Epicerie fine", "company_size": "140", "creation_date": "2002", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "100", "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableaux"], "statistics": null, "cloud_computing": null, "dev_tools": ["digitalisation,"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteDepuis 2002, Amorino √©merveille les gourmands du monde entier √† travers ses 220 boutiques pr√©sentes dans 16 pays, en faisant d√©couvrir au plus grand nombre, la magie de l‚Äôauthentique glace italienne de qualit√©.Les fondateurs d‚ÄôAmorino, Paolo Benassi et Cristiano Sereni, ont √† c≈ìur de d√©velopper une grande famille autour de leur marque, pour laquelle tout le monde prend plaisir √† travailler autour d‚Äôune valeur commune √† l‚Äôensemble des collaborateurs : La Passion pour l‚Äôexcellence !Dans le cadre de notre fort d√©veloppement, nous recherchons pour notre Si√®ge, un/une Analytics Engineer.R√¥le : L‚ÄôAnalytics Engineer sera responsable de:(i) La gestion et de l‚Äôanalyse des donn√©es. Il fournit de la data, des analyses et dashboards pertinents pour aider au pilotage de la performance du r√©seau(ii) Ainsi que du d√©veloppement de solutions / outils pour accroitre l‚Äôefficacit√© op√©rationnelle des √©quipes (internes comme franchis√©s)L‚ÄôAnalytics Engineer occupe un r√¥le central dans notre strat√©gie en sa capacit√© √† pouvoir contribuer √† convertir la donn√©e en connaissance.Nous recherchons une personne autonome et proactive qui sera √† m√™me d‚Äôaccompagner la croissance Amorino avec des outils et m√©thodes adapt√©s √† cette croissance.Vos principales missions et responsabilit√©s seront :‚óè Mesurer la performance business via le maintien et le d√©veloppement de notre datawarehouse (50%)o Owner de la donn√©e dans le data warehouse.o D√©velopper des pipelines de transformation de donn√©es (dbt).o Support sur les incidents de qualit√© de donn√©es dans la data warehouse (d√©j√† en production) et dans les prochains outils internes d√©ploy√©s (gestion de stocks).o En collaboration avec le responsable digitalisation, maintenir le r√©f√©rentiel produit France et l‚Äô√©tendre aux autres pays.o D√©velopper et maintenir des tableaux de bord interactifs et des visualisations de donn√©es pour permettre / encourager les analyses ¬´ self-service ¬ª‚óè D√©velopper des nouveaux outils en collaboration avec les √©quipes op√©rationnelles et des prestataires externes que vous benchmarkerez (25%)o S‚Äôint√©resser & comprendre parfaitement les besoins des √©quipes op√©rationnelles.o Traduire leurs besoins en un cahier des charges technique.o Assurer le suivi des d√©veloppements.‚óè Challenger les √©quipes tech / produits de nos partenaires externes - syst√®mes de caisse entre autres - (25%)Comp√©tences‚óè Rigueur & Sens du D√©tail : Vous ne faites pas de compromis sur la qualit√© des donn√©es - lorsque n√©cessaire, vous allez naturellement dans les d√©tails pour √©viter toute incompr√©hension ou approximation.‚óè Autonomie, Pro-activit√© et Curiosit√© :‚óè R√©activit√© et Adaptabilit√©‚óè Maturit√© : Vous √™tes conscient de l‚Äôimpact de votre travail sur les autres √©quipes et pour l‚Äôentreprise.‚óè Aisance relationnelleo Vous aimez discuter et comprendre les besoins des √©quipes m√©tiers pour r√©pondre √† leurs besoins.o Vous √™tes capable de communiquer avec des interlocuteurs moins techniques, en adaptant le discours √† leur compr√©hension.Salaire selon profil.NOS ATOUTSPourquoi nous rejoindre ?En rejoignant Amorino, vous int√©grez une entreprise o√π il faut bon de travailler, certifi√©e ¬´GREAT PLACE TO WORK 2023 ¬ªEn rejoignant Amorino, vous int√©grez une entreprise o√π chacun fa√ßonne les contours de son poste.En rejoignant Amorino, vous int√©grez une entreprise o√π la diversit√©, sous toutes ses formes, est encourag√©e et appr√©ci√©e.Vous b√©n√©ficiez de nombreux avantages :Un parcours d‚Äôint√©gration complet pour faciliter la prise en main de votre poste et le d√©couvrir, avec des sessions d‚Äôint√©gration ¬´ Welcome On board ! ¬ª,Une large palette de formations qualifiantes ou certifiantes pour d√©velopper votre employabilit√© et votre projet professionnelDes moments d√©di√©s pour vous permettre d‚Äô√©largir votre horizon professionnel.La mobilit√© interne est dans l‚ÄôADN de la maison : vous pourrez √©voluer dans le groupe !Un environnement de travail agr√©able :¬∑ Des conditions de t√©l√©travail am√©nag√©es pour les m√©tiers qui le permettent.¬∑ Un Plan Epargne Entreprise (PERCOL),¬∑ Une aide √† l‚Äôacc√®s au logement.¬∑ Un acc√®s √† notre salle de sport interne¬∑ Une cantine orient√©e vers le ¬´ fait maison ¬ª¬∑ Des produits √† prix pr√©f√©rentiels.¬∑ Des √©v√©nements d‚Äôentreprise f√©d√©rateurs"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Brussels", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "79", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": "5,5", "proportion_female": "31", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteWhat will be your tasks with us?Concretely on a daily basis, you will work in AGILE mode and as a team (made up of Data Scientists, architects, Devops coach, etc.). You‚Äôll support our customers on their Data, delivery & release challenges.You will be working in the following areas:Consulting & expertise among our customers on their strategic projects:Analyze our customers‚Äô strategic challenges around Data issuesMake your contribution to define their ambitions and their Data roadmapAudit & projects framing (architecture, methodology, code quality)Achievements/ support of projects that involve Data centric architecture set upR&D and Solutions:Participation in the development of internal solutionsProposal and creation of innovative solutions"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail non autoris√©", "experience": null, "education_level": null, "publication_date": "2024-04-29", "sector": "Recrutement", "company_size": "10", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteNous travaillons avec +400 startups et scale ups de la sc√®ne tech fran√ßaise et europ√©enne, √† la recherche de Data Engineers exp√©riment√©s de Confirm√©s √† C-Level:Heetch, Scaleway, Skello, Blablacar, Sendinblue, Mirakl, Partoo, Frichti, Swan, Jellysmack, MangoPay, Coinhouse‚Ä¶ mais aussi les startups d‚ÄôeFounders comme Collective Work, Numeral, ou Folk‚Ä¶ et bien d‚Äôautres. Nous d√©veloppons une communaut√© de hauts talents avec pour vocation d‚Äôapporter du soutien √† leur carri√®re tout au long de leur vie professionnelle. √âv√©nements, ressources, sessions de recrutement‚Ä¶"}
{"job_title": null, "contract_type": "CDD / Temporaire(12 √† 24 mois)", "salary": "38K √† 55K¬†‚Ç¨", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-04-29", "sector": "Intelligence artificielle / Machine Learning, Big Data, Sant√©", "company_size": "540", "creation_date": "2020", "address": null, "average_age_of_employees": "46", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null, "programming_languages": ["python"], "databases": null, "data_analyze": null, "big_data_tools": ["hadoop"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteLa mission de votre √©quipeAfin de permettre le d√©veloppement de projets de recherche innovants, en particulier dans le domaine de l‚Äôintelligence artificielle, l‚ÄôAP‚ÄìHP a mis en place une plateforme Big Data, infrastructure informatique propre, int√©grant des capacit√©s de stockage et de calcul pour l‚Äôexploitation s√©curis√©e et performante des donn√©es de sant√© dont elle est d√©positaire. Cette plateforme h√©berge notamment l‚Äôentrep√¥t de donn√©es de sant√© (EDS) de l‚ÄôAP-HP.‚ÄãL‚ÄôEntrep√¥t de Donn√©es de Sant√© (EDS) de l‚ÄôAP-HP int√®gre des donn√©es administratives et m√©dicales de plus de 8 millions de patients hospitalis√©s ou venus en consultation au sein des 39 √©tablissements de l‚ÄôAP-HP (20 millions de dossiers m√©dicaux, plus de 10 millions de diagnostics, 181 millions de r√©sultats de laboratoires‚Ä¶). Cet entrep√¥t permet d‚Äôam√©liorer le pilotage de l‚Äôactivit√© hospitali√®re et de faire avancer la recherche scientifique dans le domaine de la sant√© en favorisant la r√©alisation d‚Äô√©tudes sur donn√©es, la mise en place d‚Äôessais cliniques et le d√©veloppement d‚Äôalgorithmes d‚Äôaide √† la d√©cision.‚ÄãLa Plateforme Big Data de l‚ÄôAP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d‚Äôespace disque), de machines GPU (24 Nvidia P40), de 10 machines d√©di√©es aux environnements Jupyter pour l‚Äôanalyse de donn√©es, et de nombreuses autres machines applicatives.‚ÄãVotre √©quipe, le domaine ¬´ Plateforme Big Data ¬ª, a pour mission l‚Äôint√©gration des donn√©es de sant√© massives et complexes (donn√©es structur√©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation √† grande √©chelle, de mani√®re performante, ergonomique et s√©curis√©e dans le respect des principes et r√®gles de gouvernance des donn√©es d√©finis par l‚ÄôAP-HP. Dans le domaine de l‚Äôimagerie m√©dicale, les images sont majoritairement produites dans les plus de 20 services de radiologie de l‚ÄôAPHP et stock√©s dans un PACS Centrale APHP, g√©r√© par le p√¥le imagerie de la DSI. Vos missionsAu sein de l‚Äô√©quipe en charge de la Plateforme Big Data de l‚ÄôAPHP, vous participerez au d√©veloppement des outils ou composants r√©pondant aux attentes des m√©decins et chercheurs pour l‚Äôexploitation des donn√©es d‚Äôimagerie m√©dicale (majoritairement au format DICOM) collect√©es dans le cadre de leurs projets de recherche. La plateforme big data a engag√© le d√©veloppement d‚Äôune solution sp√©cifique de serveur PACS ainsi que les m√©canismes de collecte des donn√©es depuis le serveur PACS de l‚ÄôAPHP et d‚Äôautres sources d‚Äôimages. Vous serez amen√© √† analyser, √† proposer et √† mettre en oeuvre des solutions adapt√©es aux diff√©rents besoins des projets de recherche et vous participerez √©galement √† la mise en place d‚Äôun certain nombre d‚Äôoutils de base (visualisation, annotation, etc.) pour faciliter l‚Äôexploitation et l‚Äôenrichissement des donn√©es d‚Äôimagerie par les utilisateurs de la plateforme. En tant que data engineer sp√©cialis√© en imagerie m√©dicale, vous :R√©aliserez la d√©finition des besoins et l‚Äôaccompagnement des m√©decins pour la r√©alisation d‚Äôun projet de recherche D√©velopperez, industrialiserez et maintiendrez les flux d‚Äôint√©gration de donn√©es d‚Äôimages pour permettre la collecte et l‚Äôutilisation de nouvelles typologies de donn√©es (extraction, s√©lection, collecte et int√©gration) via des connecteurs sp√©cifiques d√©velopp√©s en python ou avec l‚Äôutilisation de l‚ÄôETL Talend Industrialiserez le code de g√©n√©ration du flux de donn√©es et assurer sa performance globaleAiderez √† l‚Äôimpl√©mentation de standards et normes de mise √† disposition des donn√©es Mettrez en place des outils permettant l‚Äôenrichissement des donn√©es (analyse, annotation, etc)Travaillerez en collaboration avec des partenaires industriels dans le cadre des diff√©rents projets de recherche"}
{"job_title": null, "contract_type": "Alternance", "salary": "Non sp√©cifi√©", "company": null, "location": "Limonest", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-28", "sector": "IT / Digital, Organisation / Management", "company_size": "50000", "creation_date": "1968", "address": null, "average_age_of_employees": "37", "turnover_in_millions": "5,1 Mds", "proportion_female": "30", "proportion_male": null, "programming_languages": ["python,"], "databases": null, "data_analyze": null, "big_data_tools": ["databricks,"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["azure"], "dev_tools": ["digitale", "digitale"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteVotre futur environnement de travail :Int√©ress√©/e par la transformation digitale et les innovations technologiques ? Voici 4 bonnes raisons de rejoindre la r√©gion Auvergne Rh√¥ne-Alpes :Une diversit√© de projets pour des entreprises locales et des grands groupes dans des secteurs vari√©s : √©nergie, transports, industrie, banque, sant√©Des postes vari√©s en int√©gration, conseil, infrastructure management et sur des domaines disruptifs : IoT, Big Data, IAUn suivi RH, une proximit√© manag√©riale et des perspectives d'√©volution de carri√®resDes √©quipes dynamiques √† taille humaine et des communaut√©s m√©tier aux expertises vari√©esAu sein de l'agence de Lyon, vous avez l‚Äôopportunit√© de travailler pour des clients locaux sur des projets du secteur industriel et automobile. Int√©gr√©/e √† une √©quipe projet, vous √™tes un/e acteur/trice cl√©/e de la transformation digitale en participant √† la conception et l‚Äôimpl√©mentation de solutions √† valeur ajout√©es pour nos clients.Vos missions seront les suivantes :Analyser fonctionnellement et/ou techniquement les besoins clients ;Concevoir, d√©velopper et tester des composants applicatifs ;R√©diger et ex√©cuter des plans de tests de qualification et d‚Äôint√©gration ;Participer activement aux diff√©rentes c√©r√©monies agiles du projet ainsi qu‚Äô√† la vie d‚Äô√©quipe : Daily meeting, reporting hebdo, poker planning, ‚Ä¶ et afterworks !√ätre acteur/trice d‚Äôun collectif dynamique et convivial.Environnement technologique/fonctionnel :Technologies : Azure Databricks, Python, PowerBI¬†Les apports de l'alternance :D√©couvrir le monde de l'entreprise et appr√©hender le m√©tier d'ing√©nieurTravailler sur des applications √† forts enjeux pour nos clientsAcqu√©rir des comp√©tences techniques avec nos expertsD√©couvrir et/ou appliquer les bonnes pratiques de d√©veloppement dans un contexte professionnelIntervenir sur les diff√©rentes phases du d√©veloppement logiciel (sp√©cification / conception / d√©veloppement / d√©ploiement)S'approprier une m√©thodologie agileS'int√©grer au sein d'une √©quipe et participer de mani√®re active √† la dynamique collective(Re)d√©couvrir le fonctionnement d'une des plus grandes ESN fran√ßaises¬†aux dimensions internationales.Informations suppl√©mentairesCe que nous vous proposons :Un accord t√©l√©travail pour t√©l√©travailler jusqu‚Äô√† 2 jours par semaine selon vos missions.Un package avantages int√©ressant : une mutuelle, un CSE, des titres restaurants, un accord d‚Äôint√©ressement, et des primes vacances.Plusieurs centaines de formations accessibles en toute autonomie depuis l‚Äôapp mobile avec Sopra Steria AcademyLa possibilit√© de s'engager aupr√®s de notre fondation ou de notre partenaire ¬´ Vendredi ¬ª.De tr√®s nombreuses opportunit√©s en CDI peuvent vous attendre √† l‚Äôissue de l'alternance.Employeur inclusif et engag√©, notre soci√©t√© ≈ìuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C‚Äôest pourquoi, attach√©s √† la mixit√© et √† la diversit√©, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements>¬†"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Grenoble", "remote": "T√©l√©travail non autoris√©", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2024-04-28", "sector": "IT / Digital, SaaS / Cloud Services, Big Data, Cybers√©curit√©", "company_size": "53000", "creation_date": "2023", "address": null, "average_age_of_employees": "41", "turnover_in_millions": "5 milliards d'euros", "proportion_female": "30", "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": null, "raw_description": "Descriptif du posteQUE FAISONS-NOUS¬†:Face √† l‚Äôurgence climatique, le nucl√©aire est une √©nergie d‚Äôavenir, pilotable et bas carbone, qui compl√®te parfaitement les √©nergies renouvelables pour d√©carboner notre production √©lectrique tout en pr√©servant notre ind√©pendance √©nerg√©tique. Worldgrid dispose d‚Äôune expertise internationale reconnue dans ce domaine. En effet, nos solutions de contr√¥le-commande pour le nucl√©aire, d√©velopp√©es √† Grenoble, √©quipent plus de 25 installations majeures en France, au Royaume-Uni et en Chine.Notre force r√©side dans notre capacit√© √† comprendre les besoins de nos clients et √† mobiliser un large √©ventail de comp√©tences et de techniques en interne : informatique industrielle, informatique embarqu√©e, contr√¥le commande, s√ªret√© de fonctionnement, cybers√©curit√©, d√©veloppement agile, ‚Ä¶Fort de nos exp√©riences et de nos savoir-faire, nous sommes un partenaire privil√©gi√© pour les installations nucl√©aire d‚Äôaujourd‚Äôhui comme de demain. C‚Äôest pourquoi nous avons √©t√© choisis pour d√©velopper le syst√®me de contr√¥le commande des futures centrales nucl√©aires fran√ßaise nomm√©es EPR2.QUE FEREZ-VOUS¬†:Dans le cadre des futures centrales nucl√©aire EPR2, vous contribuerez √† l‚Äô√©laboration de la Base de Donn√©es qui contiendra les donn√©es de tranche et vous aurez comme mission de coder les API qui permettrons de les exploiter.Pour cela votre r√¥le sera : D‚Äô√©crire les sp√©cifications techniques De r√©aliser les d√©veloppements et les tests unitaires D‚Äô√©laborer la documentation Vous aurez √©galement l‚Äôoccasion de suivre un parcours de formation technique afin de monter en comp√©tence sur notre produit, nos projets et nos m√©tiers selon vos connaissances."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": "> 3", "education_level": null, "publication_date": "2024-04-28", "sector": "Jeux vid√©o, AdTech  / MarTech", "company_size": "750", "creation_date": "2013", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["scalable,", "scalable"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": ["tableau,", "tableau"], "statistics": null, "cloud_computing": ["awsinfra"], "dev_tools": ["git,", "docker."], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["airflow", "airflow"], "IaC": ["terraformci/cd:", "terraform,"], "security_and_network": null, "virtualization": null, "containers": ["docker."], "collaboration": ["teams.engage", "teams,"], "skills": ["streamlining", "vouchergymlib", "terraformci/cd:", "ci/cd,"], "raw_description": "Descriptif du posteVoodoo is a tech company that creates mobile games and apps. With 7 billion downloads and over 150 million monthly active users,¬†Voodoo is the #3 mobile publisher worldwide in terms of downloads after Google and Meta. The company is one of the most impressive examples of hypergrowth in the ecosystem,¬†having raised over $1B and¬†backed by Goldman Sachs, Tencent, and GBL. Voodoo is now a team of over 750 employees worldwide, we‚Äôre looking for talented individuals from across the globe to come and entertain the world with us.TeamDo you have a passion for data analysis and a desire to elevate it to new heights? Join our close-knit Analytics Engineering team, where we ensure the data warehouse performs optimally, meeting and surpassing SLAs for maximum efficiency. We empower analysts by streamlining queries and maintaining a scalable, consistent repository. With custom CI processes, we minimize production hiccups, and our specialized tools around DBT boost analysts' confidence, enabling rapid and accurate data-driven decisions. Be part of a team that champions innovation and speed in the ever-evolving world of data.Take a proactive stance in solving data challenges to enhance platform performance, consistency, and accuracy.Design, maintain, and refine scalable data models to support business applications and analytics, with an eye for adapting to evolving data needs.Work with autonomy to address significant company-wide issues and develop solutions that span across teams.Engage in collaborative efforts with various teams, using data to inform strategic decisions and promote a culture of data-driven excellence.Maintain comprehensive documentation to support effective project management and collaboration.Advocate for a strong data quality culture to enable faster, more reliable decision-making.Keep up-to-date with the latest data technologies and methodologies ensuring our team remains at the forefront of data engineering, data visualization, data tools, and infrastructure innovation.Our Stack AWSInfra as code: TerraformCI/CD: CircleCIStorage: S3Data Lake/Warehouse: Redshift, Glue, AthenaOrchestration: dbt Core, Airflow (MWAA)Observability: Elementary, in-house volume and freshness anomaly detectionCompute: K8sData Visualisation: Tableau, Redash, Voil√†ProfileEngineering/Computer Science background with solid experience in crafting complex, optimized SQL queries and a solid understanding of data modeling and data warehousing principles (3 years minimum)Solid experience with the modern data stack, particularly DBT Core, Redshift (or equivalent), git, and Tableau (or equivalent), is necessary.Experience with CI/CD, Airflow and Docker.¬†Terraform, K8s and ArgoCD are a plus.Excellent written communication skills and fluency in English.A pragmatic approach to balancing technical integrity with the need to accelerate delivery.A curious, life-long learner, has a passion for solving hard problems, has comfort taking initiative and who continuously seeks to improve their skills and understanding.Benefits (France)Competitive salary upon experienceComprehensive relocation package (including visa support)Swile Lunch voucherGymlib (100% borne by Voodoo)Premium healthcare coverage SideCare, for your family is 100% borne by VoodooChild day care facilities (Les Petits Chaperons rouges)Wellness activities in our Paris officeUnlimited vacation policyRemote days"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail occasionnel", "experience": "> 5", "education_level": null, "publication_date": "2024-04-28", "sector": "IT / Digital, Strat√©gie, Transformation, Formation", "company_size": "350", "creation_date": "2003", "address": null, "average_age_of_employees": "29", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["scala,", "scalable"], "databases": null, "data_analyze": null, "big_data_tools": ["spark"], "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws,", "azure,", "gcp,"], "dev_tools": ["git", "docker"], "OS": null, "big_data_and_processing": null, "automation_and_orchestration": ["kubernetes,", "airflow."], "IaC": null, "security_and_network": null, "virtualization": null, "containers": ["docker", "kubernetes,"], "collaboration": null, "skills": ["gymlib", "cloud", "ci/cd"], "raw_description": "Descriptif du poste Descriptif du poste   Tu rejoindra notre team Data ! Tu participeras √† la r√©alisation de solutions, en collaboration √©troite avec des machine learning engineer, software architect, designers, developers... Force de proposition en interne, tu interviendras pour √™tre garant du d√©veloppement d'architecture Data, de la collecte multi-source de donn√©es, du pilotage et de la pertinence de ces derni√®res.Tu viendras compl√©ter l'offre par tes connaissances techniques  Activit√©s principales :   Compr√©hension des conceptions d'architecture data et des syst√®mes distribu√©s Conception et mod√©lisation des pipelines de donn√©es en assurant un stockage et une interrogation efficace D√©veloppement des traitements de donn√©es et de leur exploitation Ma√Ætrise l'ensemble des techniques, technologies et concepts utilis√©s Responsable de la qualit√© technique sur le p√©rim√®tre confi√© Contribuer √† la CI/CD avec TechLead et Ops Accompagnement des juniors dans leur mont√©e en comp√©tence (pair programming, pr√©sentation sur des sujets techs, management...)  Tu auras la chance d'arriver √† un moment charni√®re pour les √©quipes Datas, tu pourras ainsi participer aux diff√©rents changements qui s'op√©rent et batir avec eux le nouveau socle Data de Fabernovel en s'appropriant des nouveaux sujets : Datawarehouse, Big Data ... Chez Fabernovel nous sommes des chimistes, nous experimentons et cr√©ons ! Profil recherch√© : Nous recherchons avant tout une personne avec des comp√©tences en d√©veloppement logiciel ayant au moins 7 ans d‚Äôexp√©rience et qui a un attrait pour les probl√©matiques data. ¬† Notre futur talent est :  En plus de tes comp√©tences techniques, nous recherchons une personne curieuse, bienveillante, qui soit autonome et force de proposition.  Tu as un bon niveau en programmation fonctionnelle (ex : Scala, Rust) Tu as d√©j√† collabor√© en workflows Git (One flow, Trunk based) Tu es expert en base donn√©es SQL / NoSQL Tu maitrise les syst√®mes et calcul distribu√©s  Tu as une exp√©rience significative sur plusieurs projets de stream processing sur une ou plusieurs des technos suivantes : Akka, Kafka, Spark Tu as d√©j√† travaill√© sur un Cloud Provider: AWS, GCP, Azure, IBM Bonus : tu connais l'untilisation de Kubernetes, Docker ou Airflow.  Tu sais communiquer de fa√ßon claire et pr√©cise et fait preuve d‚Äôun esprit de synth√®se. ¬† Ce que nous offrons √† tous nos talents  Des projets riches et impactants, chez Fabernovel nous transformons les environnements, les situations, avec nos propres m√©thodes et secrets de fabrication. Une soci√©t√© apprenante ou nous avons con√ßu notre propre Learning development factory pour un partage de connaissance et un apprentissage continue. Un management fond√© sur la bienveillance, il n‚Äôy a pas d‚Äô√©chec, seulement des it√©rations et des occasions d‚Äôapprendre. De la libert√© dans ses choix : Flex office, horaires am√©nageables, possibilit√© de remote, culture de l‚Äôintrapreunariat. Des avantages toujours sympa, avec des locaux au coeur de Paris, des paniers fruits, du caf√©/th√©, des salles de jeux techs et low techs, ainsi que des salles de siestes.  Mais aussi‚Ä¶  Une Carte Swile prise en charge √† 60% par Fabernovel Acc√®s √† des offres privil√®ges Gymlib Remboursement de 75% des transports RTT PC ou MacBook  √Ä propos de nous : Cr√©√© en 2003 au c≈ìur de l‚Äô√©cosyst√®me num√©rique fran√ßais, Fabernovel na√Æt d‚Äôune conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure.Fabernovel, expert du conseil en transformation num√©rique et de la cr√©ation de produits et de services num√©riques, ma√Ætrise les expertises li√©es au design, aux technologies, au marketing et aux cultures nouvelles dans l‚Äôentreprise.Gr√¢ce au rapprochement op√©r√© entre EY Consulting et Fabernovel en juillet 2022, notre mission est de faire prosp√©rer l‚Äôinnovation et d‚Äôen faire un levier de diff√©renciation et de cr√©ation de valeur durable.Pour les grands groupes, les organisations et les startups, nous concilions transitions (num√©rique et √©cologique) et performance √©conomique, tout en posant les bases communes pour une collaboration et une innovation vertueuse.Nous renfor√ßons les piliers de diff√©renciation de nos clients en associant :Vision & Culture - cr√©er une organisation agile avec un mod√®le scalable et flexible ;Technologies & Donn√©es - √©diter ses propres logiciels et cr√©er un processus de d√©cision bas√© sur les donn√©es ;Mod√®le de valeur - construire et incarner une strat√©gie centr√©e sur ses parties prenantes (talents, clients, investisseurs, partenaires), pilot√©e et valoris√©e √† l‚Äôaide de nouveaux KPIs ;Nous activons les meilleures combinaisons de talents individuels et de m√©thodologies √† la pointe, avec toujours l‚Äôobjectif de rendre nos clients les plus autonomes possible. C'est √ßa, une Talent Company.La Communaut√© Tech d‚ÄôEY Fabernovel rassemble plus de 100 experts de la Tech (Ing√©nieurs Mobile, Back, Front, Data, Designers d‚ÄôExp√©rience, PPOs)Nous activons pour nos clients les meilleures combinatoires de talents individuels et de m√©thodologies √† la pointe, avec toujours l‚Äôobjectif de les rendre le plus autonome possible. Organis√©s en Squad Projets Agile, nous aidons de grands comptes, priv√©s ou public, √† d√©velopper des produits au plus proches de leurs besoins m√©tiers. Nous avons pour objectif :de produire des solutions sur mesure reposant sur des pratiques communes et un socle technique affut√© depuis des ann√©es par la communaut√© tech et designde garantir un processus de delivery continu afin de r√©pondre √† leurs enjeux march√©Quelques un de nos clients : Canal +, G7, RATP, The Fork, Caisse nationale de solidarit√© pour l'autonomie, CNAM, Renault, Morning ou encore Dynamo‚Ä¶"}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail total", "experience": null, "education_level": null, "publication_date": "2024-04-27", "sector": "Expertise comptable, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "370", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["(aws,"], "dev_tools": null, "OS": null, "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": ["terraform,"], "security_and_network": null, "virtualization": null, "containers": null, "collaboration": ["teams,"], "skills": ["gymlib,"], "raw_description": "Descriptif du posteAre you looking to have an impact on the daily life of millions of entrepreneurs in France (and tomorrow in Europe)?Are you looking for a work environment that values trust, proactivity, and autonomy?Do you feel like our Engineering principles are aligned with your vision?Then Pennylane is the right place for you !Our visionWe aim to become the most beloved financial Operating System of French SMEs (and soon, European ones).We help entrepreneurs rid themselves of time-consuming tasks related to accounting and finance while providing them with access to key financial information to assist in making the best decisions for their business.Simultaneously, we support accounting firms by enabling them to spend less time on redundant and repetitive tasks and more time on advising and supporting their clients. Already, over 100,000 small and medium-sized enterprises (SMEs) and more than 2,000 accounting firms use Pennylane in France! üöÄAbout usPennylane is one of the fastest growing Fintechs in France (and soon to be in Europe!)In 4 years of existence, we‚Äôve managed to :üíª Make ourselves known as a groundbreaking accounting and financial software for small businesses and their accountantsüí∞ Raise a total of ‚Ç¨84 millions, including from Sequoia, the famous fund from the Silicon Valley who invested early in companies like Google, Facebook, Airbnb, Stripe, Paypal and much more...üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Grow from 7 cofounders to 360+ happy Pennylaners : we‚Äôre now recognized as one of the greatest places to work in France (and also remotely), with a 4.5/5 rating on Glassdoor and an e-NPS of 94.üåç Build an international environment with more than 25 nationalities, with a strong remote-friendly culture, where 30% of the employees are already working from all parts of Europeü§ù Earn the trust of thousands of customers and accounting firms and obtain outstanding ratingsüöÄ¬†Already more than 100,000 small and medium-sized enterprises (SMEs) and over 2,000 accounting firms use Pennylane in France!WHY this position is of utmost importance to reach our missionAt Pennylane, every decision that is not backed by data is likely to be challenged (when data is available of course). This culture is embraced by the leadership team, and actively promoted everywhere. The role of the data team is to make this possible by treating data like a production asset, making it available company-wide, and using it proactively to improve Pennylane‚Äôs user experience.By joining us as a Senior Data Engineer, you will have a pivotal role in large projects, bringing your data architecture and engineering expertise to help us meet our high delivery standards.HOW you will contribute to the companyAs a Senior Data Engineer, you will be part of the Data Engineering team (7+ people), inside the Data department (18+ people).- You will be a key architect of our Data Platform, from data ingestion and validation to transport, storage and exposure to consumers.- You will lead the design and implementation of data solutions (streaming, ETL, etc).- You will work hand in hand with data scientists and analysts to implement analytics and machine learning solutions.- You will work closely with software engineers - the most critical data producers - to guarantee data quality and integrity, and promote a culture where data is seen as a production systemWHAT you can expect from your life at PennylaneWithin one month:- You will learn everything about our company, our teams, and our vision during the first onboarding week.- You will get familiar with our stack, and have delivered a few small projects which will give you a concrete taste of our tools & processes.- You will be given time to meet your future stakeholders, and gain a deep knowledge of our product and operations.Within 3 months:- You will be fully in charge of items in our roadmap, defining and prioritizing your tasks autonomously.- You will be confortable with our technical stack (AWS, Terraform, streaming, batch, scheduling, warehousing).- You will contribute to larger cross-team projects.Within 6 months:- You will proactively contribute to the team‚Äôs roadmap.- You will work with engineers and data practitioners on improving our stack and data platform.- You will share your learnings and best practices within the team.And beyond: the data team will continue growing with the companyWhich means:- Opportunities to recruit and mentor new team members,- Increased accountability in project leadership,- Responsibilities to design and implement new processes, tools and best practices to make sure that your team works even more efficiently.Who are we looking for ?To thrive at Pennylane, you need :- To speak English (level is assessed and appreciated according to the department you‚Äôre applying to)- To be energized by an ever-shifting work environment- To be highly collaborative (within your team or other stakeholders)Sufficiently experienced to prioritize business-led actions on your day to day activity- We know that some people are less likely to apply than others, if they don‚Äôt feel like they meet the full list of criteria.If you‚Äôre hesitating, we encourage you to apply : who knows, it might be the start of a meaningful and long-lasting collaboration.We also want to emphasize that we fully embrace diversity, equity and inclusion and that we‚Äôre doing our best to create a safe and inclusive environment. We are committed to providing an equal employment opportunity regardless of gender, sexual orientation, origin, disabilities, or any other traits that make you who you are. If anything, diversity makes us a more fun place to work at.What do we do to make your work life easierüè¢ You'll be able to work remotely from your country of residence, as long as it is in Europe and within a maximum time difference of two hours from the CET time zoneüå¥¬†Wherever you are based, you will get 25 vacations days paid by Pennylaneüíµ You‚Äôll have a competitive compensation packageüìà You'll get company shares to enjoy a piece of the success story you're building with usüè° You‚Äôll have a budget to turn your home into a more comfortable workspace, as well as a monthly allowance to work from a coworking space whenever you feel like it‚õπÔ∏è¬†Through our partner Gymlib, you‚Äôll have access to 8000 fitness spaces in Europe and more than 300 activities related to wellnessüá¨üáß You‚Äôll have access to Busuu to perfect your English or your Frenchüíª You‚Äôll get the latest Apple equipmentüéâ We are committed to regularly coming together for company events such as Tech Days (which bring remote Pennylaners together every 3 months) or our annual company seminar, fostering significant moments of cohesion for everyone.If you are based in France, you will have a French contract following French regulation on top of the additional perks : 8 to 13 RTT, 5 weeks PTOs, lunch credits (Swile), Alan Blue healthcare cover and regular events in cities where Pennylaners are mostly presents (Lyon, Bordeaux, Nantes‚Ä¶)We're working on providing those last advantages to our people based outside of France as well, but it can be quite  more complex depending on different countries.What does the recruitment process look like?- A first interview with R√©mi, Tech Recruiter (30 minutes)- A technical test to assess your coding skills (75 minutes)- A case study interview to cover a technical topic closely related to one of our priorities (75 minutes)- A past project interview to hear about your technical experience (60 minutes)- An interview with our Tech & Product founders to discuss our company cultureWe make sure we move fast; you can expect the recruitment process with us to last between 15 and 25 days in total."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Croix", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-26", "sector": "Application mobile, Logiciels, Cybers√©curit√©, Sport, E-commerce, Grande distribution", "company_size": "4000", "creation_date": "2018", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": null, "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": null, "dev_tools": ["digital", "digital", "digital"], "OS": ["linux),", "(windows,", "windows,"], "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["cloud,s√©curit√©", "cloud‚Ä¶),connaissance", "cloud,connaissance", "cloud"], "raw_description": "Descriptif du posteNotre TEAM SECURITY recherche un¬∑e Data Security Engineer SOC bas√©¬∑e √† Lille ou Paris. L'√©quipe S√©curit√© Decathlon assure la protection et la s√©curisation de l‚Äôensemble du groupe : elle pilote la strat√©gie de gouvernance et les processus de gestion du risque, s‚Äôassure de la conformit√© de nos syst√®mes d‚Äôinformations, d√©finit les moyens techniques n√©cessaires √† la d√©tection et √† la r√©ponse aux incidents, ainsi que les moyens de contr√¥le associ√©s.TA FUTURE CONTRIBUTION Participer √† la strat√©gie SOC/CSIRT de DECATHLON en lien avec la strat√©gie de l'entreprise et en tenant compte du cadre l√©gal et r√©glementaireContribuer avec les analystes au d√©veloppement et √† l'am√©lioration continue de la d√©tection (support de la Use-Case Factory),  Contribuer √† la strat√©gie de collecte log/data management et porter son int√©gration au sein des infras SOC/CSIRT (architecture, normalisation, parsing‚Ä¶)G√©rer et monitorer notre solution SIEM/Log Collection (report/dashboard, KPI/SLAs‚Ä¶) et contribuer √† l'am√©lioration continue de celle-ci (nouvelles fonctionnalit√©s, optimisation,...),Porter le r√¥le de Product Manager de la solution SIEM/Log Collection pour toute la Core Team S√©curit√© (usage mutualis√©) afin d‚Äôaccompagner autour des nouveaux besoins, suivre le capacity planning et garantir l‚Äôint√©grit√© de la plateformeContribuer √† la veille technologique autour des sujets de Data engineering, intelligence artificielle (usage dans la cadre de la s√©curit√©),...Participer au partage de connaissance et aux √©v√©nements propos√©s (voir √™tre force de proposition)  CE QUE TU APPORTESDe formation sup√©rieure en informatique, vous justifiez d‚Äôune exp√©rience significative (minimum 6 ans) sur un poste ax√© sur la s√©curit√© et/ou gestion de la data du SI, sur un p√©rim√®tre international et en environnement cloud,S√©curit√© des SI (connaissance des principes de s√©curit√© autour des syst√®mes, environnement Cloud‚Ä¶),Connaissance Splunk niveau avanc√© (Admin / Power User),Connaissance Splunk Enterprise Security (Administration),Connaissance des environnements cloud,Connaissance des langages de d√©veloppement et des syst√®mes (windows, linux), Connaissance des solutions de manipulation de donn√©es ETL/LET,Connaissance du cycle de d√©veloppement de r√®gles de d√©tection,Un environnement de travail √† haute criticit√© strat√©gique vous stimule,Vous √™tes rod√©.e √† travailler dans des environnements matriciels et √™tre entrepreneur.se sur votre p√©rim√®tre,Vous ma√Ætrisez l‚ÄôAnglais, √† l‚Äôoral comme √† l‚Äô√©crit. CE QUE NOUS T‚ÄôOFFRONS2 jours de t√©l√©travail par semaine ;Possibilit√© de travailler dans l'un des bureaux de Decathlon Digital √† Lille, Paris ou Amsterdam ;Mat√©riel fourni en accord avec tes missions et nos engagements soci√©taux (Mac, Windows, ou Chromebooks) ;Une √©quipe de projet locale au sein d'un r√©seau mondial (possibilit√© de carri√®re internationale) ;D√©veloppement des comp√©tences et accompagnement (diversit√© des projets, certifications techniques d√®s la premi√®re ann√©e, formations internes et externes, etc.) ;Package de r√©mun√©ration (participation des employ√©s aux actions de l'entreprise, bonus mensuels/trimestriels). DECATHLON DIGITAL Imaginez si la technologie nous permettait de repousser les fronti√®res et d'offrir des exp√©riences sportives in√©dites. C'est pr√©cis√©ment notre ambition chez Decathlon Digital ! Nous sommes une √©quipe de plus de 5 000 experts en ing√©nierie logicielle, gestion de produits, donn√©es, cloud et cybers√©curit√©, r√©partis √† Paris, Lille et Amsterdam. Ensemble, nous cr√©ons la plus vaste plateforme sportive num√©rique, en exploitant les innovations technologiques pour optimiser la cha√Æne de valeur, concevoir des exp√©riences connect√©es et donner une seconde vie √† nos produits.Changeons la donne pour de bon. Notre passion du sport nous guide et nous voulons qu‚Äôelle perdure. C‚Äôest pourquoi nous nous engageons √† b√¢tir un mod√®le technologique plus durable, en r√©duisant notre impact direct sur l'environnement, et en cr√©ant un espace s√ªr et inclusif pour apprendre et nous √©panouir ensemble. Rejoins l‚Äô√©quipe et fa√ßonnons le futur du sport."}
{"job_title": null, "contract_type": "CDI", "salary": "Non sp√©cifi√©", "company": null, "location": "Paris", "remote": "T√©l√©travail fr√©quent", "experience": null, "education_level": null, "publication_date": "2024-04-26", "sector": "Ing√©nieries Sp√©cialis√©es, IT / Digital, Strat√©gie", "company_size": "2500", "creation_date": "2007", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null, "programming_languages": ["python", "java,", "scala"], "databases": null, "data_analyze": null, "big_data_tools": null, "ML_and_data_mining": null, "data_viz": null, "statistics": null, "cloud_computing": ["aws", "gcp"], "dev_tools": null, "OS": ["linux,"], "big_data_and_processing": null, "automation_and_orchestration": null, "IaC": null, "security_and_network": null, "virtualization": null, "containers": null, "collaboration": null, "skills": ["statistiques", "cloud"], "raw_description": "Descriptif du posteVous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.Vous serez en charge de :Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,Concevoir et construire des architectures de donn√©es,Int√©grer des sources de donn√©es,Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux.Profil recherch√© :Vous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,Vous maitrisez les bases de l‚Äôanalyse statistique,Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,Vous √™tes familiaris√© avec l‚Äôenvironnement Linux, Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.Vous connaissez ou utilisez Dataiku"}
